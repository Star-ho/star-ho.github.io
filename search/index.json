[{"content":"Java 언어의 특징 Java는 컴파일 + 인터프리터 두가지 특징을 다 가지고 있음 Java코드를 컴파일하면 .class파일(byte Code)이 되고, JVM은 .class파일을 가지고 os에 맞게 machine code로 변환함 .class파일은 특정 실행횟수가 지나면 최적화가 됨 Tiered Compilation JVM의 JIT Compiler는 자주 실행되는 부분의 코드를 native code로 변환함 JIT compiler에는 2개의 java byte code interpreter가 존재함 Client compiler 메소드를 빠르게 컴파일 하지만 Server compiler보다 덜 최적화된 machine code를 생성함 빠른\u001f 시작에 사용함 Server compiler 동일한 메서드르 컴파일하는데 더 많은 시간이 듬 Client compiler보다 더 많은 시간 및 메모리를 소요하지만, 더 최적화된 machine code를 생성함 Tiered Compilation은 Client compiler를 첫번째 계\u001c으로 사용하여 서버 VM시작 속도를 향상시킴 서버 vm은 인터프리터를 사용하여 컴파일러에 공급되는 메서드에 대한 프로파일링 정보를 수집함 Tiered Compilation에서는 인터프리터 외에도 client compiler가 자신에 대한 프로파일링 정보를 수집하는 메서드의 컴파일된 버전을 생성함 컴파일된 코드가 인터프리터 보다 후러씬 빠르기 때문에, 이 프로파일 단계에서 프로그램이 더 뛰어난 성능으로 실행됨 애플리케이션 초기화 된계에서 server compiler가 생성한 최종 코드를 사용할 수 있기때문에 시작이 더 빠른 경우도 종종 존재함 Tier level 서로 다른 컴파일러와 인터프리터의 결합으로 아래와 같은 5개의 최적화 수준이 생성됨 Level Compiler 0 Interpreter JVM은 모든 자바 코드를 0 level을 사용함\n워밍업 단계가 끝나면 JIT 컴파일러가 시작되어 런타임에 코드를 최적화함\nJIT 컴파일러는 0 level에서 수집한 프로파일링 정보로 최적화 수행 1 C1 without profiling C1컴파일러를 사용하여 코드를 컴파일하지만, 프로파일 정보는 수집하지 않음\n사소한 것으로 간주되는 메서드(ex. getter)에 대해 level1 컴파일을 수행함\n메서드 복잡성이 낮아 C2컴파일하지 않음 2 C1 with basic profiling JVM은 라이트 프로파일링이 포함된 C1컴파일러를 사용하여 컴파일함\nC2큐가 가득차면 level2를 사용함\n목표는 성능개선을 위해 가능한 빠르게 코드를 컴파일 하는것\n나중에 JVM은 전체 프로파일링을 사용하여 level3으로 코드를 다시 컴파일함\n마지막으로, C2 대기열이 짧아지면, JVM은 level4에서 코드를 다시 컴파일함 3 C1 with full profiling JVM은 전체 프로파일링이 포함된 C1컴파일러를 사용하여 코드를 컴파일함\nlevel3은 기본 compilation path임\nJVM은 사소한 메서드와 컴파일러 대기열이 가득찬 경우를 제외한 모든 경우에 사용함\nJIT컴파일러에서 가장 일반적인 시나리오는 해석된 코드가 레벨 0에서 레벨3으로 바로 점프하는 것임 4 C2 full optimizing, no profiling 장기적인 성능을 극대화 하기 위해 JVM이 C2컴파일러를 사용하여 코드를 컴파일함\nlevel 4는 기본 compilation path임\nJVM은 사소한 메서드를 제외한 모든 메서드를 level4로 컴파일함\nlevel4코드는 완전히 최적화된 것으로 간주되므로 프로파일링 정보 수집을 중단함\n그럼에도, 코드 최적화를 해제하고 레벨 0으로 돌려보낼 수 있음 일반적으로 메서드는 interperter안에서 생성되며 메서드가 실행되는동안 계측을 통해 메서드의 프로파일이 수집됨 수집된 프로파일은 휴리스틱에 의해 사용되며 컴파일될지, 다시 다른 수준에서 컴파일 될지, 어떤 최적화를 수행할지 절정함 메서드를 실행하는 동안 HotSpot이 수집하는 가장 기본적인 두 가지 정보는 메서드가 실행된 횟수와 메서드의 루프가 반복된 휫수임 이 정보는 컴파일 정책에서 메서드를 컴파일 할지 여부와 컴파일 수준을 결정하는데 사용됨 컴파일 정책에서는 현재 compile중인 메서드에 대해 컴파일 요청을 레벨 3에서 설정하기 위해 공식을 사용함 현재 3레벨 컴파일로 실행중인 메서드를 레벨 4로 컴파일 하기 위한 요청을 생성할지 여부를 결정하는 데도 동일한 공식이 사용됨 1 2 3 (Executions \u0026gt; TierXInvocationThreshold * Scale) (Executions \u0026gt; TierXMinInvocationThreshold * Scale AND Executions + Iterations \u0026gt; TierXCompileThreshold * Scale) TierXInvocationThreshold\n호출 수가 이 임계값을 초과하는 경우, 메서드를 레벨X로 컴파일함 기본값은 레벨 3의 경우 200, 레벨 4의 경우 5000 TierXMinInvocationThreshold\n메서드를 레벨 X에서 컴파일하는데 필요한 최소 실행 횟수 기본값은 레벨 3의 경우 100, 레벨 4의 경우 600 TierXCompileThreshold\n메서드와 해당 루프의 반복 횟수가 이 임계값보다 . 더많이 실행된 경우 메서드를 레벨 X에서 컴파일함 기본값은 레벨 3의 경우 2000, 레벨 4의 경우 15000 Executions\n메서드가 실행된 횟수 Iterations\n메서드 내부의 루프가 실행된 누적 반복 횟수 Scale\n컴파일 대기열 부하를 안정적으로 유지하기 위한 Scale 계수 컴파일 대기열 함목 수와 컴파일러 스레드 수에 따라 주기적으로 동적으로 조정됨 HoptSpot은 컴파일이 다른 부분에 미치는 영향과 시스템이 현재 처리하고 있는 부하량도 고려함\n메서드를 해석중이고 위의 공식이 충족되어 레벨 3에서 메서드를 컴파일한다고 가정하면 컴파일 정책이 실제로 레\u001f3이 아닌 레벨2에서 컴파일 하기로 \u001f결정할 수 있음\nC2 대기열의 길이 일반적으로 레벨 3에서 컴파일된 메서드는 레벨2에서 컴파일된 동일한 메서드보다 느리기 때문에 메서드가 레벨3에서 보내는 시간을 최소화 하는 것이 좋음 적절한 프로파일리을 수집하여 필요한 시간만 레벨 3에서 소비해야함 따라서 C2대기열이 너무 길어, 레벨 3로 전환되는게 너무 오래걸린다면 우선 레벨 2로 이동하는 것이 유리함 추후 C2대기열이 줄어든다면 레벨 3에서 메서드를 다시 컴파일함 C1대기열 길이는 임계값을 동적으로 조정하고, 컴파일러가 과부하 될때 추가 필터링을 도입하는데 사용됨 컴파일러 대기열이 너무 길면 컴파일이 완료될 때 까지 메서드가 더이상 실행되지 않을 수 있기 때문 레벨 3에서 컴파일된 메서드가 레벨 4로 전환하기 위한 공식을 충족할 만큼 충분하 실행되면, 해당 레벨에서 메서드를 다시 컴파일 하라는 요청이 생성됨\n이 level에서는 HotSpot은 장기적인 성능을 극대화 하기 위해 C2 컴파일러를 사용하여 코드를 컴파일함\n레벨 4코드는 완전히 최적화된 것으로 간주되므로 JVM은 프로파일링 정보 수집을 중단함\n위 설명은 컴파일 정책의 단순화된 버전임, 메서드를 컴파일하거나 다시 컴파일할지 결정할 때 HotSpot이 고려하는 몇가지 다른 사항과 JVM 사용자가 정책을 정의하는데 사용할 수 있는 몇개의 플래그가 있음\n아래는 최적화와 연관된 이야기임 C2는 메소드의 동적 프로파일에 대한 정보를 사용하여 몇가지 최적화를 안내함\nInlining, Class Hierarchy Analysis(CHA), basic block ordering, some loop optimizations 프로파일이 if-else문이 과거에 then부분만 실행했음을 보여줄 떄,\nC2는 앞으로도 계속 이런 일이 발생할 것이라 가정하고, else블록은 전혀 컴파일 하지 않기로 결정 프로파일이 참조 변수가 절대 null이 아니라고 보여줄 때,\nC2는 향후 실행에서 변수가 계속 null이 아닐것이라고 가정하고, 그 가정을 사용하여 코드를 최적화 할 수 있음 프로필이 루프가 일반적으로 수천번 반복된다고 보여줄 때,\nC2는 해당 정보를 기반으로 루프를 unrolling 또는 벡터화 할 수 있음 프로파일이 클래스에 서브클래스가 없음을 보여줄 때,\nC2는 해당 클래스의 객체를 사용하여 메서드 호출에서 인라인 또는 다른 종류의 최적하를 수행하기로 결정할 수 있음 메서드의 프로파일은 동적 문제가 있음\n애플리케이션이 실행동항 메서드의 프로파일이 안정적일것이라는 보장은 없음\n프로그램 실행 중 대부분 참이었던 if-else조건이 갑자기 거짓을 반환함 트리거 되지 않었던 예외가 트리거됨 한번도 null이 아니었던 참조변수가 null로 표시됨 시스템에 새클래스가 로드되고, 이전에는 단순했던 클래스 계층구조가 더 복잡해짐 일반적으로 수천번 반복되는 루프가 이제는 몇번만 반복함 이러한 동적 동작을 고려하기 위해, C2는 컴파일된 코드에 predicates를 삽입하여 프로파일 정보를 기반으로 한 가정이 예전이 유효한지 확인함\npredicate가 false인 경우, 트랩(JVM 내부에 대한 호출)이 실행되어 어떤 가정이 거짓인지 HotSpot에 알림\n트랩이 제공한 정보를 바탕으로 HotSpot은 수행해야 할 작업을 결정함\n현재 컴파일된 메서드를 다시 컴파일할 수 있고, 실행을 인터프리터로 전환해야 할 수도 https://github.com/openjdk/jdk/blob/8eed7dea7b92dd98b74277e8521100f7f807eabb/src/hotspot/share/runtime/deoptimization.hpp#L69\n트랩이 실행될 수 있는 가능한 이유 목록 링크\n필요한 조치목록링크\n\u001d\nCompile 관련 옵션 default로 TieredCompilation은 활성화 되어있음\n-Xcomp\n메서드를 컴파일만 하도록 설정 HotSpot은 인터프리터를 사용하지 않으며 메서드는 항상 컴파일됨 -Xint\n메서드를 인터프리터만 사용하도록 수정 모든 JIT컴파일러가 비활성화되고 HotSpot이 프로그램을 실행하는 유일한 수단은 interpretation임 -XX:TieredStopAtLevel\n최대 컴파일 수준을 설정하는데 사용함 일부 C2버그를 우회하거나 C1을 스트레스 테스트 하기 위해 C1컴파일러만 사용하도록 강제하는것 -XX:-TieredCompilation\nHotSpot이 Tiered Compilation heuristics을 사용하여 컴파일간 전환하지 않고, 다른 heuristics을 사용하여 모든 컴파일에 대해 C1과 C2를 선택하게함 XX:InitialCodeCacheSize=N XX:ReservedCodeCacheSize=N` -XX:NonNMethodCodeHeapSize\nnon-method segment 영역을 지정 JVM내부 관련코드(default 대략 5MB) -XX:ProfiledCodeHeapSize\nprofiled-Code segment 영역 지정 C1으로 컴파일된, 잠재적으로 짧은 수명을 가진 영역(default 대략 122MB) -XX:NonProfiledCodeHeapSize\nnon-profiled-code segment 영역 지정 C2로 컴파일된, 잠재적으로 긴 수명을 가진 영역(default 대략 122MB) -XX:Tier4CompileThreshold\nTier4로 컴파일 하는 Threshold를 지정 -XX:+PrintCompilation\ndefault로, JIT compilation log는 disable되어 있음 위 옵션으로 JIT compilation log를 활성화 할 수 있음 아래의 포맷을 가짐 Timestamp 애플리케이션 시작 . 후밀리초 단위 Compile ID 컴파일되 각 메소드의 increment ID Attribute 5가지 값의 상태를 가짐 % - 온스택 교체 발생 s - 메소드가 동기화됨 ! - 메소드가 exception handler를 포함하고 있음 b - blocking모드에서 컴파일이 발생 n - 컴파일이 래퍼를 네이티브 메서드로 변환함 Compilation level 0에서 4사이 값을 가짐 Method name Bytecode size Deoptimisation indicator Made not entrant 표준 C1 최적화 또는 컴파일러의 낙관적 가정이 잘못된것으로 이증되을때 Made zombie 코드캐시에서 공간을 확보하기 위해 gc의 정리 메커니즘 아래는 AMD Ryzen 7 1800X machine running Ubuntu 20.04에서 java-17.07으로 HelloWorld 프로그램을 실행한 결과임\nFlags Average Wall Time \u0026ldquo;Default\u0026rdquo; 0.020s -Xint 0.020s -Xcomp 0.890s -Xcomp로 실행한것이 현저하게 느린것을 확인할 수 있는데, 이는 많은 메서드가 컴파일 비용을 상쇄할만큼 충분히 실행하지 않았기 때문 인터프리터만 사용하도록 JVM을 구성하면, 사용자 지정을 하지 않았을때와 같은데, 이는 예제가 오래 실행되는 메서드가 없기에, 인터프리터가 최선의 선택이기 때문임 https://www.baeldung.com/jvm-tiered-compilation\nhttps://docs.oracle.com/en/java/javase/11/jrockit-hotspot/compilation-optimization.html#GUID-8033B236-F6E5-473B-BB9F-34422143A1AA\nhttps://devblogs.microsoft.com/java/how-tiered-compilation-works-in-openjdk/\n","date":"2024-08-27T22:57:53Z","permalink":"https://sungho94.me/p/jvm-tiered-compilation/","title":"JVM Tiered Compilation"},{"content":"웹에서 실시간 상효작용을 위한 접근법 Polling 브라우저에서 반복적으로 서버를 호출하여 새로운 데이터가 있는지 확인함 효율적이지 못하며, 데이터 변경이 빈번하지 않을때 필요없는 요청이 너무 많이 발생함 Server-Sent Envent(SSEs) 폴링처럼 주기적으로 서버를 호출하는 대신, 개방형 연결(open connection)을 유지하여 서버가 데이터를 사용할 수 있을때, 클라이언트로 데이터를 전송함 불필요한 여러 요청과 응답으로 인한 오버헤드를 줄일 수 있음 SSE의 주요단점은 단방향임 서버는 데이터를 푸시할 수 있지만, 클라이언트는 동일한 연결을 통해 응답할 수 없기에, SSE는 일방적인 서버 업데이터에 이상적임 WebSocket 데이터를 반복적으로 요청하는 대신, 브라오저와 서버간에 통신라인을 열어둠 이로인해 웹소켓은 양방향 통신을 가능하게함 MQTT (Message Queuing Telemetry Transport) 배경 과거에는 거대한 외딴 지역의 데이터를 모니터링을 하는데 어려움이 있었음 불안정하고 대역폭이 낮은 네트워크, 모니터링 장치는 배터리로 작동하기 때문에 에너지절약이 필수적이 었음 이로인해 지속적인 통신이나 높은 네트워크 사용은 실용적이지 않았음 Light weight MQTT는 간결한 메시지와 컴팩트한 페이로드를 사용하여 네트워크를 통해 전송해야 하는 데이터 양을 줄인 최소한의 프로토콜로 설계됨 pub/sub이라는 단 하나의 메시지 패턴에만 집중함 QoS QoS레벨이 존재, 메시지 게시 시 QoS수준을 선택할 수 있음 QoS 0은 대역폭 사용량이 낮지만, 전송 보장도 낮음 QoS 2는 가장 높은 대역폭 사용량과 가장 높은 전송 보장을 제공 Last Will and Testament 연결의 불안정한 특성을 고려할때, 예기치 않은 연결이 발생할때 브로커가 전송한 last will(마지막 유언)을 설정할 수 있음 이 정보를 통해, subscriber는 유연한 대처가 가능함 일반적으로 connection time에 클라이언트에 의해 지정됨 Retained Message MQTT브로커는 Topic에 대해 마지막으로 알려진 메시지를 유지하여, 다운타임후 온라인 상태가 된 모든 드바이스다 즉시 최신메시지를 받을수 있도록 보장함 위와 같은 특성에서 MQTT는 다양한 시나리오에서 사용가능했음 현재 IoT 사용시에 이상적인 선택임 AMQP (Advanced Message Queuing Protocol) 모든 벤더가 구현할수 있는 프로토콜을 통해 서로 다른 시스템과 제품간의 상호 운영성을 보장한다는 비전을 바탕으로 탄생함 Open Standard 처음부터 개방형 표준으로 설계되었기에, 사양을 공개적으로 사용 가능함 모든 벤더나 개발자는 이러한 사양을 사용하여 제품이나 시스템에 AMQP를 구현할 수 있음 Reliable Message Deliveries 신뢰성을 보장하는 주요 메커니즘 중 하나는 승인임 메시지가 소비되면 브로커에게 확인을 전송하여 메시지가 처리되었음을 확인함 Flexibility 메시지가 먼저 Exchange로 이동한 다음 Queue로 이동함 Queue는 특정 패턴이나 기준에 따라 Exchange에 바인딩됨 이러한 바인딩 메커니즘은 다양한 Exchange유형과 결함되어 복잡한 라우팅 로직을 가능하게함 STOMP (Simple Text Oriented Messaging Protocol) 쉽게 구현하고 이해할 수 있는, 단순한 것을 만들기 위해 탄생함 Simplicity 미니멀리즘 방식으로 설계됨 기능이 많은 프로토컬의 오버헤드와 복잡성 없이 메시징에 필요한 기본 기능만 제공 아래와 같은 간단한 명령과 클래스가 존재함 Few Command CONNECT, CONNECTED, SEND, SUBSCRIBE, UNSUBSCRIBE, BEGIN, COMMIT, ABORT, ACK, NACK, MESSAGE, CRECEIPT, ERROR 풍부한 메서드 집합을 가진 AMQP와 대조됨 Connection Class Start, Start-Ok, Secure, Secure-Ok, Tune, Tune-Ok, Open, Open-Ok, Close, Close-Ok Channel Class Open, Open-Ok, Flow, Flow-Ok, Close, Close-Ok 적은 상태관리 STOMP는 상태저장기능이 있지만, AMQP는 세부적인 상태 관리 기능이 없음 AMQP는 Exchange, Queue, Binding등 다양한 속성을 지정하는 작업이 필요함 STOMP는 대상에게 메시지를 보내기만 하면 브로커가 세부사항을 처리함 Fewer Feature By Design STOMP는 일반적으로 메시징의 기본을 잘처리하는 것을 목표로 하며, AMQP에 있는 많은 고급 기능은 없거나, 더 높은 수준에서 구현됨 사용관점 뿐만 아니라 클라이언트 구현 관점에서도 STOMP를 단순하게 만듬 Text-Oriented 텍스트 기반이라 이해하고 디버깅하기 쉬움 원시 STOMP프레임을 보면 HTTP처럼 사람이 읽을 . 수있음 https://www.cloudamqp.com/blog/rabbitmq-and-websockets-part-1-amqp-mqtt-stomp.html\n","date":"2024-08-15T23:32:47Z","permalink":"https://sungho94.me/p/amqp-mqtt-and-stomp/","title":"AMQP, MQTT, and STOMP"},{"content":"Exchange 다양한 속성을 설정할 수 있음 가장 중요한 옵션은 name, durablity, auto-delete(마지막 대기열이 해해제되면 자동 삭제됨), argument 임 Default Exchange 브로커가 미리 선언한 이름이 없는 direct exchange 간단한 애플리케이션에 매우 유용한 한가지 속성이 있는데, 생성되는 모든 큐는 큐 이름과 동일한 라우팅 키를 사용하여 자동으로 바인딩됨 예를 들어 \u0026ldquo;search-indexing-online\u0026quot;이름의 큐를 선언하는 브로커는 \u0026ldquo;search-indexing-online\u0026quot;를 사용하여 기본 exchange에 해당 큐를 바인딩함 Direct Exchange 메시지 라우팅 키를 기반으로 메시지를 대기열에 전달함 메시지의 유니캐스트 라우팅에 이상적이지만, 멀티캐스트 라우팅에도 사용 가능함 라우팅 키 K를 가진 queue가 라우팅 R을 가진 새 메시지가 direct exchange에 도착하면 교환은 K=R인경우 해당 대기열로 라우팅함 동일한 라우팅 키 K를 가진 direct exchange가 여러개 있으면, Exchange는 K=R인 모든 대기열에 라우팅함 Fanout Exchange 바인딩된 모든 대기열로 메시지를 라우팅하며, 라우팅 키는 무시됨\nN개의 queue가 Fanout Exchange에 바인딩 되어 있는경우, 새 메시지가 Exchange에 publish되면, 메시지의 사본이 모든 N개의 대기열에 전달됨\n브로드 캐스트 라우팅에 이상적임\nFanout Exchange는 바인딩된 모든 queue에 메시지 사본을 전달하므로 사용 사례는 다들 비슷함\n대규모 멀티 온라인 게임에서 순위표 업데이트 스포츠 뉴스 사이트에서 실시간으로 모바일 클라이언트에 점수 업데이트를 하는데 사용할 수 있음 분산 시스템에서 다양한 상태 및 구성 업데이트에 사용될 수 있음 Topic Exchange 라우팅 키와 대기열을 exchange에 바인딩하는데 사용된 패턴의 일치 여부에 따라 메시지를 하나 또는 여러개의 대기열로 라우팅함 다양한 pub/sub패턴을 구현하는데 자주 사용됨 일반적으로 멀티 캐스트 라우팅에 사용됨 수신할 메시지 유형을 선택적으로 선택하는 여러 소비자/애플리케이션에 관련된 문제가 있을 떄마다 고려할 필요가 있음 Headers Exchange 라우팅 키 보다는 메시지 헤더로 더 쉽게 표현되는 여러 속성에 대한 라우팅을 위해 설계됨 Headers Exchange는 라우팅 키속성을 무시함 라우팅에 사용되는 속성을 헤더에서 가져옴 헤더의 값이 바인딩시 지정된 값과 같으면 바인딩함 일치하는 헤더를 2개이상 사용하여 대기열을 헤더 교환에 바인딩 할 수 있음 브로커는 애플리케이션으로 부터 모두 일치 또는 일부만 일치하는 메시지를 고려햐기 위해 x-match 인수가 사용됨 x-match가 all이면 모든 값이 일치해야함 x-match가 any면 하나라도 일치하면 됨 x-match를 any-with-x또는 all-with-x로 설정하면 문자열 x-로 시작하는 헤더도 일치항목을 평가하는데 사용됨 Binding Exchange에서 메시지를 Queue로 라우팅 하기 위해 사용하는 규칙\n일부 Exchange 유형해서 사용하는 라우팅 키 속성이 있을 수 있고, Exchange E가 메시지를 Queue Q로 라우팅하도록 지시하려면, Q를 E에 바인딩해야함\n라우팅 키의 목적은 Exchange에 publish된 특정 메시지를 바인딩된 Queue로 라우팅하도록 선택하는것\n라우팅 키는 필터와 같은 역할을함\n이러한 방향지정 계층이 있으면 publishing을 직접 사용하여 구현하기 불가능하거나 매우 어려운 시나리오에 대해 Queue를 라우팅 할 수 있으면 중복작업이 줄어듬\n메시지가 어떤 Queue로도 라우팅 할 수 없는경우, publisher가 설정한 메시지 특성에 따라 메시지가 삭제되거나, publisher에게 되돌아감\n","date":"2024-08-15T20:35:20Z","permalink":"https://sungho94.me/p/exchange-and-binding/","title":"Exchange and binding"},{"content":"Queue 애플리케이션에서 소비되는 메시지를 저장하는 장소 \bQueue는 일부 속성을 Exchange와 공유하지만, 몇가지 추가 속성이 있음 Name 256바이트의 UTF-8문자로 구성함 빈 문자열을 전달시, AMQP 0-9-1 브로커는 고유한 대기열 이름을 생성함 amq. 로 시작하는 대기열은 브로커 내부용으로 예약되어 있음 이 규칙을 위반하면 코드 403의 예외가 발생함 Durable(브로커 재시작 후에도 큐가 유지됨) durable한지 transient한지 선언할 수 있음 durable하다면 Queue의 메타데이터는 디스크에 저장되고, transient하다면 가능한경우 메모리에 저장됨 publish된 메시지도 동일 Exclusive(하나의 연결에서만 사용되며, 해당 연결이 닫히면 큐가 삭제됨) Auto-delete(큐에 연결된 모든 소비자가 연결을 끊으면 자동으로 삭제됨) Arguemnt(optional, 메시지 TTL, 큐길이 제한과 같은 플러그인 및 브로커별 기능에서 사용) Queue를 사용하려면 Queue을 선언해야함 Queue를 선언하면, Queue가 존재하지 않을경우 생성 Queue가 이미 존재하고 속성이 동일할경우 아무 영향을 끼치지 않음 속성이 다른경우, 코드 406의 예외가 발생함 ","date":"2024-08-15T20:34:36Z","permalink":"https://sungho94.me/p/queue/","title":"Queue"},{"content":"AMQP 0-9-1 적합한 클라이언트 애플리케이션이 적합한 메시징 미들웨어 브로커와 통신할수 있도록 하는 메시징 프로토콜\nMessage Broker는 publisher에게 메시지를 받아 consumer에게 라우팅함\n네트워크 프로토콜 이므로 broker, publisher, consumer는 다른 시스템에 존재할 수 있음\n메시지는 우체국이나 우편함에 비유되는 Exchange에 publish됨\nExchange는 Binding이라는 규칙을 사용하여 메시지 사본을 대기열에 배포함\nbroker는 Queue를 subscribe하는 consumer에게 메시지를 전달하건, consumer가 필요에따라 queue에서 메서지를 fetch/pull함\n메시지를 publishing할때, publisher는 다양한 메시지 속성을 지정할 수 있음\n일부는 브로커에서 사용할 수 있지만, 나머지는 브로커가 볼 수 없으며, 메시지를 수신하는 애플리케이션에서만 사용됨 네트워크가 불안정하고, 어플리케이션이 메시지를 처리할 수 없을 수 있으므로 AMQP 0-9-1 모델에는 message acknowledgements라는 개념이 있음 메시지가 소비자에게 전달되면, 소비자는 자동 또는 개발자의 선택에 따라 큐에 알림 메시지 확인이 사용중일때, 브로커는 해당 메시지 알림을 수신할때만 큐에서 해당 메시지를 완전히 제거함 메시지가 라우팅을 확장할 수 없는경우, 특정 상황에서는 메시지가 publisher에게 반환되거나, 삭제되거나 dead letter queue에 쌓일 수 있음\nqueue, exchanges, binding은 AMQP엔티티임\nAMQP 엔티티는 broker 관리자 뿐만이 아니라, application에서 정의되어질 수 있기에 프로그래밍 가능한 protocol임\nMethod HTTP메서드와 유사하게, AMQP는 몇개의 메서드가 구성되어 있음\nexchange.declare\nexchange.declare-ok\nexchange.delete\nexchange.delete-ok\npublisher나 consumer가 해당 메시지를 보내, exchange, queue, binding을 생성할 수 있음\nhttps://www.rabbitmq.com/tutorials/amqp-concepts\n","date":"2024-08-12T23:17:42Z","permalink":"https://sungho94.me/p/amqp-0-9-1-model/","title":"AMQP 0-9-1 Model"},{"content":"Broker 관련 설정: 메시지 브로커 설정 심층 분석 Broker는 메시지 중개자 역할을 수행하며, Producer와 Consumer 간의 메시지 전달을 책임지는 핵심적인 구성 요소입니다. Broker의 설정은 시스템의 성능, 안정성, 확장성에 직접적인 영향을 미치므로 신중하게 설정해야 합니다.\n주요 Broker 설정 항목 Network 설정: Binding: 어떤 Queue에 어떤 Exchange를 바인딩할지 설정 Virtual Host: 논리적인 분리된 환경 구성 Clustering: 여러 Broker를 연결하여 클러스터 구성 Queue 설정: Durability: Queue의 지속성 설정 (메시지 유실 방지) Auto-delete: 더 이상 사용되지 않는 Queue 자동 삭제 Exclusive: 단독 소비자만 접근 가능하게 설정 Message TTL: 메시지 유효 기간 설정 Dead-Letter Exchange: 처리 실패 메시지를 보낼 DLX 설정 Exchange 설정: Type: Direct, Fanout, Topic, Headers 등 Exchange 타입 설정 Durability: Exchange의 지속성 설정 Auto-delete: 더 이상 사용되지 않는 Exchange 자동 삭제 Message 설정: Message Size: 최대 메시지 크기 설정 Message TTL: 메시지 유효 기간 설정 Performance 설정: Prefetch Count: 소비자가 미리 가져올 메시지 수 설정 Concurrency: 동시에 처리할 메시지 수 Security 설정: Authentication: 인증 메커니즘 설정 Authorization: 권한 관리 설정 SSL/TLS: 보안 통신 설정 Monitoring 설정: Metrics: 메트릭 수집 (메시지 처리량, 지연 시간 등) Logging: 로그 설정 Broker 선택 시 고려 사항 기능: 필요한 기능 (Durable, Transactional, Exactly-Once Delivery 등) 지원 여부 성능: 처리량, 지연 시간 등 성능 요구사항 충족 여부 확장성: 시스템 부하 증가에 따른 확장성 운영 편의성: 관리 도구, 모니터링 기능 등 커뮤니티: 활발한 커뮤니티 지원 여부 주요 메시지 브로커 종류 및 특징 RabbitMQ: 다양한 기능, 높은 확장성, 활발한 커뮤니티 Kafka: 고성능, 분산 시스템, 스트리밍 처리에 적합 ActiveMQ: 다양한 프로토콜 지원, 안정성 Amazon SQS: 클라우드 기반, 쉽고 빠른 설정 Google Pub/Sub: 클라우드 기반, 스케일링 용이 ","date":"2024-08-10T23:49:41Z","permalink":"https://sungho94.me/p/broker/","title":"Broker"},{"content":"Consumer 에플리케이션이 메시지를 사용할 수 없다면, Queue에 메시지를 저장하는것은 불필요함 AMQP 0-9-1 모델에는 Subscribe과 Polling이 있음 애플리케이션이 메시지를 전달받도록 하는 Subscribe 방식 - 권장 옵션 비효율적이며 대부분의 경우 피해야하는 Polling 방식 Push API를 사용하면 애플리케이션이 특정 Queue에 Subscriber를 등록하거나, Queue에 가입해야함 Queue에 두명 이상의 consumer를 등록하거나, exclude consumer를 등록할 수 있음 각 consumer는 consumer tag라는 문자열로된 식별자가 존재함 이 식별자는 메시지 수신을 취소하는데 사용할 수 있음 Rejecting Messages consumer 애피리케이션이 메시지를 받을 때, 메시지 처리가 성공 할 수도, 실패할 수도 있음 애플리케이션은 메시지를 거부하므로써 브로커에게 메시직 처리가 실패했음을 알릴 수 있음 메시지를 거부할 때 브로커에게 메시지를 폐기하거나, 다시 Queue에 넣도록 요청할 수 있음 대기열에 소비자가 한명 만 있는경우, 동일 소비자의 메시지를 거부했다가 다시 queue에 넣는 무한루프를 만들지 않도록 주의해야함 Prefetching Message 여러 Consumer가 하나의 queue를 공유할때, 다음 ACK를 보내기전에 각 소비자가 한번에 처리할 수 있는 메시지 수를 지정하는것은 유영함 간단히 부하분산 기술로 사용하거나, 메시지가 일괄적으로 publish되는 경항이 있는경우 처리량 개선에 사용할 수 있음 예를들어, publisher특성상 매분 메시지를 전송하는 경우 유용함 RabbitMQ는 채널 레벨 prefetch만 지원하고, 연결 또는 크기기반 prefetch는 지원하지 않음 기본 설정 Queue 바인딩: 어떤 Queue의 메시지를 받을지 설정 Message Listener: 메시지를 받아 처리하는 메소드 구현 Container Factory: 메시지 컨테이너 생성을 위한 팩토리 설정 고급 설정 Concurrency: 동시에 처리할 메시지 수 Error Handling: 오류 처리 (Retry, Dead-Letter Exchange, Error Queue, Circuit Breaker) Transaction: 트랜잭션 관리 Acknowledgment: 메시지 처리 확인 Prefetch Count: 미리 가져올 메시지 수 Dead-Letter Exchange: 처리 실패 메시지 보낼 DLX 설정 Message Converter: 메시지 형식 변환 심화 설정 및 고려사항 메시지 처리 전략: Pull vs Push, Batch 처리, Parallel 처리, Message Sequencing, Deduplication, Prioritization, Asynchronous Processing 오류 처리 심화: Retry Strategies, Circuit Breaker Pattern, Bulkhead Pattern, Resilience4j 성능 최적화: Batching, Compression, Caching, Profiling 확장성: Horizontal Scaling, Sharding, Load Balancing 보안: TLS/SSL, Access Control, Authentication, Authorization 모니터링: Metrics, Logging, Alerting, Distributed Tracing 특수 기능: Delayed Messages, Scheduled Messages, Message Routing 클라우드 환경: Serverless Functions, Managed Messaging Services, Cloud-Native Patterns 테스트: Unit Test, Integration Test, Chaos Engineering, Mutation Testing 패턴: Observer Pattern, Strategy Pattern, Actor Model, CQRS 추가 키워드 Consumer Tag: 소비자 식별 Channel: 메시지 채널 Ack: 메시지 처리 성공 확인 Nack: 메시지 처리 실패 확인 Requeue: 메시지 다시 큐에 넣기 ","date":"2024-08-10T23:37:42Z","permalink":"https://sungho94.me/p/subscriber/","title":"Subscriber"},{"content":"지금까지 다룬 Spring Boot Publisher 설정에 대한 핵심 키워드를 정리해 드리겠습니다.\n핵심 설정 RabbitMQ 연결: 호스트, 포트, 사용자명, 비밀번호 등 RabbitMQ 서버 연결 정보 Exchange: Exchange 이름, 타입 (direct, fanout, topic, headers), 내구성, 자동 삭제 여부 Queue: Queue 이름, 내구성, 독점 여부, 자동 삭제 여부, 인자 (DLX, TTL 등) Binding: Exchange와 Queue 바인딩, 라우팅 키 Template: mandatory, returnCallback, confirmCallback 등 ConnectionFactory: 연결 팩토리 설정 (커넥션 풀링, 재연결 등) MessageConverter: 메시지 변환기 설정 (JSON, XML 등) 추가 고려 사항 메시지 크기 및 속도: 대용량 메시지 처리, 고속 메시지 전송 메시지 보장: 확인, 트랜잭션, QoS 보안: 인증, 암호화, 접근 제어 클러스터링: 고가용성, 부하 분산 모니터링: 메트릭, 로그 테스트: 단위 테스트, 통합 테스트, Contract Test 비동기 처리: AsyncRestTemplate, CompletableFuture 메시지 형식: Custom Message Converter, Schema Registry, Type Conversion 확장성: Dynamic Routing, Message Expiration, DLX 클라우드 환경: Cloud-Native Messaging, Kubernetes 패턴 및 관례: Builder Pattern, Template Method Pattern Retry Mechanism: 재시도 메커니즘 Circuit Breaker: 회로 차단기 Idempotent Producer: 중복 메시지 처리 심화 설정 메시지 형식: Custom Message Converter, Schema Registry, Type Conversion 확장성: Dynamic Routing, Message Expiration, DLX 클라우드 환경: Cloud-Native Messaging, Kubernetes 테스트 및 모니터링: Integration Test, Contract Test, Prometheus 보안 및 규정 준수: TLS/SSL, IAM, Compliance 패턴 및 관례: Builder Pattern, Template Method Pattern Retry Mechanism: 재시도 메커니즘 Circuit Breaker: 회로 차단기 Idempotent Producer: 중복 메시지 처리 Confirm : 각 키워드에 대한 자세한 설명은 이전 답변들을 참고하시거나, 궁금한 부분을 질문해주세요.\n","date":"2024-08-10T23:37:33Z","permalink":"https://sungho94.me/p/publisher/","title":"Publisher"},{"content":"\nConnection Timeout client가 server에 커넥션을 연결을 시도하는 최대 시간 지정 the time to establish the connection with the remote host Socket Timeout server와의 연결이 완료된 시점에서, 데이터의 송수신을 할 최대 시간 지정 두 데이터패킷 사이 비활성화된 최대 시간 maximum time of inactivity between two data packets HTTP Manager Timeout HTTP Client 라이브러리에서는 내부적으로 HTTP 커넥션 풀을 관리함 HTTP 커넥션 풀에서 커넥션을 가져오는데 걸리는 최대 시간 제어 https://www.baeldung.com/httpclient-timeout\nhttps://stackoverflow.com/questions/18184899/what-is-the-difference-between-the-setconnectiontimeout-setsotimeout-and-http\n","date":"2024-07-14T23:01:00Z","permalink":"https://sungho94.me/p/http-client-timeout/","title":"HTTP Client Timeout"},{"content":"개념 프로그래밍 패러다임의 한 종류로, 객체간의 상호작용을 통해 로직을 구성하는 방법 객체간의 상호작용은 인간 세계의 상호작용을 바탕으로 하기에 이해하기 쉬움 특징 캡슐화 서로 연관되어있는 속성과 기능들을 하나의 캡슐로 만들어 외부로 부터 보호하는것 데이터 보호 - 외부로부터 클래시에 정의된 속성과 기능들을 보호 데이터 은닉 - 내부의 동작을 감추고 외부에는 필요한 부분만 노출 추상화 중요한 부분을 강조하기 위해 불필요한 세부사항을 제거하고, 본질적이고 공통적인 부분만 추출하여 표현하는 것 상속 상위 클래스로부터 확장된 여러 개의 하위 클래스들이 모두 상위 클래스의 속성과 기능들을 간편하게 사용할 수 있도록 하는것 속성보다는 하는 행위가 같아야지 덜 복잡함 다형성 어떤 객체의 속성이나 기능이 상황에 따라 여러 가지 형태를 가질 수 있는 성질 메서드 오버라이딩, 메서드 오버로딩 원칙 단일 책임 원칙 (Single Responsiblity Principle) 하나의 객체는 하나의 책임만 가져야함 변경의 이유도 하나여야함 개방-폐쇄 원칙 (Open Closed Principle) 변경에는 닫혀있고, 확장에는 열려있어야함 리스코프 치환 원칙 (Liskov Substitution Principle) 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야 함 인터페이스 분리 원칙 (Interface Segregation Principle) 필요한 인터페이스만 상속받아야함 특정 클라이언트를 위한 인터페이스 여러개가 범용 인터페이스 하나보다 낫다 의존 역전 원칙 (Dependency Inversion Principle) 구체화된것 보다는 추상적인것을 의존해야함 어떤 코드가 변경되었을때 변경되는 정도\n결합도\n응집도\n관심사의 분리\nhttps://www.cs.utexas.edu/users/EWD/transcriptions/EWD04xx/EWD447.html\nIt is what I sometimes have called \u0026ldquo;the separation of concerns\u0026rdquo;, which, even if not perfectly possible, is yet the only available technique for effective ordering of one\u0026rsquo;s thoughts, that I know of. This is what I mean by \u0026ldquo;focussing one\u0026rsquo;s attention upon some aspect\u0026rdquo;: it does not mean ignoring the other aspects, it is just doing justice to the fact that from this aspect\u0026rsquo;s point of view, the other is irrelevant. It is being one- and multiple-track minded simultaneously.\nhttps://www.codestates.com/blog/content/%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-%ED%8A%B9%EC%A7%95\n#argent\n","date":"2024-06-30T23:17:10Z","permalink":"https://sungho94.me/p/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-object-oriented-programming/","title":"객체지향 프로그래밍 - Object Oriented Programming"},{"content":"\n1. coordinateing stage Elasticsearch의 모든 색인 작업은 일반적으로 document ID(routing_key)를 기반으로 라우팅을 사용해 복제 그룹을 확인함 shard = hash(routing_key) % number_of_primary_shards 복제 그룹이 확인되면, 그 작업은 내부적으로 그룹의 현재 기본 샤드로 전달됨 2. primary stage primary 샤드는 작업의 유효성을 검증하고, replica 샤드로 전달하는 역할 replica 샤드는 오프라인 상태일 수 있으므로 primary 샤드가 모든 replica에 복제할 필요가 없음 대신 Elasticsearch는 작업을 수신해야 하는 샤드 복제본 목록을 유지함 이 목록을 in-sync copies라고 불리며, 마스터노드에서 관리됨 사용자에게 승인된 모든 인덱스 및 삭제 작업을 처리했음을 보장하는 정상 샤드 복사본 직합 primary는 이 불변성을 유지할 책임이 있으므로, 모든 작업을 해당 세트의 replica에 복제해야함 기본 샤드의 요청 흐름\n2-1. 들어오는 연산의 유효성을 검사하고, 유효하지 않은 경우 거부함\nex) 숫자 필드에 객체 필드가 들어오는경우\n2-2. local에서 작업을 수행하고, 관련 document를 indexing하거나 삭제함 유효성을 검사하고 필요할경우 거부함(키워드가 너무 길어 Lucene에 색인할 수 없는경우)\n2-3. in-sync copies set의 각 replica에게 작업을 전송함 복제본이 여러개인 경우, 병렬로 수행됨\n2-4. 모든 in-sync copies set이 작업을 성공적으로 수행하고, primary에 응답하면 primary는 클라이언트에 대한 요청이 정상적으로 완료되었음을 알 수 있음 검색은 in-sync copies에 있는 reaplica샤드 뿐만아닌, 모든 replica 샤드에서 검색이 가능함\n모든 replica샤드에 요청이 전파되어 저장되기 전에, in-sync copies외 샤드에 검색하면 변경내용이 없음\n이로인해 es는 near real-time search가 됨\n3. replica stage 각 in-sync replica는 로컬에서 인덱싱 작업을 수행하며 복사본을 가짐 위의 indexing단계는 순차적으로 진행되며, 내부 재시도를 가능하기 위해 lifetime을 가지고 있음 https://www.elastic.co/blog/found-elasticsearch-top-down\nhttps://www.elastic.co/blog/found-elasticsearch-from-the-bottom-up\nhttps://www.javaadvent.com/2022/12/elasticsearch-internals.html\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-replication.html#basic-write-model\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html\n","date":"2024-06-23T10:45:30Z","permalink":"https://sungho94.me/p/elasticsearch-write/","title":"Elasticsearch write"},{"content":" document의 문자열 필드가 역 인덱스의 term으로 변환되는 방식을 결정하는 알고리즘 궁극적인 목표는 문자열을 일련의 토큰으로 변환하는것 문자열이 token화 되는 과정 1. Input 2. CharacterFilter 텍스트를 소문자로 변환하거나, 단어를 대체하는 등 특정 방식으로 문자열을 변환하고, 변환된 문자열을 출력함 문자를 추가, 제거, 또는 변경함 힌두-아랍 숫자(٠١٢٣٤٥٦٧٨٩)를 아랍어-라틴어(0123456789)로 변환하거나 \u0026lt;b\u0026gt;와 같은 HTML 요소를 제거할 수 있습니다. 3. Tokenizer 문자열 스트림을 입력으로 받아, 개별 토큰으로 분리함 다음을 데이터을 저장 각 용어의 순서 또는 위치 용어가 나타나는 원래 단어의 시작 및 끝 문자 오프셋 검색 스니펫을 강조하기 위해 사용함(?) 토큰 유형 ex) \u0026lt;ALPHANUM\u0026gt;, \u0026lt;HANGUL\u0026gt;, or \u0026lt;NUM\u0026gt; 4. TokenFilter Tokenizer에서 받은 토큰을 수정(대-\u0026gt;소 문자로 변환), 삭제(stopword제거), 추가(ex) 동의어)함 5. Output https://www.elastic.co/blog/found-text-analysis-part-1\nhttps://www.elastic.co/blog/found-text-analysis-part-2\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-charfilters.html\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html\n","date":"2024-06-22T21:13:08Z","permalink":"https://sungho94.me/p/analyzer/","title":"Analyzer"},{"content":" search쿼리는 도착지를 고정할 수 없고, 잠재적으로 매칭되는 index또는 indices안의 모든 샤드를 검색해야하기에 어려움 일치하는 문서를 찾는 것 뿐만아니라, 검색 api는 결과를 사용자에게 표시하기 전에 통합되고 정리된 목록으로 결합해야함 기본적으로, 엘라스틱서치는 Query Then Fetch라는 검색방법을 사용함 단계 1. 클라이언트가 Elasticsearch로 쿼리 전송(조정노드) 2. 쿼리를 각 샤드로 브로드캐스팅(조정노드) 2-1. 조정노드는 패턴 또는 별칭으로 대상 인덱스 목록 작성\n단일인덱스도 될 수 있지만, logsash-*과같이 패턴일 수 있음 실제 쿼리가 검색해야하는 인덱스 목록이 생성됨\n2-2. 대상 인덱스의 distinct shard 목록을 작성함 distinct shard목록은 primary shard와 replica shard의 집함임 검색요청은 primary shard와 replica shard 둘 중 어\n2-3. 각 인덱스의 라우팅옵션에 따라 모든 샤드로 갈지, 하나의 샤드로 갈지 결정함 대부분의 쿼리는 모든 별개의 샤드로 가지만, 특정 라우팅으로 하나의 샤드에 모든 document가 있다는것을 보증한다면, 하나의 샤드로만 쿼리함\n2-4. 조정노드는 관롼된 각 샤드에 대해 쿼리할 실제 샤드를 선택함 일반적으로 무작위로 선택되지만, 최근 쿼리에서 가장 성능이 좋은 샤드를 결정하는 등 최적화가 이루어지기도 함 3. 로컬 용어/빈도를 사용해 일치하는 모든 문서 찾기 및 점수계산 아래의 작업이 발생함 ElasticSearch level에서 매핑 인덱스 시점의 매핑과 유사함 쿼리 필드를 기본 Lucoene데이터 필드 및 구조에 매핑하여, 각 세그먼트(Lucene index)가 실행할 수 있는 Lucene호환 쿼리를 생성 Lucene에서의 분석 Lucene에서 검색 Lucone에서 Scoring 쿼리의 텍스트 부분은 동일한 analyzer를 통해 tokenzing됨 이로인해 쿼리 텍스트가 색인된 방식과 일치하게 됨 4. 결과의 우선순위 큐 구축(정렬, 페이지네이션 등) 5. 조정 노드에 결과에 대한 메타데이터를 반환함 실제 문서가 아닌 document ID와 점수를 반환함 6. 모든 샤드의 점수가 조정 노드에서 병합 및 정렬되고, 쿼리 기준에 따라 문서가 선택됨 7. 끝으로, 실제 문서가 있는 개별 샤드에서 실제 문서가 검색됨 8. 결과를 클라이언트에 반환(조정노드) 조정 노드는 1,2,8단계에서 사용됨 Query Phase(3,4,5,6) 검색 쿼리는 모든 샤드에 전성되어 로컬 실행이 시작되고, 일치하는 문서가 포함된 우선순위 대기열이 생성됨 Fetch Phase(7) query Phase가 연관된 문서를 확인하는 반면에, Fetch phase에서는 각각의 샤드에서 실제 문서를 가져오는 역할을 담당함\n이 분할방식은 분산된 환경에서 효과적이고 확장가능한 검색작업을 보장함\nQuery phase에서는 검색 커리가 각 샤드 복사본을 탐색하여 로컬 검색을 시작하고, 일치하는 문서의 우선순위가 지정된 목록을 컴파일함 이 단계는 검색 결과를 구체화 하는 초기단계임 Fetch phase에서는 원하는 검색 결과를 제공함 이 단계는 쿼리 실행과 검색 결과 사이의 가교 역할을 하며 검색 프로세스의 철저함을 보장함 추가 정보 Elasticsearch의 query와 fetch phases에서 slow logs를 enable하면, 검색 성능을 모니터링 및 최적화가 가능함 1 2 3 4 5 6 7 8 9 10 11 12 13 PUT *,-.*/_settings { \u0026#34;index.search.slowlog.threshold.query.warn\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.search.slowlog.threshold.fetch.warn\u0026#34;: \u0026#34;100ms\u0026#34; } #or with curl curl -XPUT \u0026#34;http://localhost:9200/*,-.*/_settings\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; -d\u0026#39; { \u0026#34;index.search.slowlog.threshold.query.warn\u0026#34;: \u0026#34;1s\u0026#34;, \u0026#34;index.search.slowlog.threshold.fetch.warn\u0026#34;: \u0026#34;100ms\u0026#34; }\u0026#39; https://medium.com/@musabdogan/elasticsearchs-distributed-search-query-and-fetch-phases-df869d35f4b3\nhttps://steve-mushero.medium.com/elasticsearch-search-data-flow-2a5f799aac6a\n","date":"2024-06-18T22:30:18Z","permalink":"https://sungho94.me/p/elasticsearch-query-and-fetch/","title":"ElasticSearch query and fetch"},{"content":"인증과 인가는 보안 시스템에서 중요한 개념으로, 사용자의 신원을 확인하고 자원에 대한 접근 권한을 관리하는 데 사용됩니다. 이 두 개념은 종종 혼동되지만, 서로 다른 목적을 가지고 있습니다.\n인증 (Authentication) 사용자가 자신이 주장하는 신원임을 확인하는 과정 사용자가 로그인할 때 시스템은 사용자의 신원을 확인하기 위한 방법 무엇을 알고 있는가 (What you know): 패스워드, PIN 등. 무엇을 가지고 있는가 (What you have): 스마트 카드, 보안 토큰 등. 무엇인가 (What you are): 지문, 얼굴 인식, 홍채 스캔 등 생체 인식. 사용자나 시스템이 제공하는 정보가 신뢰할 수 있는지를 확인하는 절차로, 이 단계에서 사용자는 본인임을 증명해야 합니다. 인가 (Authorization) 인증을 거친 사용자가 특정 자원에 접근할 수 있는 권한이 있는지를 결정하는 과정\n인증이 사용자의 신원을 확인하는 것이라면, 인가는 그 사용자가 특정 작업을 수행할 수 있는지를 결정하는 것\n사용자가 시스템에 로그인을 해서 인증이 완료된 후, 그 사용자가 특정 파일을 읽거나 쓸 수 있는지, 또는 특정 애플리케이션을 실행할 수 있는지 등을 결정하는 것이 인가입니다. 인가 시스템은 주로 다음과 같은 정보를 바탕으로 작동함\n역할 기반 접근 제어 (Role-Based Access Control, RBAC): 사용자에게 특정 역할을 부여하고, 그 역할에 따라 접근 권한을 결정합니다. 정책 기반 접근 제어 (Policy-Based Access Control, PBAC): 조직의 보안 정책에 따라 접근 권한을 결정합니다. 속성 기반 접근 제어 (Attribute-Based Access Control, ABAC): 사용자, 자원, 환경 등의 속성에 따라 접근 권한을 결정합니다. 요약 인증: 사용자가 누구인지 확인하는 과정. 인가: 확인된 사용자가 어떤 자원에 접근할 수 있는지를 결정하는 과정. ","date":"2024-05-28T23:21:08Z","permalink":"https://sungho94.me/p/%EC%9D%B8%EC%A6%9D-%EC%9D%B8%EA%B0%80/","title":"인증, 인가"},{"content":" Jeremy Cole의 InnoDB정보들은 MySQL 5버전에 관한 내용이며, 10년전의 내용임 현재 MySQL 8버전대를 사용하는데, 큰 기본 틀의 큰 차이는 없어 보이지만, 간단하게 알아볼 예정 Mysql버전에 따라 innodb버전이 업데이트됨 Jeremy Cole의 Innodb_ruby는 현재 8버전 대를 지원하고 있지 않음 필자는 아래 두가지 도구를 추천한다 https://github.com/alibaba/innodb-java-reader 이 포스팅에서 사용할 도구 https://github.com/baotiao/inno_space 사용방법을 익히려 해보았지만, record를 파싱하는 부분에서 에러가 나서 결국 포기하였다. 예제 데이터는 ibd2sdi를 이용하여 record정보를 가져오는것 같은데 실패하였다 방법을 알면 댓글로 알려주시길 바랍니다 ㅠㅠ 무엇을 알아볼 것인가? space page구조 page들은 doubly-linked list 구조인가? index record들은 singly-linked list구조인가? Space page 구조 매우 작은 테이블의 구조를 나타냄 5버전대와의 차이점은 SDI페이지가 생겼다는 것이고, 이외에는 동일하다 SDI는 데이터베이스 객체에 대한 메타데이터를 저장하는 용도 자세한 정보는 링크참고 여전히 page들은 doubly-linked list인가? 데이터가 들어있는 페이지의 일부이다 page들이 prevPage, nextPage를 가지고 있고 INDEX페이지들은 앞 뒤 페이지를 참조하는 것을 알 수 있음 doubly-linked list구조 확인 index record들은 singly-linked list구조인가? 하나의 offset만 존재하며, 현재 primaryKeyPosition값에서 offset을 더하면, 다음 primaryKeyPosition이 되는 것을 알 수 있음 singly-linked list구조 확인 ","date":"2024-05-24T16:30:40Z","permalink":"https://sungho94.me/p/7-mysql-8.0%EC%97%90%EC%84%9C%EB%8A%94/","title":"7-Mysql 8.0에서는?"},{"content":"Record 해당 포스트에서는 COMPACT row format만 고려함 Record offsets 이전 포스트에서 레코드 오프셋은 레코드를 가르키는 구조라고 설명했음 레코드 오프셋은, 가변길이인 레코드 데이터 자체의 시작을 가르키지만, 각 레코드 앞에는 가변길이의 레코드 헤더가 존재함 해당 포스트의 글과 그림에서 레코드 데이터는 N에 존재하고, N+1과같이 양수오프셋으로 표현함 헤더는 N-1과 같이 음수 오프셋으로 표현함 InnoDB는 종종 레코드의 시작점 위치인 N을 원본으로 지칭함 The record header Next Record offset\n현재 레코드에서 페이지 내 다음 레코드의 시작점까지의 상대적 오프셋 Record Type\n레코드 유형으로 일반(0), 노드 포인터(1), 최소값(2), 최상위(3)의 4가지 값만 지원됨 Order\n이 레코드가 힙에 삽입된 순서임 Infimum, supremum을 포함한 힙 레코드는 0번부터 번호가 매겨짐, Infimum은 항상 0, supremum은 항상 1임 삽입된 사용자 레코드는 2부터 번호가 매겨짐 Number of Records Owned\n페이지 디렉토리에서 현재 레코드가 \u0026lsquo;소유\u0026rsquo;한 레코드수 향후 포스트에서 설명할 예정 Info Flag\n레코드에 대한 boolean flag를 지정하는 4비트 비트맵 현재 두개의 플래그만 정의도어 있음 min_rec(1)는 이 레코드가 B+Tree의 non-leaf에서 최소 레코드임을 의미함 deleted(2)는 레코드가 삭제 표시되어 있으며, 향후 purge operation에 의해 실제로 삭제될 것임을 의미함 Nullable field bitmap(optional)\n필드가 NULL인지 여부를 저장하기 위한 필드, nullable한 필드당 1비트를 사용하고, byte로 반올림됨 필드가 NULL인 경우 해당 필드 값은 레코드의 키 또는 행부분에서 제거됨 Null이 필드가 없는 경우 이 비트맵은 존재하지 않음 Variable file lengths array(optional)\n가변길이 필드당 8비트 또는 16비트 정수 배열(필드의 최대크기에 따라 다름)로 해당 필드에 대한 데이터 길이를 저장 가변길이 필드가 없는경우, 이 배열은 없음 record header는 row당 최소 5 byte이며, 가변길이 필드에 의해 더 길어질 수 있음\nClustered indexes Cluster Key Fields 클러스 키 필드는 문자 그대로 함께 연결됨 InnoDB는 column유형 별 내부 저장소 형식의 raw byte를 단이 바이트 스트림으로 연결하기만 함 Transaction ID 이 레코드를 마지막으로 수정한 트랜잭션의 48비트 정수 트랜직션 ID Roll Pointer 해당 레코드를 마지막으로 수정한 트랜잭션의 undu record의 rollback segment 위치를 포함하고 있는 구조체 이 필드의 roll pointer 구조는 1비트의 \u0026ldquo;삽입중\u0026rdquo; 플래그, 7비트의 rollback segment ID, 4바이트 페이지 번호, 2바이트의 undo log위치의 페이지 오프셋으로 이루어짐 Non-Key Fields 기본키가 아닌 실제 행데이터가 단일 바이트 스트림으로 연결되어 있음 non-leaf 페이지의 레코드 포맷임 non-leaf page는 MVCC가 아니기에, Transaction ID와 Roll Pointer filed는 없음 non-key field 대신에 이 노드 포인터가 가르키는 하위 페이지 번호가 포함됨 클러스터 키는 NUL이 될 수 없으므로 nullable field bitmap도 없음 Secondary indexes InnoDB의 Secondary Index는 clustered key와 전체 구조가 동일하지만, non-key대신 Primary Key Value(PKV)라고 하는 clustered key field를 포함함 Secondary Index와 clustered key사이에 겹치는 필드가 있는 경우, Secondary Index레코드에 저장된 clustered key에서 겹치는 필드가 제거됨 예를들어, 테이블에 primary key(a,b,c)와 secondary Index(a,d)가 있는경우, 인덱스 내의 secondary key는 (a,d)가 되지만, PKV에는 (b,c)만 포함됨 sendary key fields는 clusterd key와 마찬가지로 단일 바이트 스트림으로 연결됨 clustered key 필드는 정확한 동일한 방식으로 함께 연결되어 PKV를 만듬 Secondary index의 non-leaf page는 PKV가 레코드에 포함되며, 이는 레코드 값이 아닌, 레코드 키의 일부로 간주됨 Secondary index는 고유하지 않을 수 있지만, \u001d페이지 내의 각 레코드는 unique 식별자가 필요함 그러므로 고유성을 보장하기 위해 PKV가 레코드에 포함되어 있어야함 즉, Secondary key의 non-leaf에 있는 레코드는 leaf 페이지의 레코드보다 4바이트 커짐 row당 오버헤드 위의 그림을 보면 InnoDB에 필요한 행당 오버헤드를 쉽게 계산할 수 있음\n\bclusterd key leaf에는 헤더에 최소 5바이트, 트랜잭션 ID에 6파인트, 롤포인터에 7바이트, row당 총 18바이트가 필요함\n매우 작은 테이블(2-3개의 정수컬럼을 가지는 테이블)의 경우 오버헤드가 상당히 높을 수 있음\n또한 페이지당 오버헤드가 상당하여, 비 효율적으로 페이지를 채우면 많은 야의 공간을 차지할 수 있음\nhttps://blog.jcole.us/2013/01/10/the-physical-structure-of-records-in-innodb/\n","date":"2024-05-22T22:43:24Z","permalink":"https://sungho94.me/p/5-physical-structure-of-records-in-innodb/","title":"5-physical structure of records in InnoDB"},{"content":"B+Tree, root, leaf, level 용어정리 B+Tree는 InnoDB 인덱스의 구조임\n데이터가 메모리 크기와 일치하지 않아, 디스크에서 읽어야하는 경우 효율적임\n트리의 깊이에 따라 요청된 데이터에 엑세스하는데 필요한 최대 읽기 횟수가 고정되어 있어 확장성이 뛰어남 인덱스 트리는 트리에 엑세스하기 위한 시작점으로 root 페이지에서 시작됨\nroot page는 InnoDB의 data dictionary에 영구적으로 저장되어 있음 트리는 단일 루트 페이지일만큼 작을 수 있고, multi-level tree의 수백만 페이지 일 수 있음 페이지를 leaf(internal)과 non-leaf(node)페이지로 구분함\nleaf 페이지에는 실제 행 데이터가 포함됨 non-leaf페이지는 다른 non-leaf페이지 또는 leaf 페이지를 가지고 있음 tree는 균형이 잡혀있고, 모든 가지의 깊이는 동일함 InnoDB는 트리의 각 페이지에 level을 할당함\n리프페이지에는 level 0을 할당하고, 트리 위로 올라갈수록 level이 증가함 root page의 level은 트리의 깊이와 같음 구분이 중요하지 않은 경우, leaf페이지와 non-leaf페이지는 둘다 internal페이지라고 부름 Leaf and non-leaf page leaf와 non-leaf페이지(Infimum과 supreme을 포함)는 next record의 오프셋을 저장한 \u0026ldquo;next record\u0026quot;포인터를 가지고 있음 이 연결은 infimum에서 시작하여 모든 레코드를 오름차순으로 연결되며, sumpemum에서 끝남 레코드는 물리적으로 정렬되어 있지 않고, 링크된 목록에서의 위치가 유일한 순서임 insert시 사용 가능한 공간이 있으면 insert됨\nleaf page의 구조로, 각 레코드의 데이터의 일부로 키가 아닌 값을 가지고 있음 non-leaf페이지는 동일한 구조를 가지지만, 데이터로 하위 페이지 번호를 가르키며, 정확한 키 대신 하위페이지의 가장 작은 키를 가짐 대부분의 인덱스는 2개 이상의 페이지로 구성되며, 여러 페이지가 오름차순 및 내림차순으로 링크되어 있음 각각의 페이지는 FIL헤더 안에 이전페이지와 다음 페이지를 가르키는 point를 가지고 있음 이로인해 INDEX 페이지들은 동일한 레벨에서 double linked list구조를 가짐 위 그림은 B+Tree내의 단일 index page임 실제로 살펴보기 실제로 그림에서 사용중인 테스트 테이블을 생성하고, 데이터를 삽입해보자! 1 2 3 4 5 6 7 8 CREATE TABLE t_btree ( i INT NOT NULL, s CHAR(10) NOT NULL, PRIMARY KEY(i) ) ENGINE=InnoDB; INSERT INTO t_btree (i, s) VALUES (0, \u0026#34;A\u0026#34;), (1, \u0026#34;B\u0026#34;), (2, \u0026#34;C\u0026#34;); 매우 작고 비현실적이지만, 레코드와 레코드 순회가 어떻게 이루어 지는지 알기 위해 적절한 테이블임 실제 기본 table space 파일 구조 확인 실제 테이블을 확인해보면, 이전에 보았던 테이블들과 같이 FSP_HDR, IBUF_BITMAP, INODE 페이지가 있고, 루트 인덱스가 있는 INDEX페이지, 아직 사용되지 않은 FREE 페이지 2개가 존재함 1 2 3 4 5 6 7 $ innodb_space -f t_btree.ibd space-page-type-regions start end count type 0 0 1 FSP_HDR 1 1 1 IBUF_BITMAP 2 2 1 INODE 3 3 1 INDEX 4 5 2 FREE (ALLOCATED) space-index-pages-summary 명령은 각 페이지에 레코드가 몇개 있는지 알려준다 3개가 있을것으로 예상함 1 2 3 4 5 $ innodb_space -f t_btree.ibd space-index-pages-summary page index level data free records 3 18 0 96 16156 3 4 0 0 0 16384 0 5 0 0 0 16384 0 실제 레코드 확인 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 $ innodb_space -f t_btree.ibd -r ./simple_t_btree_describer.rb -d SimpleTBTreeDescriber -p 3 page-dump {:format=\u0026gt;:compact, :offset=\u0026gt;125, :header=\u0026gt; {:next=\u0026gt;157, :type=\u0026gt;:conventional, :heap_number=\u0026gt;2, :n_owned=\u0026gt;0, :min_rec=\u0026gt;false, :deleted=\u0026gt;false, :field_nulls=\u0026gt;nil, :field_lengths=\u0026gt;[0, 0, 0, 0], :field_externs=\u0026gt;[false, false, false, false]}, :next=\u0026gt;157, :type=\u0026gt;:clustered, :key=\u0026gt;[{:name=\u0026gt;\u0026#34;i\u0026#34;, :type=\u0026gt;\u0026#34;INT\u0026#34;, :value=\u0026gt;0, :extern=\u0026gt;nil}], :transaction_id=\u0026gt;\u0026#34;0000000f4745\u0026#34;, :roll_pointer=\u0026gt; {:is_insert=\u0026gt;true, :rseg_id=\u0026gt;8, :undo_log=\u0026gt;{:page=\u0026gt;312, :offset=\u0026gt;272}}, :row=\u0026gt;[{:name=\u0026gt;\u0026#34;s\u0026#34;, :type=\u0026gt;\u0026#34;CHAR(10)\u0026#34;, :value=\u0026gt;\u0026#34;A\u0026#34;, :extern=\u0026gt;nil}]} :format 레코드가 Barracuda 포맷 테이블 내의 compact포맷인것을 의미 반대로 Antelope 테이블 내의 redundant가 있음 :key 인덱스의 키 필드 배열 :row 키가아닌 필드의 배열 :transaction_id and :roll_pointer 각 레코드에 포함된 MVCC를 위한 내부 필드 :header내의 :next 실제로는 상대저 오프셋(32)가 들어가며, 편의를 위해 계산된 오프셋이 표시됨 인덱스 재귀 index-recurse모드를 사용하면 전체 인덱스를 재귀하는 멋지고 간단한 출력을 얻을 수 있음 예시는 단일 페이지 인덱스이므로 매우 짧음 1 2 3 4 5 $ innodb_space -f t_btree.ibd -r ./simple_t_btree_describer.rb -d SimpleTBTreeDescriber -p 3 index-recurse ROOT NODE #3: 3 records, 96 bytes RECORD: (i=0) -\u0026gt; (s=A) RECORD: (i=1) -\u0026gt; (s=B) RECORD: (i=2) -\u0026gt; (s=C) 간단하지 않은 인덱스 트리 구축 multi level 인덱스는 위와같이 나타남 이전에 설명했듯이, 모든 페이지는 각각 doubly-linked 되어있고, 각 페이지 안의 레코드들은 오름차순으로 singly-linked되어있음 Non-leaf페이지는 실제 키보다는 자식의 페이지 넘버를 포함한 포인터를 가지고 있음 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 $ innodb_space -f t.ibd -r ./simple_t_describer.rb -d SimpleTDescriber -p 3 index-recurse ROOT NODE #3: 2 records, 26 bytes NODE POINTER RECORD \u0026gt;= (i=252) -\u0026gt; #36 INTERNAL NODE #36: 1117 records, 14521 bytes NODE POINTER RECORD \u0026gt;= (i=252) -\u0026gt; #4 LEAF NODE #4: 446 records, 9812 bytes RECORD: (i=1) -\u0026gt; () RECORD: (i=2) -\u0026gt; () RECORD: (i=3) -\u0026gt; () RECORD: (i=4) -\u0026gt; () \u0026lt;many lines omitted\u0026gt; NODE POINTER RECORD \u0026gt;= (i=447) -\u0026gt; #1676 LEAF NODE #1676: 444 records, 9768 bytes RECORD: (i=447) -\u0026gt; () RECORD: (i=448) -\u0026gt; () RECORD: (i=449) -\u0026gt; () RECORD: (i=450) -\u0026gt; () \u0026lt;many lines omitted\u0026gt; NODE POINTER RECORD \u0026gt;= (i=891) -\u0026gt; #771 LEAF NODE #771: 512 records, 11264 bytes RECORD: (i=891) -\u0026gt; () RECORD: (i=892) -\u0026gt; () RECORD: (i=893) -\u0026gt; () 10만개의 row를 가지는 간단한 테이블은 위와같은 구조리르 가짐 ROOT, INTERNAL, LEAF NODE를 가지고 있음 일부 페이지는 완전히 꽉차있으며, 468개의 레코드가 16KB페이지의 거의 15KB를 차지하고 있음을 알 수 있음 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ innodb_space -f t.ibd -r ./simple_t_describer.rb -d SimpleTDescriber -p 36 page-dump {:format=\u0026gt;:compact, :offset=\u0026gt;125, :header=\u0026gt; {:next=\u0026gt;11877, :type=\u0026gt;:node_pointer, :heap_number=\u0026gt;2, :n_owned=\u0026gt;0, :min_rec=\u0026gt;true, :deleted=\u0026gt;false, :field_nulls=\u0026gt;nil, :field_lengths=\u0026gt;[0], :field_externs=\u0026gt;[false]}, :next=\u0026gt;11877, :type=\u0026gt;:clustered, :key=\u0026gt;[{:name=\u0026gt;\u0026#34;i\u0026#34;, :type=\u0026gt;\u0026#34;INT UNSIGNED\u0026#34;, :value=\u0026gt;252, :extern=\u0026gt;nil}], :child_page_number=\u0026gt;4} 위는 non-leaf 페이지임 :key 배열이 나타나고, 정확한 키보다는 자식레코드의 최소키를 포함하고 있음 :row 필드가 없으며, child_page_number가 해당 필드를 대신함 특별한 root page 인덱스가 처음 생성될때 루트페이지가 할당되고, 해당 페이지 번호가 데이터 사전에 저장되므로 루트페이지는 절대 재배치하거나 제거할 수 없음 루트페이지가 가득 차면, 루트페이지와 두개의 리프 페이지로 구성된 작은 트리를 형성하여 분할해야함 하지만 루트 페이지 자체는 재배치 할 수 없으므로 분할할 수 없음 대신 새 빈페이지가 할당되고, 루트 레코드가 그 페이지르 이동되며(루트페이지가 한단계 상향됨) 새페이지가 두개로 분할됨 그러면 루트페이지는 바로 그 아래 레벨에 하위페이지(node pointer라 부름)로 가득 찰 때까지 다시 분할할 필요가 없으며, 실제로 수천개의 페이지가 될 수 있음 https://blog.jcole.us/2013/01/10/btree-index-structures-in-innodb/\n","date":"2024-05-20T23:10:14Z","permalink":"https://sungho94.me/p/4-b-tree-index-structure/","title":"4-B+tree index structure"},{"content":"Index 물리적인 인덱스 구조를 알기전, InnoDB에서 Index에 대해 중요하게 알아야하는 아래 3가지에 대해 알아야 함 모든 테이블은 primary key를 가지고 있다 \b테이블 생성시 primary key를 설정하지 않는다면, 먼저 non-NULL unique키를 사용하고, 없다면 48bit의 숨겨진 ROW id를 primary key로 사용함 row data(primary key가 아닌 필드)는 primary key 인덱스 구조 내에 저장됨 이를 clustered key라고 명함 인덱스 구조는 primary key필드에 키가 저장되며 row data는 해당 키에 연결된 값임(MVCC의 경우 추가적인 필드가 포함됨). Secondary key는 동일한 인덱스 구조에 저장되며, 키는 해당하는 Secondary key이며, 값은 primary임 Index page 구조 FIL header and trailer 모든 페이지 유형에 일반적이고 공통적임 다른 페이지 유형들과 다른점은, previous page와 next page 포인터가 인덱스 키를 기준으로 동일한 수준의 이전페이지와 다음페이지를 오름차순으로 가르킴 이로인해 모든 페이지가 이중으로 연결된 double-linked list가 형성됨 FSEG header 이전 글에서 보았던, index root page의 FSEG헤더에는 포함됨 해당 인덱스에서 사용하는 파일 세그먼트에 대한 포인터가 포함되어 있음 다른 index page는 FSEG header를 사용되지 않고 0으로 채워짐 INDEX header Index 페이지 관리와 record관리에 필요한 필드가 포함되어 있음 자세한 설명은 아래에 있음 System records 인덱스의 각 페이지에는 infimum과 supremum로 불리는 system record가 존재함 이러한 레코드들은 페이지의 고정된 장소에 저장되어, 패이지 내에서 바로 접근이 가능함 User records 실제 데이터임 각 레코드는 가변길이의 헤더와, 실제 데이터 컬럼을 가지고 있음 헤더에는 오름차순으로 정렬된 singly-linked list를 구현하기 위한 next record 포인터를 포함함 자세한 설명은 아래에 있음 The page directory FIL 트레일러에서 시작하여 페이지의 top에서 아래쪽으로 커지며(메모리 스택과 유사한 구조라고 생각됨), 페이지의 일부 레코드(4~8번째 레코드마다)에 대한 포인터를 포함함 INDEX Header Index ID 해당 페이지에 속해있는 index의 ID를 의미함 Format Flag 해당 페이지 안에있는 record들의 포맷을 의미함 Number of Heap Record필드의 상위비트(0x8000)비트에 저장됨 현재 COMPACT와 REDUNDANT가 가능함 뒤에 자세히 설명함 Number of Heap Records infimum과 supremum 시스템 레코드, 삭제된garbage records를 포함한 페이지 내의 총 레코드 수를 의미함 Heap Top Position 현재 사용된 공간의 마지막 바이트 오프셋을 가르킴 heap 상단과 page directory의 마지막의 모든 공간은 여유공간임 Garbage Space garbage 레코드안에 있는 삭제된 레코드가 소비한 총 바이트 수를 저장함 Last Insert Position 페이지 내의 마지막으로 추가된 레코드의 바이트 오프셋을 저장함 Page Direction 현재 LEFT, RIGHT, NO_DIRECTION 세가지 값이 사용됨 페이지가 순차적으로 insert되는지, 무작위로 insert되는지를 나타냄 각 insert시 마지막 insert위치의 레코드를 일고, 해당 키를 insert된 레코드 키와 비교하여 insert방향을 결정함 Number of Inserts in Page Direction 한번 페이지 방향이 설정된 후 방향을 바꾸지 않은 모든 다음 삽입은 이값을 증가시킴 한번 페이지 방향이 설정된 후에 같은 방향으로 insert된 레코들 수를 의미 Number of Directory Slots 페이지 디렉토리의 크기(16바이트 오프셋인 slot의 단위) Page Level index에서 해당 페이지의 level을 의미 Leaf 페이\u001f의 레벨은 0이고, B+트리를 따라 올라감 일반적으로 3레벨 B+트리에서 루트는 레벨2, internal non-leaf page중 일부가 level 1, leaf page는 level 0임 항후 게시글에서 추가로 설명함 Record format: REDUNDANT vs COMPACT COMPACT 레코드 형식은, Barracuda테이블의 새로운 형식이고, REDUNDANT레코드 형식은 Antelope테이블의 기존 형식임 둘다 Barracuda가 만들어질때까지, 공식적인 이름이 없었음 COMPACT형식은 각 레코드에 중복 저장되어 data dictionary에 있는 정보(필드수, nullable한 필드, 동적 길이 필드)를 대부부분 제거함 record pointer에 대한 추가설명 record pointer는 INDEX Header안에 있는 Last Insert Position field, System record와 user record의 next pointer, page directory안에 있는 모든값 등 여러 다른 위치에서 사용됨 모든 레코드는 헤더(가변 길이 일수 있는)와 실제 레코드 데이터(가변 길이 일수 있는)를 포함함 record pointer는 레코드 데이터의 첫번째 바이트 위치를 가르키며, 실제로는 header와 record 데이터 사이에 위치함 이를 통해 역방향으로 헤더를 읽고, 정방향으로 레코드 데이터를 읽음 시스템 및 사용자 필드에서 next record pointer를 항상 레코드의 첫번째 필드임 이로인해, 항상 가변 width레코드 데이터를 파싱할 필요없이 페이지의 모든 레코드를 매우 효율적으로 읽을 수 있음 System records: infimum and supremum 모든 INDEX 페이지는 고정된 위치에 infimum과 supremum이라는 시스템 레코드가 포함함\n두 시스템 레코드는 일반적인 헤더를 가지며, infimum과 supremum이 유일한 데이터임 데이터를 가지고있는 필드 바로 앞은 다음 레코드 포인터임 infimum record infimum record는 페이지에서 모든 키보다 낮은 값을 나타냄 \u0026ldquo;next record\u0026quot;포인터는 가장 낮은 키를 가진 사용자 레코드를 가르킴 infimum은 사용자 레코드를 순차적으로 스캔하기 위한 고정된 진입점 역할을 함 supremum supremum레코드는 페이지에서 가장 높은 키를 나타냄 \u0026ldquo;next record\u0026quot;포인터는 항상 0임 페이지 헤도로 인해 실제 레코드에 대해서는 항상 NUMM을 나타내며, 위효화지 않은 위치임 페이지에서 가장 높은 키를 가진 사용자레코드의 \u0026ldquo;next record\u0026quot;포인터는 항상 supremum레코드를 가르킴 User records user record의 길고 복잡하기에 자세한 설명은 다음 게시글에서 다룸\n사용자 레코드는 삽입된 순서대로 page body에 추가되며, 각 레코드 헤더의 \u0026ldquo;next record\u0026quot;포인터를 사용하여 키별로 오름차순으로 단일 링크됨\n이전에 삭제된 리코드에서 기존 여유공간을 차지 가능 단일 링크된 목록은 infimum record부터 오름차순으로 모든 사용자 레코드를 거쳐 supremum으로 끝남\n이 list를 사용하면 한페이지의 모든 사용자 레코드를 오름차순으로 스캔하는 것은 간단함\n또한 FIL헤더의 \u0026ldquo;next page\u0026quot;포인터를 사용하면 전체 인덱스를 오름차순으로 한페이지에서 다른 페이지로 쉽게 스캔 가능\nFIL헤더로 인해 오름차순 테이블 스캔도 간단히 구현 가능 인덱스 안의 첫번째 page에서 시작 이 페이지는 B+트리 탐색을 통해 찾을 수 있음(향후 게시글에서 설명) infimum record를 읽고, next record 포인터를 따라감 record가 supremum이라면 step 5로 이동하고, 아니라면 레코드 내용을 읽고 처리함 \u0026ldquo;next record\u0026quot;포인터를 따라가 step 3으로 돌아감 \u0026ldquo;next page\u0026rdquo; 포인터가 NULL을 가르키면 종료하고 아니라면 \u0026ldquo;next page\u0026quot;포인터를 따라 step 2로 돌아감 *레코드가 doubly-linked가 아닌 singly-linked이므로 내림차순 탐색은 쉽지 않음\nPage directory page directory는 FIL trailer에서 시작하여 user record방향으로 커짐 page directory는 4-8개의 레코드 포인터를 가지고 있으며, infimum과 supremum값을 포함함 page directory는 단순히 페이지 레코드에 대한 16비트 오프센 포인터인 동적 크기 배열(dynamically-sized array)임 향후 게시물에 자세하게 설명할 예정 Free space user record(위쪽으로 증가함)와 page directory(아래로 증가함) 사이의 공간을 free space로 간주함 두 섹션이 중간에 만나서 여유공간이 소진되면 페이지가 가득 찬것으로 간주함 garbage를 제거하기 위한 re-organizing으로 공간을 확보할 수 없을때도 가득 찬것으로 간주함 https://blog.jcole.us/2013/01/07/the-physical-structure-of-innodb-index-pages/\n","date":"2024-05-19T22:44:51Z","permalink":"https://sungho94.me/p/3-innodb-index/","title":"3-InnoDB Index"},{"content":"Extent 64개의 연속된 페이지인 1MiB블록 space에서 페이지를 관리하려면 복잡하기에, 중간에 Extent를 두어 space는 Extent를 관리하고, Extent에서 page를 관리 Innodb는 FSD_HDR과 XDES페이지를 고정된 위치에 두어 extent가 사용중인지, extent내의 사용중인 페이지를 추적함 FSP_HDR/XDES 구조 요약 FIL Header와 trailer, FSP Header와 256개의 extent discriptors(EHSMS descriptors)가 포함됨 많은 양의 미사용공간도 포함됨 아래에 더 자세한 설명 있음 Extent decriptor File Segment ID extent가 파일 세그먼트에 속할시, extent가 속한 파일 세그먼트 id List node for XDES list double linked extent descriptor 목록의 이전 및 다음 extent를 가르키는 포인터 State extent의 현재 상태를 나타냄(4가지 상태가 있음) 해당 extent가 동일한 space목록에 속하는 FREE, FREE_FRAG, FULL_FRAG 상태 아래에서 자세한 설명 해당 extent가 파일 세그먼트 ID필드에 저장된 ID를 가진 파일 세그먼트에 속함을 의미하는 FSEG상태 Page State Bitmap 2개의 비트로 페이지가 free한지, clean 한지 나타냄 첫번빼 비트는 페이지가 free한지 여부 두번째 비트는 clean한지 여부 현재 사용되지 않는다면 1로 할당됨 extent를 참조하는 다른 구조에서는 extent\u0026rsquo;s descriptor가 있는 FSP_HDR 또는 XDES 페이지 번호와, descriptor entry가 존재하는 페이지의 byte offset을 조합하여 위치를 나타냄 page 0 offset 150은 첫번째 페이지에서 150번째 오프셋의 XDES Entry를 참조 0-63페이지를 가지고 있는 XDES Entry임 page 16384 offset 270은 16384페이지에서 270번째 오프셋의 XDES Entry를 참조 16576-16639페이지를 가지고 있는 XDES Entry임 page 16384는 실제로 첫 번째 XDES 페이지를 의미함 List - free list List는 여러 관련 구조를 함께 연결할 수 있는 일반적인 구조체 2개의 상호보완적인 구조를 사용해서, 디스크상의 이중 링크드 리스트를 구현함 List base node 하이레벨구조(FSP헤더와 같은)에서 한번만 저장됨 리스트의 길이 및 리스트의 처음과 마지막 리스트 노드의 정보를 포함함 List Node 이전과 다음 노드에 대한 포인터를 저장함 모든 포인터는 페이지 번호(같은 space내에 있는)와 리스트 노드를 찾을 수 있는 해당 페이지 내의 byte offset으로 구성됨 모든 포인터는 리스트 노드의 시작을 가르킴 반드시 서로 연결된 구조는 아님 FSP Header 상세 \bSpace ID 현재 space의 ID Highest page number in the space (size) 파일이 커짐에 따라, 증가되는 유효한 최대 페이지 수 space확장은 여러 단계에 걸쳐 이루어지므로, 모든 페이지가 초기화 되지 않음(일부는 0으로 채워질 수 있음) Highest page number initialized (free limit) FIL헤더가 초기화된 가장 높은 페이지 번호로, 페이지자체에 페이지 번호를 저장함 free lmit은 항상 이 크기보다 작거나 같음 Flags space와 연관된 플래그 Next Unused Segment ID 다음에 할당될 파일 세그먼트에 사용될 파일 세그먼트 ID Number of pages used in the FREE_FRAG list 목록의 모든 extents를 순회하지 않고 FREE_FRAG갯수를 확인할 수 있게하기 위한 필드 다음 extent descriptor list의 List base node도 저장됨 FREE_FRAG 여유페이지가 남아있는 extent를 나타냄 여유 페이지가 있는 extent는 개별 페이지를 다른 용도로 사용 가능함 예를들어, FSP_HDR 이나 XDES 페이지가 있는 모든 extent는 FREE_FRAG 목록에 배치뒤어 남은 free page를 다른 용도로 할당할 수 있음 FULL_FRAG FREE_FRAG와 똑같지만, 여유페이지가 없는 extent를 나타냄 extent가 가득차면 FULL_FRAG로 이동되며, 페이지가 해제되어 가득차 있지 않으면 FREE_FRAG로 이동됨 FREE 완전히 사용되지 않고, 특정 용도로 전체 할당할 수 있는 extent를 의미함 FREE extent는 파일세그먼트(적절한 INODE 목록에 배치되기 위해)에 할당되거나, 개별 페이지 사용을 위해 FREE_FRAG목록이로 이동될 수 있음 file segment, INODE InnoDB는 파일시스템에서 사용하는 file segment, INODE를 오버로드해서 사용함 InnoDB는 inode를 다음 2가지 유형에 사용함 INODE entires(하나의 작은 구조) INODE pages(많은 INODE 항목을 포함하는 페이지 유형) InnoDB의 INODE는 단순히 file segment(FSEG)를 설명할 뿐이며, 앞으로 \u0026ldquo;file segment INODE\u0026quot;라 칭함 INODE pages 각각의 INODE page는 85개의 file segment INODE entries(총 16KiB page)를 포함함 각각의 INODE page는 192바이트임 INODE page는 FSP_HDR의 FSP 헤더 구조에서 설명했던 List node가 있음 해당 List node는 INODE pages를 위한 것, 해당 INODE page의 INODE가 아님! FREE_INODES 적어도 하나의 free file segment INODE entry가 있는 INODE pages의 리스트 FULL_INODES free file segment INODE entry가 하나도 없는 INODE pages의 리스트 file per table space를 사용하는 경우, 테이블에 42개 이상의 인덱스가 없는 한 각 file per table space 안에 있는 해당 목록은 비어있음 각각의 index는 정확히 두개의 file segment INODE entry를 사용하기 때문 INODE ENTRY 필드 설명 File Segment ID file segment ID는 해당 file segment INODE entry를 의미함 ID가 0이면 해당 entry는 사용되지 않은 것을 의미 Magic Number 값이 97937874이면 file segment INODE entry가 초기화 되었다는 것을 의미 Number of used pages in the NOT_FULL list space의 FREE_FLAG list(FSP header에 있는)와 정확히 같음 NOT_FULL 리스트 수 빠르게 확인할 수 있게 하기 위한 필드 Fragment Array space에 있는 FREE_FRAG 또는 FULL_FRAG 리스트(\u0026ldquo;fragment\u0026quot;의 extent) 안의 extent로부터 개별적으로 할당된 32페이지의 배열 해당 array가 꽉 차면, 오직 full extents만 file segment에 할당될 수 있음 table이 커지면 각 file segment는 배열이 가득 찰때까지, 각 file segment에 개별 pages들을 할당하고, 이후 1개의 extent를 할당함, 결국에는 4개의 extent가 할당됨 extent descriptors의 list base node또한 각각의 file segment INODE entry에 나타남 FREE 완전히 사용되지 않고, 해당 file segment에 할당된 extents NOT_FULL 해당 file segment에 할당된 사용된 페이지가 하나 이상 있는 extents 마지막 사용가능한 페이지가 사용되면, extents는 FULL list로 이동함 FULL 해당 file segment에 할당된 사용가능한 페이지가 없는 extent 페이지가 여유가 생기면, NOT_FULL 목록이도 이동함 마지막으로 사용된 page가 NOT_FULL 목록의 범위에서 해제되면, 해당 extent는 file segment\u0026rsquo;s의 FREE로 이동될 수 있지만, 실제로는 space\b의 FREE list로 이동됨 Index는 어떻게 file segments를 사용할까 인덱스 페이지에 대한 설명은 없지만, 한가지 작은 측면을 살펴볼 수 있음 각 인덱스의 FSEG의 루트페이지는 인덱스에서 사용하는 파일 세그먼트를 설명하는 file segment INODE entry에 대한 포인터가 포함되어 있음 각 인덱스는 leaf페이지에 하나의 세그먼트와, non-leaf페이지에 하나의 파일 세그먼트를 사용함 이 정보는 FSEG header 구조에 저장되어 있음\nspace ID는 불필요한 것으로, 항상 현재 sapce와 동일함 page number와 offset은 file segment INODE entry를 가르킴 두 파일 세그먼트는 완전히 비어있어도 항상 존재함 예를 들면 새로 만든 테이블에서 존재하는 페이지는 루트페이지이며 리프페이지 이기도 하지만, internal file segment에 존재하므로 나중에 옮길 필요가 없음 leaf file segment의INODE list와 fragment는 모두 비어있음 internal file segment INODE list는 모두 비어있고, 단일 루트 페이지는 fragment array에 있음 인덱스에 대한 전체 multi level index root pages는 두개의 inodes(file segment)를 가르키며, 각각은 fragment array(fragment list에서 최대 32개의 개별 페이지를 가르킴)전체 extents 목록(extent descriptor의 리스트 포인터를 사용하여 연결된)을 가짐 extent descriptor는 extent를 참조할 뿐 아니라, extent내 free page를 추적하는 데도 사용됨 참고\nhttps://blog.jcole.us/2013/01/04/page-management-in-innodb-space-files/\nhttps://dev.mysql.com/blog-archive/innodb-tablespace-space-management/\nhttps://dev.mysql.com/blog-archive/extent-descriptor-page-of-innodb/\n","date":"2024-05-12T17:45:54Z","permalink":"https://sungho94.me/p/2-page-management-in-innodb-space-files/","title":"2-Page management in Innodb space files"},{"content":"Page 각 스페이스는 16KiB의 페이지로 나누어짐 UNIV_PAGE_SIZE를 변경하거나, InnoDB 압축을 사용하는경우 변경 가능 오프셋 이라고하는 32bit 정수 페이지 번호가 할당됨 파일의 시작부분부터 해당 페이지 위치까지의 실제 오프셋임 페이지 0은 파일 오프셋 0, 페이지1은 오프셋은 16384(16*1024)임 페이지 구조 각 페이지는 38바이트의 FIL(file의 줄임말) header와 FIL Trailer를 가지고 있음 헤더에는 페이지의 남은 부분을 결정하는 page type 필드를 포함하고 있음 FIL Header / Trailer page type은 페이지의 다른 부분을 파싱하기 위해 필수적인 부분임 page type은 file space management, extent management, the transaction system, the data dictionary, undo logs, blobs, indexes가 할당될 수 있음 페이지는 앞서 나열한 페이지가 될 수 있다는것을 의미함 페이지가 초기화 될때, page number(Offset)이 할당됨 해당 필드에서 읽은 페이지번호가 파일에 오프셋을 기준으로 해야하는 페이지 번호가 일치하는지 확인하여, 읽기가 올바른지 확인함 이 필드가 초기화되면 페이자가 초기화되었다는 것을 의미함 해당 페이지의 유형과 같은 이전 페이지와 다음페이지 포인터가 헤더가 저장되어 있음 이 필드들로 페이지를 double-linked list \b구조가 됨 인덱스 페이지를 동일한 수순으로 연결하는데 사용되므로 전체 인덱스 스캔을 효율적으로 수행할 수 있음 대부분의 페이지 유형은 이 필드들을 사용하지 않음 Space - tablespace 각 테이블당 하나의 space가 존재 하나의 스페이스는 .idb파일로 구성됨 하나 이상의 idb파일로 구현 될 수 있음 물리적으로 하나 이상의 파일이지만, 논리적으로 단일파일 취급함 .idb파일은 하나의 테이블에 대한 정보가 들어감 하나의 .idb파일에 여러 테이블이 들어갈 수 있는 구조지만, 하나의 테이블만 넣음 space별로 32bit 정수인 space ID가 할당됨 해당 space를 참조할 목적 InnoDB는 InnoDB에서 필요로 하는 장부(book-keeping)를 작성하기 위해 system space를 가지고 있음 system space의 space ID는 0임 많은 페이지가 연결된것 효율적으로 페이지를 관리하기 위헤 1MiB 블록 단위로 페이지를 관리함 이를 extent라 부름 파티션을 나누면 각각의 space가 나누어짐 Space File 구조 Innodb는 모든 page, extent, space를 추적-관리하기 해야하므로 위와같은 구조를 가짐 space의 첫번째 페이지(page 0)은 항상 FSP_HDR 또는 file space header 페이지임 FSP_HDR페이지는 space의 크기, free, fragmented, full extents의 목록을 추적할 수 있는 FSP header 구조를 포함하고 있음 FSP_HDR페이지는 내부적으로 256 extents(또는 16384페이지, 256MiB)에 대한 정보를 저장 가능함 그러므로 256extents마다 XDES정보를 저장하기 위해 공간을 미리 예약해놓음 XDES와 FSP_HDR페이지는 XDES에서 FSP해더\u001e 구조가 0으로 처리된다는 점을 제외하면 동일함 추가페이지는 스페이스 파일이 커짐에 따라 할당됨 두번째\u001e페이지인 IBUF_BITMAP페이지는 insert buffering과 관련된 정보를 저장함(이 글의 범위를 벗어나는 부분이라 더 이상 언급하지 않음) 세번째 페이지인 INODE페이지는 파일 세그먼트와 관련된 목록을 저장하는데 사용됨 각 INODE페이지에는 85개의 INODE항목을 저장할 수 있으며, 각 인덱스에는 2개의 INODE항목이 필요함 System space InnoDB에는 space ID가 0인 system space가 존재함 InnoDB의 작동에 중요한 정보를 저장하기 위해 고정 페이지 번호로 할당된 페이지가 포함되어 있음 다른공간과 마찬가지로 FSP_HDR, IBUF_BITMAP, INODE페이지가 처음 3페이지로 할당되어 있음 3번째 SYS페이지에는 insert buffering에 관련된 헤더와 부기정보가 있음 4번째 INDEX페이지에는 insert buffering에 관련된 index구조의 루트 페이지가 존재 5번째 TRX_SYS페이지에는 InnodDB의 트랜잭션 시스템의 동작과 관련된 정보가 존재함 최신 transaction ID, Mysql binary log정보, double write buffer extents의 위치 등 6번째 SYS페이지에는 첫번째 롤백 segment page정보가 있음 rollback segment data의 저장이 필요하다면, 추가적인 페이지가 할당될 수 있음 7번째 SYS페이지에는 data dictionary와 관련된 헤더가 있음 data dictionary를 구성하는 인덱스의 루트 페이지 번호를 포함함 루트 페이지 번호가 data dictionary 자체에 저장되므로,\b다른 인덱스를 찾기 위해 필요함 64-127번째 페이지에는 double write buffer에 저장됨 128-192번째 페이지에는 두번째 double write buffer\u001c IBD 파일 구조 런타임에 인덱스를 생성\u001d하는 fast index creation을 제외하고, 필수 초기 3페이지 이후 공간에 할당된 페이지들은 테이블 생성에 정의된 순서대로 테이블에 있는 각 인덱스 루트 페이지가 됨 3번째 페이지는 clustered index의 루트페이지, 4번째 페이지는 첫번째 secondary index의 루트페이지임 InnoDB의 부기 구조는 대부분 시스템 공간에 저장되므로, 테이블별 공간에 할당된 대부분의 페이지는 INDEX유형이며, 테이블 데이터를 저장함 참고\nhttps://blog.jcole.us/2013/01/03/the-basics-of-innodb-space-file-layout/\n","date":"2024-05-10T22:40:29Z","permalink":"https://sungho94.me/p/1-page-space-idb-file-structure/","title":"1-page, space, idb file structure"},{"content":" 다수의 엘리먼트가 있을때, 지역성을 가질 수 있는 자료구조 한번읽고, 다음걸 읽을때 빠르게 찾아갈 수 있기 때문 특징 모든 데이터는 leaf노드에 있음 non-leaf노드에는 키만 존재 root노드에서 모든 leaf노드까지는 같음 만약, 노드에서 n개의 자식을 가지고 있으면, 이 노드는 n-1개의 키를 가지고 있음 루트노드를 제외한 모든 노드는 절반이상 차있음 하위노드의 모든 값은, 해당 부모 노드의 양쪽 포인터 값 사이에 있는 키를 가짐 루트노드가 leaf노드가 아닌경우, 적어도 2개의 자식을 가지고 있음 리프노드의 탐색시간은 O(logN)임 예제 아래 예제는 branch factor가 5인 B-tree임 branching factor가 5이기에, 리프가 아닌 노드들은 5개의 addr값을 가지고 있음\nkey29에 있는 값을 찾는 순서 먼저 루트노드에서 10과 50사이의 주소를 찾음 1에서 얻은 주소를 따라가, 25와 37사이의 주소를 얻음 2에서 얻은 주소를 따라가 28과 31사이의 주소를 얻고, 해당 주소에서 값을 찾음 삽입과정(tree가 자라나는 과정) key 16에 값을 넣는 과정임 key 16을 넣으려니, 리프노드에는 5개의 값이 꽉 차있어 분리가 필요함 부모의 노드가 여유가 있어, 부모트리를 나누어 1개의 leaf노드를 2개의 leaf노드로 분리함 이후 key 16에 데이터를 추가함 https://www.cs.cornell.edu/courses/cs3110/2012sp/recitations/rec25-B-trees/rec25.html\nhttps://www.linkedin.com/pulse/data-structures-powering-our-database-part-3-b-trees-saurav-prateek/\n","date":"2024-05-08T22:34:01Z","permalink":"https://sungho94.me/p/b-tree/","title":"B-tree"},{"content":" Extra 열에는 Mysql에서 쿼리를 resolve하기 위한 추가적인 정보가 들어감 여기서는 추가적인 정보 중 유용하다고 생각되는 정보를 정리할 예정 전체 정보는 다음 [링크]를 참고할것 Using file sort 정렬된 순서로 행을 찾기 위해 추가적인 작업이 필요하다는 것을 의미함 정렬은 조인 유형에 따라 모든 행을 살펴보고, Where 절과 일치하는 모든 행에 대해 정렬키와 포인터를 저장하는 방식으로 수행됨 이후 키가 정렬되고 정렬된 순서대로 행을 검색함 부하가 많이 걸리는 부분으로 개선이 필요함 Using index 커버링 인덱스가 사용되었음을 의미함 실제 테이블데이터를 읽지 않고, 인덱스만 조회함 쿼리가 하나의 인덱스에서 조회에 필요한 모든 데이터를 가지고 있을 경우 사용됨 Using index condition 인덱스를 먼저 읽은 후 필요할 경우 테이블 데이터를 읽음 테이블 데이터를 필요할때 까지 읽는것을 미룸 링크참고 Using index for group-by Using index와 유사하게, 실제 테이블데이터를 읽지않고 인덱스에서 group by 또는 distinct에 필요한 모든 열을 찾았음을 의미 그룹바이 최적화참고 Using join buffer (Block Nested Loop), Using join buffer (Batched Key Access), Using join buffer (hash join) 이전 조인 테이블을 버퍼에서 부분적으로 읽은 후 버퍼데이터와 해당 테이블의 조인을 실행함 각 buffer는 괄호안의 알고리즘을 사용함 Using temporary 해당 쿼리를 수행하기 위해서 임시 테이블이 사용됨을 의미 주로 GROUP by나 order by를 사용하는 쿼리에서 보여짐 Using where where절을 사용하여 행을 제한한것을 의미함 모든 행을 가져오는 경우가 아니라면, using where이 사용되지 않으면서 join type이 ALL이나 index이면 쿼리에 문제가 있는 것일 수 있음 Using index for skip scan 1 2 3 4 5 6 7 8 9 10 11 CREATE TABLE t1 (f1 INT NOT NULL, f2 INT NOT NULL, PRIMARY KEY(f1, f2)); INSERT INTO t1 VALUES (1,1), (1,2), (1,3), (1,4), (1,5), (2,1), (2,2), (2,3), (2,4), (2,5); INSERT INTO t1 SELECT f1, f2 + 5 FROM t1; INSERT INTO t1 SELECT f1, f2 + 10 FROM t1; INSERT INTO t1 SELECT f1, f2 + 20 FROM t1; INSERT INTO t1 SELECT f1, f2 + 40 FROM t1; ANALYZE TABLE t1; EXPLAIN SELECT f1, f2 FROM t1 WHERE f2 \u0026gt; 40; 11번 라인의 쿼리문이 실행되면 Using index for skip scan이 적용됨 11번 라인의 쿼리는 인덱스가 f1, f2가 걸려있는데, f2만 사용해서 조건을 걸었음 f1만을 사용하거나, f1, f2를 사용하면 Using Index로 나타남 11번 쿼리는 f1의 인덱스는 뛰어넘고, f2 인덱스 만 사용해서 결과를 가져옴 f1의 인덱스에서 고유값을 찾고, 고유값마다 f2의 인덱스에 걸린 조건을 찾아 결과를 가져옴 단일 인덱스에 대한 여러 개별 검색이 이루어지고, 결합시 접두사 열의 영향이 제거됨 Using join buffer(Block Nested Loop, hash join) ","date":"2024-05-03T23:35:47Z","permalink":"https://sungho94.me/p/mysql-explain-planextra-information-3/","title":"Mysql Explain Plan(Extra Information) - 3"},{"content":"조인타입 먼저에 나올수록 성능이 좋음\nsystem\n테이블이 하나의 row만 가지고 있을때 표시됨 const join타입의 특별한 케이스임 const\n쿼리시작시 결과가 오직 하나일때 표시됨 결과가 하나의 row일 경우, 컬럼의 값은 옵티마이저에 의해 상수로 처리됨 const 테이블은 오직 한번만 읽기에 매우 빠름 기본키 또는 UNIQUE 인덱스의 모든 부분을 상수값과 비교될때 표시됨 예제 쿼리 1 2 SELECT * FROM _tbl_name_ WHERE _primary_key_=1; SELECT * FROM _tbl_name_ WHERE _primary_key_part1_=1 AND _primary_key_part2_=2; eq_ref const와 system을 제외하고는 가장 최상의 join 이전 테이블에서 가져온 행 조합마다 해당 테이블에서 정확히 한 행을 읽음 인덱스의 모든 부분이 join에 사용되며, 인덱스가 기본키 또는 유니크키+not null조합이면서 =를 사용하여 비교될때 사용됨 비교하는 값은 상수이거나, 이전에 읽은 테이블의 컬럼 사용 예제쿼리 1 2 3 SELECT * FROM _ref_table_,_other_table_ WHERE _ref_table_._key_column_=_other_table_._column_; SELECT * FROM _ref_table_,_other_table_ WHERE _ref_table_._key_column_part1_=_other_table_._column_ AND _ref_table_._key_column_part2_=1; ref 이전 테이블에 가져온 행 조합마다\b일치하는 모든 인덱스를 읽음 키의 접두사만 읽거나, 키가 기본키나 유니크키가 아닐 경우 사용됨 정확히 하나의 row를 반환하지 않는 경유를 의미 키에 해당하는 행이 적은경우, 충분히 좋은 join 방법임 =이거나 \u0026lt;=\u0026gt;일때 사용됨 예제쿼리 1 2 3 4 SELECT * FROM _ref_table_ WHERE _key_column_=_expr_; SELECT * FROM _ref_table_,_other_table_ WHERE _ref_table_._key_column_=_other_table_._column_; SELECT * FROM _ref_table_,_other_table_ WHERE _ref_table_._key_column_part1_=_other_table_._column_ AND _ref_table_._key_column_part2_=1; fulltext\nFULLTEXT인덱스를 사용할때 사용됨 ref_or_null\nref와 유사하지만, null을 포함하는 행의 질의를 할때 사용됨 subquery를 \b처리할때 자주 표시됨 예제쿼리 1 SELECT * FROM _ref_table_ WHERE _key_column_=_expr_ OR _key_column_ IS NULL; index_merge\n인덱스 병합 최적화일때 사용됨 이 경우 Explain의 key column에는 사용된 인덱스 목록이 포함되며, key_len에는 가장 긴 인덱스의 키 목록이 표함됨 링크참고 unique_subquery\nIN절 내의 eq_ref 서브쿼리의를 대체\u001c함 효율성을 높이기 위해 서브쿼리를 대체하여 인덱스만 조회함 예제쿼리 1 value IN (SELECT primary_key FROM single_table WHERE some_expr) index_subquery unique_subquery와 유사하지만, non-unique 서브쿼리일때 사용됨 예제쿼리 1 value IN (SELECT key_column FROM single_table WHERE some_expr) range 인덱스로 범위질의를 사용시 사용됨 =, \u0026lt;\u0026gt;, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, IS NULL, \u0026lt;=\u0026gt;, BETWEEN, LIKE, IN() 연산자를 사용하여 상수 값과 비교할때 나타남 key_len에는 사용된 키 중 가장 긴키의 길이를 표시함 예제쿼리 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 SELECT * FROM tbl_name WHERE key_column = 10; SELECT * FROM tbl_name WHERE key_column BETWEEN 10 and 20; SELECT * FROM tbl_name WHERE key_column IN (10,20,30); SELECT * FROM tbl_name WHERE key_part1 = 10 AND key_part2 IN (10,20,30); ``` - index - 인덱스 트리가 스캔되는 것을 제외하면, ALL과 동일함 - 아래 두가지 경우에 나타남 - 인덱스 쿼리가 커버링 인덱스이고, 테이블에서 필요한 모든 데이터를 인덱스에서 가져올 수 있는 경우, 인덱스 트리만 스캔함 - Extra column에 Using Index라고 나타남 - index Only 스캔은 인덱스만 스캔하므로, 모든 테이블 데이터를 스캔하는 ALL보다 항상 빠름 - 인덱스를 사용하여 모든 테이블 데이터를 인덱스 순서대로 접근하는 경우 - Extra column에 Using Index라고 나타나지 않음 - 쿼리가 단일 인덱스의 일부 열만 사용하는 경우 이 조인 유형이 나타남 - ALL - 이전의 모든 테이블 행 조합마다 테이블 전체 테이블을 스캔함 - 거의 모든 경우 좋지않음 - index를 추가하여 피할 수 있음 ","date":"2024-05-03T23:34:03Z","permalink":"https://sungho94.me/p/mysql-explain-plan%EC%A1%B0%EC%9D%B8%ED%83%80%EC%9E%85-2/","title":"Mysql Explain Plan(조인타입) - 2"},{"content":" named lock\nmysql, redis 등 named lock을 지원하는 저장소에서 사용가능\nredis서버가 없는 상황에서 mysql named lock도 유용한 선택지임\nmysql은 connection 끊기면 lock도 풀림\n분산락은 자원에대한 락이 아닌 작업,행위에 대한 락\n하나의 작업이 한번만 실행되게 할때 유용함\n따닥 방지 데이터베이스에 부하가 가지않음\nbut, 실제로 작업하는 row가 db lock이 걸려있을시 처리 실제로 사용하기 위해 멱등성 보장이 필요할 수 있음\nhttps://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html ","date":"2024-05-02T22:41:32Z","permalink":"https://sungho94.me/p/11-%EB%B6%84%EC%82%B0%EB%9D%BDdistributed-lock/","title":"11-분산락(Distributed lock)"},{"content":"개요 Explain 문은 Mysql이 어떻게 statements를 실행할것인가에 대한 정보를 제공 select, delete, insert, replace, update문에 적용 가능 출력에 테이블이 나열되는 순서는, Mysql이 statements를 처리하는 동안 테이블을 읽는 순서임 첫번째 테이블에서 행을 읽고, 두번째테이블에서 일치하는 행을 찾고, 세번째에서 또 찾는 방식임 모든 테이블이 처리되면 Mysql은 선택한 열을 출력하고, 더 많은 행을 찾기 찾을 때 까지 테이블 목록을 역추적함 Explain Output Columns Column JSON Name Meaning id select_id Select 식별자 select_type None Select Type table table_name 결과 행을 가져오는 테이블 partitions partitions 매칭되는 파티션 type access_type join 유형 possible_keys possible_keys 선택될 수 있는 인덱스 key key 실제로 선택된 인덱스 key_len key_length 선택된 키의 길이 ref ref 인덱스와 비교한 열 rows rows 예상되는 행의 추정치 filtered filtered 테이블 조건에 따라 필터링된 행의 비율 Extra None 추가정보 id Select의 식별자로, 쿼리 내 Select의 일련 번호 다른행 의 유니온 결과를 참조하는 경우 Null일수 있음 이 경우 table Column은 \u0026lt;union M,N\u0026gt; 으로 나타남 select_type Select의 유형으로 다음 표에 나타나는 것중 하나가 들어감 select_type JSON Name Meaning SIMPLE None 서브쿼리나 Union을 사용하지 않은 간단한 Select PRIMARY None 가장 바깥쪽의 SELECT UNION None UNION으로 결합하는 첫번째를 제외한 두번째 이후의 쿼리 DEPENDENT UNION dependent (true) UNION으로 결합하는 첫번째를 제외한 두번째 이후의 쿼리이지만 외부 쿼리의 영향을 받는 Select UNION RESULT union_result UNION의 결과일때 SUBQUERY None Subquery의 첫번째 결과, From절 이외에서 사용되는 서브쿼리 DEPENDENT SUBQUERY dependent (true) 외부 쿼리에 의존하는 Subquery의 첫번째 결과,\nFrom절 이외에서 사용되는 서브쿼리 DERIVED None Select쿼리의 실행결과로 메모리나 디스크에 임시 저장되는 정보 DEPENDENT DERIVED dependent (true) 다른 테이블에 의존하고 있는 DERIVED 테이블 MATERIALIZED materialized_from_subquery 서브쿼리의 내용을 임시테이블로 구체화 할때 사용 UNCACHEABLE SUBQUERY cacheable (false) 결과를 캐시할 수 없고, 외부 쿼리의 각 row에 대해 재평가가 필요한 데이터에 일때 표시됨 UNCACHEABLE UNION cacheable (false) 캐시를 할 수 없는 서브쿼리를 포함하는, 첫번째를 제외한 두번째 이후의 UNION select일 경우 표시됨 select쿼리가 아닌 CUD쿼리는 해당 statements의 종류가 표시됨 DELETE일 경우, select_type에는 DELETE를 표시 table 각 행의 결과를 가져오는 테이블의 이름 \u0026lt;unionM,N\u0026gt; id(Explain의 id 컬럼)가 M과 N인 행의 UNION결과를 나타냄 \u0026lt;derivedN\u0026gt; id(Explain의 id 컬럼)가 N인 쿼리의 결과로 파생된 행 derived테이블은 FROM에 있는 서브쿼리의 결과임 \u0026lt;subqueryN\u0026gt; id(Explain의 id 컬럼)가 N인 행에 대한 구체화된 subquery의 결과를 나타냄 subquery mareirialzied 최적화 링크 partitions 쿼리에 의해 매치된 파티션을 나타냄 파티션이 없는 테이블은 NULL로 표시됨 type(join 유형) join type을 나타냄 possible_keys MySQL이 해당 테이블에서 데이터를 찾기위해 선택할 수 있는 인덱스를 보여줌 EXPLAIN문과는 독립적이어서, possible_keys에 나타난 인덱스를 실제로 사용할 수 없을 수 있음 해당 행이 NULL일경우 관련 인덱스가 없다는걸 난타냄 이 경우 WHERE절을 참고해 컬럼에 인덱스를 지정하여 쿼리 성능을 개선할 수 있음 key 실제로 사용을 결정한 인덱스를 보여줌 key_len 사용하기로 결정된 key의 길이를 나타냄 ref key에서 선택된 인덱스와 비교되는 컬럼 또는 상수값을 나타냄 rows MySQL이 해당 쿼리를 실행하기 위해 검사해야 한다고 생각되는 행의 수를 나타냄 innodb의 경우 항상 추정치이며 정확하지 않을 수 있음 filtered 테이블의 조건에 따라 필터링 되는 행의 수를 퍼센트로 나타낸것 최대값은 100이며 필터링 되지 않은 것을 의미함 Extra Mysql이 쿼리를 해결하는데 필요한 추가정보를 나타냄 Real Mysql 8.0\nhttps://dev.mysql.com/doc/refman/8.0/en/explain-output.html\nhttps://zzang9ha.tistory.com/436\n","date":"2024-04-30T22:35:11Z","permalink":"https://sungho94.me/p/mysql-explain-plan-1/","title":"Mysql Explain Plan - 1"},{"content":"\nURI(Uniform Resource Identifier) 통합 자원 식별자 인터넷에 있는 자원을 나타내는 유일한 주소 URN과 URL을 포괄하는 개념 URL은 URI가 될 수 없지만, URI는 URL이 될 수 있음 제한적인 URL과 URN보다는 URI라는 용어를 쓰자 예시 data:text/plain;base64,SGVsbG8gV29ybGQh data:image/jpeg;base64,/9j/4AAQSkZJRgAB… tel:+1234567890 tel:555–123–4567 file:///path/to/file.txt file:///C:/Documents/document.docx URL(Uniform Resource Locator) 통합 자원 위치 인터넷에서 웹페이지, 이미지, 비디오 등 리소스의 위치를 가르키는 문자열 자원를 식별하는것 뿐만아니라 수단을 제공 예시 https://www.example.com/index.html http://api.example.com/data ftp://ftp.example.com/files/document.pdf info@example.com mailto:user@example.com?subject=Hello\u0026amp;body=Hi%20there URN(Uniform Resource Name) 통합 자원 이름 지속적이고, 위치에 독립적인 리소스 식별자 예시 urn:isbn:0–486–27557–4 urn:ietf:rfc:3986 urn:oid:2.16.840 https://datatracker.ietf.org/doc/html/rfc3986#section-1.1.3\nhttps://blog.bytebytego.com/i/132279282/url-uri-urn-do-you-know-the-differences\nhttps://inpa.tistory.com/entry/WEB-%F0%9F%8C%90-URL-URI-%EC%B0%A8%EC%9D%B4\nhttps://ko.wikipedia.org/wiki/%ED%86%B5%ED%95%A9_%EC%9E%90%EC%9B%90_%EC%8B%9D%EB%B3%84%EC%9E%90\n","date":"2024-04-09T22:31:29Z","permalink":"https://sungho94.me/p/url-urn-uri/","title":"URL, URN, URI"},{"content":"객체의 필드를 그대로 노출하여 로직을 구하는 경우 캡슐화가 깨지고 결합도가 높아진다.\n다른 객체의 필드값을 가지고 로직을 구현한다면, 로직 변경되었을때 해당 로직을 가지고 있는 모든 로직을 변경해야한다. 예약이라는 객체가 있다고 생각해보자\n예약이라는 객체는 capacity라는 속성이 있고, 기존에는 capacity만으로 주문 가능한 여부를 따졌다.\n하지만 요구사항이 추가되어, \b거리에 따라 capacity를 수정하기로 하였고, 거리마다 capacity가 다르다\n이렇게 변경 시 기존에 capacity를 사용해서 마감을 확인하던 코드를 다 변경하여, 거리, capacity 두개 다 확인하도록 변경해야한다.\n","date":"2024-04-09T17:03:45Z","permalink":"https://sungho94.me/p/%ED%95%84%EB%93%9C%EB%A5%BC-%EB%85%B8%EC%B6%9C%EC%8B%9C%ED%82%A4%EB%A9%B4-%EC%95%88%EB%90%98%EB%8A%94-%EC%9D%B4%EC%9C%A0/","title":"필드를 노출시키면 안되는 이유"},{"content":"상황 현재 개발중인 기능에서 특정 api가 아래의 로그를 뱉으며 동작하지 않는 문제가 \b있다고 수정해달라는 요청을 받았다. 1 2 3 org.springframework.transaction.CannotCreateTransactionException: Could not open JPA EntityManager for transaction; nested exception is org.hibernate.exception.JDBCConnectionException: Unable to acquire JDBC Connection \u0026lt;생략\u0026gt; Caused by: java.sql.SQLTransientConnectionException: write-pool - Connection is not available, request timed out after 30000ms. write-pool에서 커넥션을 가져올 수 없다는 로그였다. 테스트 서버였고, 커넥션 10개로 설정되어있었다. 다른 업무도 있었고, 단순 커넥션 부족이라고 생각해서 테스트 서버를 재시작하였고, 커넥션 개수를 20개 까지 늘렸다 큰 착오였다, 테스트 서버에서 작업하는 인원은 5명이 채 되지 않았고, 절대 커넥션이 모자라지 않는 개수인데 당시에는 다른 작업으로 바빳고 대수롭지 않게 생각했었다\n그 이후 2일뒤 커넥션 개수를 늘려도 계속 에러가 나서 수정요청을 받았다. 커넥션 수가 모자랄리가 없다고 판단했는데, 계속 에러가 난다고하여 우선 커넥션 관련 로그 설정을 하였다 1 2 3 4 5 logging: level: com.zaxxer.hikari.HikariConfig: DEBUG com.zaxxer.hikari: TRACE org.springframework.transaction.interceptor: TRACE 위 로그를 설정하고, 서버 로그를 확인해보니, write-pool의 커넥션이 api요청이 끝난 후에도 반환되지 않는 것을 확인했다. 1 2 3 DEBUG 57394 --- [l-1 housekeeper] com.zaxxer.hikari.pool.HikariPool : write-pool - Pool stats (total=20, active=0, idle=19, waiting=0) DEBUG 57394 --- [l-1 housekeeper] com.zaxxer.hikari.pool.HikariPool : write-pool - Pool stats (total=20, active=1, idle=18, waiting=0) DEBUG 57394 --- [l-1 housekeeper] com.zaxxer.hikari.pool.HikariPool : write-pool - Pool stats (total=20, active=2, idle=17, waiting=0) connection을 사용한 후 connection이 반환되지 않는 connection leak이 있는것을 확인하였고, hikariConnection leak을 확인 할 수 있는 설정을 추가하였다 1 dataSource.leakDetectionThreshold = 2000 커넥션이 누수를 판단하는 시간으로 디폴트로 0(disable)으로 설정됨\n위 설정을 하니 아래의 로그가 남았다 1 java.lang.Exception: Apparent connection leak detected 로그에는 디테일한 메소드 정보까지 남았고, queryDsl의 trasform을 사용하는 메서드였다 @Transactional어노테이션 붙어있지 않았다! 관련해서 검색을 해보니, queryDsl의 transform을 @Transactional없이 사용하면, connection leak이 발생한다는 이슈가 있었다. 링크참고 우선 queryDsl의 transform를 사용하지 않는 로직에 대해 @Transactional을 다 붙여서 이슈를 종료하였다 Deep dive! 1 2 3 테스트환경 spring boot 2.7.8 querydsl 5.0.0 왜 @Transcational이 붙지않는 querydsl의 transform에 connection leak이 발생했을까? 위 이유를 알기 위해 아래 2가지를 알아보려 한다 @Transcational이 붙을때 커넥션을 어떻게 반납하는지? querydsl의 transform에서 커넥션 왜 반납하지 않는지? @Transcational이 붙을때 커넥션을 어떻게 반납하는지? 커넥션은 쿼리를 실행할때 얻음 Transactional을 실행할 때 얻지않음\n-\u0026gt; 쿼리가 없는 메서드에 @Transactional을 붙여도 커넥션을 할당하지 않음 @Transactional이 있을떄\nTransactionAspectSupport::createTransactionIfNecessary에서 txInfo를 리턴함 반납은 transaction종료시 발생 반납은 앞선 과정에서 받은 txInfo를 가지고, TransactionAspectSupport::commitTransactionAfterReturning의 인자로 넘겨 커넥션을 반납함 commitTransactionAfterReturning따라가다보면, ConcurrentBag::requite를 호출하는것을 확인함 txInfo내 entituManger에 connection에 대한 정보가 있음\n-\u0026gt; @Transactional이 있으면 명시적으로 커넥션을 반환하는 로직이 있어서 @Transactional이 있다면 커넥션 반환이 정상적으로 이루어짐 @Transactional이 없을때\nTransactionAspectSupport::createTransactionIfNecessary에서 txInfo가 없음 트랜잭션 종료시 TransactionAspectSupport::commitTransactionAfterReturning에 넘길 txInfo가 없으므로 쿼리를 실행 후 커넥션을 반납하는 로직이 필요함 아래의 로직으로 커넥션 반납함 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ... static{ queryTerminatingMethods.add(\u0026#34;execute\u0026#34;); queryTerminatingMethods.add(\u0026#34;executeUpdate\u0026#34;); queryTerminatingMethods.add(\u0026#34;getSingleResult\u0026#34;); queryTerminatingMethods.add(\u0026#34;getResultStream\u0026#34;); queryTerminatingMethods.add(\u0026#34;getResultList\u0026#34;); queryTerminatingMethods.add(\u0026#34;list\u0026#34;); } ... public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { ... if (SharedEntityManagerCreator.queryTerminatingMethods.contains(method.getName())) { if (this.outputParameters != null \u0026amp;\u0026amp; this.target instanceof StoredProcedureQuery) { StoredProcedureQuery storedProc = (StoredProcedureQuery)this.target; Iterator var12 = this.outputParameters.entrySet().iterator(); while(var12.hasNext()) { Map.Entry\u0026lt;Object, Object\u0026gt; entry = (Map.Entry)var12.next(); try { Object key = entry.getKey(); if (key instanceof Integer) { entry.setValue(storedProc.getOutputParameterValue((Integer)key)); } else { entry.setValue(storedProc.getOutputParameterValue(key.toString())); } } catch (IllegalArgumentException var20) { IllegalArgumentException ex = var20; entry.setValue(ex); } } } EntityManagerFactoryUtils.closeEntityManager(this.entityManager); this.entityManager = null; } ... 실행한 메서드 명이 queryTerminatingMethods 안에 있을때, closeEntityManager를 호출함 querydsl의 transform에서 커넥션 왜 반납하지 않는지? querydsl의 transform는 쿼리 조회시 scroll메서드를 사용함 queryTerminatingMethods에 존재하지 않음 정리 @Transactional을 사용한다면 @Transactional 내부에 connection을 종료하는 로직이 있음 @Transactional을 사용하지 않는다면, 커넥션이 끝날때, queryTerminatingMethods안에 존재하는 메서드를 사용해 커넥션을 종료해야함 querydsl의 transform는 쿼리 조회시 scroll메서드를 사용하여 커넥션이 종료되지 않음 해당 이슈정리 해당 이슈는 2018년 4월부터 발생한 이슈이다.github 이슈 링크 해당 이슈가 테스트 환경인 spring boot 2.7.8에서도 재현되었고 혹시 아직 고쳐지지 않았나 싶어, spring-orm코드를 보니, 23년 11월 26일에 scroll을 추가 되어 있었다. 추가로 spring boot 3.0 버전부터는 JPAQueryFactory생성 자 JPQLTemplates.DEFAULT을 받도록 수정되어, 해당 이슈를 우회할 수 있는것으로 보인다. ","date":"2024-04-07T12:24:58Z","permalink":"https://sungho94.me/p/querydsl-transform-connection-leak/","title":"Querydsl transform connection leak"},{"content":"ExecutorService 비동기 작업을 할때 쓰레드관리가 복잡한 과정임 ExecutorService가 복잡한 쓰레드관리를 단순화 시켜줌 하나이상의 비동기 작업을 과정을 추적하기 위한 Future를 생성하는 메서드와 종료관리 메서드를 제공 Excutor를 상속받았기에 execute메서드와 ExecutorService자체에서 제공하는 submit 메서드, shutdown, shutdownNow, awaitTermination등의 메서드가 있음 Method execute(Runnable command) Runnable한 인자를 받아 미래에 실행시킴 void를 리턴함 submit(Runnable command) execute와 마찬가지고러 Runnable한 인자와 Callable한 인자를 받아 미래에 실행시킴 인자의 수행 결과를 Future로 감싸서 리턴함 awaitTermination(long timeout, TimeUnit unit) 시간을 인자로 받으며, 모든 작업이 끝나거나, 시간 초과되거나, 인터럽트가 발생할때까지 쓰레드를 block시킴 shutdown() 이전에 제출된 작업은 유지하지만, 새로운 작업은 받지않음 제출된 작업이 완료되면 종료함 shutdownNow() 실행중인 작업과 대기중인 작업 모두 중지하고, 실행 대기중인 작업을 반환함 CountDownlatch 하나 이상의 스레드가 다른 쓰레드의 작업이 완료될때 까지 기다려주는 보조 동기화 장치 생성자로 count를 받으며, count가 0이 되면 await를 즉시 리턴함 메서드 CountDownLatch(int count) 생성자로 count를 받고, await를 호출하면 해당 count가 0이 될때까지 스레드를 wait함 countDown() count를 1감소시킴, 0이되면 await중인 스레드의 release함 getCount() 현재 count를 가져옴 await() 스레드가 인터럽트 되지 않는 한, count가 0이 될때까지 현재 쓰레드를 wait함 https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CountDownLatch.html\nhttps://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ExecutorService.html\n","date":"2024-04-05T17:25:00Z","permalink":"https://sungho94.me/p/5-executorservice-countdownlatch/","title":"5-ExecutorService \u0026 CountDownLatch"},{"content":" 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 fun main(){ repeat(3){ val worker = VolatileWorker() // worker 쓰레드 생성 worker.start() // worker 쓰레드 시작 Thread.sleep(100) // 메인 쓰레드 잠시 수면 println(\u0026#34;stop을 true로 변경\u0026#34;) worker.stop = true // worker쓰레드의 stop 플래그 변경 worker.join() // worker 쓰레드가 끝날 때까지 메인쓰레드에서 대기 } println(\u0026#34;작업 종료\u0026#34;) } class VolatileWorker : Thread() { @Volatile var stop = false override fun run() { super.run() while(!stop){ } } } class Worker : Thread() { var stop = false override fun run() { super.run() while(!stop){ } } } 현재 실행되고 있는 프로그램의 변수의 값을 읽기 위해서는 main메모리 혹은 cpu캐시에서 데이터를 읽어오게 된다 cpu캐시에 데이터가 있을 경우, main메모리가 아닌, cpu캐시에서 읽어오는 것이 더 효율적이기에 cpu캐시에서 데이터를 읽어온다 하지만 cpu캐시에서 계속 데이터를 읽어올경우, 다른 쓰레드에서 변경한 데이터를 읽지 않아 변경을 확인하지 못하는 문제가 발생할 수 있다 이때 변수에 @Volatile을 사용하면 해당 변수는 항상 main메모리에서만 데이터를 읽고 쓰기에 최신의 데이터에 대한 동작을 보장받을 수 있다 항상 main메모리에서 데이터를 읽어오기에 성능 저하가 발생한다 Volatile을 사용하지 않았을때 Volatile을 사용할 때 https://nesoy.github.io/articles/2018-06/Java-volatile\nhttps://jenkov.com/tutorials/java-concurrency/volatile.html\n","date":"2024-04-04T23:11:59Z","permalink":"https://sungho94.me/p/4-volitile/","title":"4-Volitile"},{"content":" 허가증을 유지함으로서 동시성을 제어\nacquire()메서드는 허가증이 사용가능할때까지 block하고 사용가능할때 허가증을 가짐\nrelease는 허가증을 추가하고, 잠재적으로 blocking되어있는 acquirer를 해제함\n실제로 퍼미션 객체는 사용되지 않으며, 세마포어는 사용가능한 개수를 카운팅할 뿐임\nSemaphore는 자원에 대해 접근할수 있는 쓰레드의 수를 제한하는데 사용함\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class Pool { private static final int MAX_AVAILABLE = 100; private final Semaphore available = new Semaphore(MAX_AVAILABLE, true); public Object getItem() throws InterruptedException { available.acquire(); return getNextAvailableItem(); } public void putItem(Object x) { if (markAsUnused(x)) available.release(); } // Not a particularly efficient data structure; just for demo protected Object[] items = ... whatever kinds of items being managed protected boolean[] used = new boolean[MAX_AVAILABLE]; protected synchronized Object getNextAvailableItem() { for (int i = 0; i \u0026lt; MAX_AVAILABLE; ++i) { if (!used[i]) { used[i] = true; return items[i]; } } return null; // not reached } protected synchronized boolean markAsUnused(Object item) { for (int i = 0; i \u0026lt; MAX_AVAILABLE; ++i) { if (item == items[i]) { if (used[i]) { used[i] = false; return true; } else return false; } } return false; } } ReentrantLock과 유사하게 lock을 얻어 자원을 확보한 이후에 작업을 진행함 허가증을 1개만 사용하여 metex처럼 사용 가능 reentrantLock과 같이 공정성 여부를 파라미터로 받아 공정성 여부를 결정함 vs ReentrantLock ReentrantLock은 1개의 자원에 대해 1개의 쓰레드만 접근이 가능함 Semaphore는 1개의 자원에 대해 n개의 쓰레드 접근이 가능함 ReentrantLock은 하나의 자원에 대해 여러번 시도하여 재진입이 가능함 재진입한 횟수만큼 자원 해제를 해야함 Semaphore에서는 지원하지 않음 ","date":"2024-04-03T23:37:49Z","permalink":"https://sungho94.me/p/2-semaphore/","title":"2-Semaphore"},{"content":"ReentrantLock Lock 인터페이스의 구현체 synchronized method, statements와 기본적인 동작과 의미가 동일하지만 확장된 기능을 가짐 synchronized 키워드를 사용할때보다 더 유연하게 사용가능 lock을 얻은후 다시 Lock을 얻을 수 있음 hold count를 증가시키고, hold count가 0이 되면 자원을 release함 \bFair 생정자에서 fair변수의 값을 받음 fair가 true라면 잠금을 가장 오래 기다린 쓰레드에 엑세스 권한부여 false라면 특정 엑세스 순서를 보장하지 않음 fair가 true인 경우가 전체처리량이 낮을 수 있지만, lock을 얻는 편차가 적고, \block starvartion이 덜 발생함 fair가 true라도 쓰레드 스케줄링이 공정하지 않을 수 있음 쓰레드 A,B,C가 lock을 대기하고 순서도 A,B,C순일때, A가 lock을 점유하고 해제한뒤 A가 다시 lock 요청시 B와 C가 사용한 \u001f가 아닌, A가 다시 사용하는 현상 tryLock 메소드는 fair필드의 여부와는 상관없음 tryLock을 사용한다면, 다른 쓰레드가 대기중이더라도 lock을 점유할 수 있음 Method lock() lock을 점유함 다른 스레드에서 lock을 점유하고 있지 않다면 lock을 점유하고 즉시 return함 현재 스레드에서 점유하고 있었다면, hold count를 1 증가시키고 즉시 return함 다른 스레드에서 점유중이라면 현재 스레드는 사용불가능하고 lock을 얻을 수 있을때 까지 대기함 lock을 얻는다면 hold count를 1로 세팅함 unLock() lock을 헤제함 현재 \u001f스레드가 lock을 점유하고 있다면 hold count를 1 감소시킴 hold count가 0이 된다면 락을 해제함 현재 스레드가 lock을 점유하고 있지 않다면 illegalMonitorStateException 예외를 발생시킴 tryLock() 다른 스레드에서 lock을 점유하지 않다면, 락을 점유하고 true를 리턴하고 hold count를 1로 세팅함 심지어 해당 ReentrantLock객체가 fair하게 동작하고 있고, 다른 스레드에서 lock을 대기하고 있는 상태라도 해당 lock을 점유할 수 있는 상태라면 lock을 점유함 만약 공정성을 해치고 싶지 않다면 tryLock(0,TimeUnit.SECONDS)로 호출하면 공정성을 해치지 않을 수 있음 해당 스레드가 Lock을 이미 점유하고 있다면 true를 리턴하고 hold count를 1 증가시킴 다른 스레드에 의해 이미 lock이 점유되어 있다면 즉시 false를 리턴함 기타 hasQueuedThreads() : 해당 락을 점유하기 위해 대기하고 있는 쓰레드의 존재여부를 알려줌 hasQueuedThread(Thread thread) : 주어진 쓰레드가 락을 점유하기 위해 대기중인지 여부를 알려줌 getQueueLength() : 락 점유 대기중인 \u001f스레드 수를 알려줌 getQueuedThreads() : 락 점유 대기중인 스레드 Collection을 리턴 Condition Lock이 synchronized를 대체하듯 Condition은 Object를 대체함 Lock.newCondition 메서드로 생성가능 synchronized lock wait await notify signal notifyAll signalAll javadoc\nhttps://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/ReentrantLock.html\n","date":"2024-04-02T18:05:04Z","permalink":"https://sungho94.me/p/1-reentrantlock-condition/","title":"1-ReentrantLock \u0026 Condition"},{"content":" Java를 사용하는 어플리케이션에 mysql의 연결을 쉽게 하기 위해 개발됨\nJDBC type 4 driver이며, JDBC 4.2 specification을 구현함\nmysql connector-j를 사용해서 커넥션을 얻고, 구문을 실행하여 5번째 컬럼의 문자열 결과를 얻어오는 코드는 아래와 같음\n1 2 3 4 5 6 7 8 DriverManager.getConnection(\u0026#34;jdbc:mysql://localhost:3306/dreamStore\u0026#34;,\u0026#34;root\u0026#34;,\u0026#34;tjdgh123\u0026#34;).use {conn -\u0026gt; conn.createStatement().use { statment -\u0026gt; val resultSet = statment.executeQuery(\u0026#34;select * from product\u0026#34;) while(resultSet.next()){ println(resultSet.getString(5)) } } } Connection을 한번 생성하면 데이터베이스에서 메타데이터를 가져오기 위한, Statement객체와 PrepareStatement객체를 생성하는데 사용 가능함 select쿼리는 executeQuery(String)메서드를 사용해서 호출가능 insert, update, delete쿼리는 executeUpdate(String)메서드를 사용해서 호출가능 만약 쿼리가 조회 쿼리인지, 변경 쿼리인지 알 수 없다면, execute(String)을 사용하여 확인가능 \b데이터 조회 쿼리라면 true, 변경쿼리라면 false를 리턴함 ","date":"2024-04-01T23:04:47Z","permalink":"https://sungho94.me/p/mysql-connector-j/","title":"Mysql Connector j"},{"content":"사용하는 이유 쓰레드 동기화 멀티 쓰레드 환경에서 서로 다른 스레드가 하나의 자원을 공유해서 사용할때, 자원을 동시에 사용하면 예상치 않은 동작이 발생 쓰레드 간섭(Thread Interference), 메모리 일관성 오류(Memory consistency Error) ex) 두개의 쓰레드가 하나의 변수에 10을 증가시키려할때, 20이 증가되지 않고 10이 증가되는 문제 위와 같은 방법을 해결하기 위해 쓰레드를 동기화 하여 하나의 자원을 동시에 사용하지 못하는 방법 종류 및 사용방법 Synchronized synchronized는 내재적 잠금(Intrinsic Lock) 또는 모니터 잠금(Monitor Lock)으로 알려진 내부 앤티티 중심으로 구현됨\n내재적 잠금은 동기화의 두가지 측면을 구현함 객체의 상태에 대한 배타적 엑세스를 강제함 가시성에 필수적인 happens-before relationships(발생 전 관계)를 설정 java의 모든 Object은 내재적 잠금을 가지고 있음\nheader에 들어가있음 객체의 필드에 독점적이고 일관된 엑세스를 필요로 하는 쓰레드는, 객체를 접근하기전객체의 내재적 잠금을 얻어야함\n그리고 작업이 끝나면 내재적 잠금을 해제(release)해야함 쓰레드는 잠금을 획득한 시점부터 해제할때까지 내재적 잠금을 소유해야함\n한 스레드가 내재적 잠금을 소유하고 있으면, 다른 쓰레드는 같은 lock을 소유할 수 없음\n다른 쓰레드가 잠금을 획득하려하면 block됨 스레드가 내재적 잠금을 해제하면, 해당 작업과 이후 동일한 잠금을 획득하는 모든 작업간에 선후(happens-before) 관계가 설정됨\njava에서는 synchronized method와 synchronized statment를 제공함\nsynchronized method 스레드가 synchronized 메서드를 호출하면, 해당 메서드의 객체에 대한 내재 잠금을 자동으로 획득하고 메서드가 반환될때 잠금을 해제 반환이 잡히지 않은 예외로 인해 발생한 경우에도 잠금이 해제됨 잠금이 객체단위에 적용되므로 increment뿐만 아닌 increment와 decrement도 동시에 동작하지 않음 정적 synchronized 메서드가 호출되면 객체가 아닌 클래스에 대한 내재 잠금을 획득 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class SynchronizedCounter { private var c = 0 @Synchronized fun increment() { c++ } @Synchronized fun decrement() { c-- } @Synchronized fun value(): Int { return c } } \bsynchronized 메소드를 사용하면 아래 2가지 효과를 얻을 수 있음 동일한 객체에 대해 \bsynchronized 메서드 호출이 동시에 발생되지 않음 한 스레드가 객체에 대해 synchronized 메서드를 실행하면, 첫번째 쓰레드가 작업을 완료할때까지 동기화된 메서드를 호출하는 다른 모든 쓰레드가 block됨 synchronized된 메서드가 종료되면, 동일한 객체에 대한 synchronized 메서드의 후속 호출과 함께 happends-before 관계가 설립됨 이로인해 모든 스레드에서 해당 객체 변경사항을 확인할 수 있음 생성자 메소드에는 synchronized를 호출할 수 없음 Synchronized statements synchronized method와 다르게 명시적으로 객체를 정의해야함 명시적의로 정의한 객체의 잠금을 획득하고 반환할때 잠금을 해제함 1 2 3 4 5 6 7 public void addName(String name) { synchronized(this) { lastName = name; nameCount++; } nameList.add(name); } 위의 예시에서는 lastName과 nameCount에는 동기화가 필요하지만, nameList에는 동기화가 필요하지 않은 경우이다\nSynchronized statements가 없다면 nameList.add를 호출하는 별도의 메서드가 필요함\n세분화된 동기화시에도 Synchronized statements가 유용함\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class MsLunch { private long c1 = 0; private long c2 = 0; private Object lock1 = new Object(); private Object lock2 = new Object(); public void inc1() { synchronized(lock1) { c1++; } } public void inc2() { synchronized(lock2) { c2++; } } } c1과 c2는 절대 함께 사용되지 않으며, 이런 필드의 모든 업데이트는 동기화 되어야함 하지만 c1과 c2사이의 동기화는 고려하지도 않아도 됨 위와 같은상황에서 \bsynchronized statements가 유용함 Synchronized method or statements에서만 사용가능한 메서드 Synchronized method or statements외에 사용시 IllegalMonitorStateException 오류 발생\nwait\n현재 쓰레드를 중단하고 객체 잠금을 해제함 notify() 또는 notifyAll메서드를 호출하여 해당 객체를 알릴때까지 대기함 notify\n객체 잠금을 가진 한 쓰레드르 깨우고 실행함 깨어난 쓰레드는 객체 잠금을 얻고 작업을 수행 어떤 쓰레드를 깨울지는 알 수 없기에 notifyAll을 주로 사용 notifyAll\n객체 잠금을 기다리는 모든 스레드르 꺠우고 실행 깨어난 쓰레드들은 객체 잠금을 얻기위해 경쟁함 https://www.ibm.com/docs/en/i/7.3?topic=techniques-synchronization-among-threads\nhttps://www.linkedin.com/pulse/thread-synchronization-techniques-ensuring-order-concurrent-n/\nhttps://docs.oracle.com/javase/tutorial/essential/concurrency/syncmeth.html\n","date":"2024-04-01T22:38:42Z","permalink":"https://sungho94.me/p/0-lock-%EC%A0%95%EC%9D%98-synchronized/","title":"0-Lock 정의 \u0026 synchronized"},{"content":"가상쓰레드, 리액티브 스트림즈, 코루틴 이 세가지 프로젝트는 모두 Blocking I/O로 인한 병목을 줄이기 위해 nonBlocking I/O를 사용할 목적으로 쓰이고 있습니다.\n기존에는 리액티브 스트림즈, 코루틴으로 nonBlocking I/O를 사용했다면, 작년 가상쓰레드가 나온 이후, 과연 어떻게될 지에 대해 개인적인 의견 및 정보들을 작성하려 합니다.\n우선 세가지 프로젝트의 목표에 대해 이야기 하려합니다.\n리액티브 스트림즈 The main goal of Reactive Streams is to govern the exchange of stream data across an asynchronous boundary—think passing elements on to another thread or thread-pool—while ensuring that the receiving side is not forced to buffer arbitrary amounts of data. In other words, back pressure is an integral part of this model in order to allow the queues which mediate between threads to be bounded. The benefits of asynchronous processing would be negated if the communication of back pressure were synchronous (see also the [Reactive Manifesto](http://reactivemanifesto.org/)), therefore care has to be taken to mandate fully non-blocking and asynchronous behavior of all aspects of a Reactive Streams implementation.\n간단히 요약해보자면\n비동기 뿐만이 아닌, 쓰레드간 element들을 교환하여 백프레셔를 지원하여 수신측에서 리소스를 지원한다\n입니다\n리액티브 스트림즈트는 비동기 뿐만이 아닌, 배압까지 신경쓰고 있는 것을 알 수 있습니다\n코루틴 No dependency on a particular implementation of Futures or other such rich library; Cover equally the \u0026ldquo;async/await\u0026rdquo; use case and \u0026ldquo;generator blocks\u0026rdquo;; Make it possible to utilize Kotlin coroutines as wrappers for different existing asynchronous APIs (such as Java NIO, different implementations of Futures, etc).`\n코루틴의 목표는Futures와 다른 라이브러리 의존 없이, 비동기 api의 래퍼를 제공하는것 입니다\n가상 스레드 Enable server applications written in the simple thread-per-request style to scale with near-optimal hardware utilization.\nEnable existing code that uses the java.lang.Thread API to adopt virtual threads with minimal change.\nEnable easy troubleshooting, debugging, and profiling of virtual threads with existing JDK tools.\n가상스레드의 목표는 최소한의 변경으로, 현재 서버 애플리케이션이 작성된 요청당 스레드 모델의 최적화된 하드웨어 사용이라는 것을 알 수 있습니다.\n\u001f\n추가로 Improving scalability with the asynchronous style을 살펴보면 reactive에 대한 내용이 더 나온다.\n1 2 3 Some developers wishing to utilize hardware to its fullest have given up the thread-per-request style in favor of a thread-sharing style. Instead of handling a request on one thread from start to finish, request-handling code returns its thread to a pool when it waits for another I/O operation to complete so that the thread can service other requests. This fine-grained sharing of threads — in which code holds on to a thread only while it performs calculations, not while it waits for I/O — allows a high number of concurrent operations without consuming a high number of threads. While it removes the limitation on throughput imposed by the scarcity of OS threads, it comes at a high price: It requires what is known as an _asynchronous_ programming style, employing a separate set of I/O methods that do not wait for I/O operations to complete but rather, later on, signal their completion to a callback. Without a dedicated thread, developers must break down their request-handling logic into small stages, typically written as lambda expressions, and then compose them into a sequential pipeline with an API (see [CompletableFuture](https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/CompletableFuture.html), for example, or so-called \u0026#34;reactive\u0026#34; frameworks). They thus forsake the language\u0026#39;s basic sequential composition operators, such as loops and `try/catch` blocks. In the asynchronous style, each stage of a request might execute on a different thread, and every thread runs stages belonging to different requests in an interleaved fashion. This has deep implications for understanding program behavior: Stack traces provide no usable context, debuggers cannot step through request-handling logic, and profilers cannot associate an operation\u0026#39;s cost with its caller. Composing lambda expressions is manageable when using Java\u0026#39;s [stream API](https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/stream/package-summary.html) to process data in a short pipeline but problematic when all of the request-handling code in an application must be written in this way. This programming style is at odds with the Java Platform because the application\u0026#39;s unit of concurrency — the asynchronous pipeline — is no longer the platform\u0026#39;s unit of concurrency. 리액티브 스타일의 어려운점(코드 스타일, 스택 트레이스, 디버깅 등)을 언급하는 부분이 있다.\n1 Typically, a virtual thread will unmount when it blocks on I/O or some other blocking operation in the JDK, such as `BlockingQueue.take()`. When the blocking operation is ready to complete (e.g., bytes have been received on a socket), it submits the virtual thread back to the scheduler, which will mount the virtual thread on a carrier to resume execution. 추가로 virtual Thread는 Blocking작업을 해당 스레드 unmount를 통해 Blocking을 회피할 수 있는것도 알 수 있다.\n결론 이를보면 가상 스레드가 리액티브 스트림즈를 대체하는 Blocking I/O로 인한 병목을 줄이는 기능을 하지않을까 싶다.\njava reactor에서 virtual thread를 사용하는 scheduler를 추가하며 vitual thread를 지원한다.\n지원한다고 해도 reactive streams의 단점이 뚜렸다하기에 reactive streams의 추가적인 기능인 배압을 사용하지 않는 이상, virtual thread를 사용하는게 더 나을거란 생각이다.\ncoroutine에서도 가상스레드를 지원하지만, Coroutine 또한 코드의 변경이 필요하기에, 가상스레드가 더 나을거라 생각된다\n개인적으로 리액티브 스트림즈 구현체인 리액터를 사용하면서 어려운점이 많았기에 얼른 가상스레드를 사용하고 싶다.\n하지만 가상스레드가 나왔지만, 데이터베이스 드라이버 같은 외부 라이브러리의 수정이 완성되지 않아 업무 프로젝트에는 사용하기 어려운점이 아쉽다.\nhttps://www.reactive-streams.org/\nhttps://openjdk.org/jeps/444\nhttps://github.com/Kotlin/KEEP/blob/master/proposals/coroutines.md\nhttps://blog.honeybomb.kr/9\nhttps://perfectacle.github.io/2023/07/10/java-virtual-thread-vs-kotlin-coroutine/\n","date":"2024-03-31T22:41:00Z","permalink":"https://sungho94.me/p/15-%EA%B0%80%EC%83%81%EC%8A%A4%EB%A0%88%EB%93%9C-vs-%EB%A6%AC%EC%95%A1%ED%8B%B0%EB%B8%8C-%EC%8A%A4%ED%8A%B8%EB%A6%BC%EC%A6%88-vs-%EC%BD%94%EB%A3%A8%ED%8B%B4/","title":"15 - 가상스레드 vs 리액티브 스트림즈 vs 코루틴"},{"content":" hikari가 일본어로 빛이라는 의미\nConcurrentBag hikary cp 에서 커넥션을 관리하는 주체 borrow(빌려줌)메서드으로 커넥션을 반환 Compare and set 연산으로 커넥션을 사용상태로 변경 requite(갚음)메스드로 커넥션을 반납 setState 메서드로 커넥션을 사용가능한상태로 변경 빌려줄때는 CAS연산으로 해당 커넥션이 사용가능한 상태인지 확인하지만, 갚을때는 따로 확인하지 않음\n왜 Hikari CP를 많이 사용하는가? Spring에서 지원하는 기본 connection pool이다 Spring에서는 성능과 동시성에서 HikariCP가 장점이 있다고 판단하여 사용함 사용이 불가능한 상황에서는 아래와 같은 순서로 Connection pool을를 사용함 HikariCP \u0026gt; Tomcat pooling DataSource \u0026gt; Commons DBCP2 \u0026gt; Oracle UCP 참고\nhttps://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.datasource.connection-pool\n다른 CP들과 비교 [https://github.com/brettwooldridge/HikariCP/blob/dev/documents/Welcome-To-The-Jungle.md] 위 링크를 보면 다른 CP에 비해 request spike가 발생했을때 blocking thread가 적고, 커넥션 수가 일정한 것을 확인할 수 있음 기타 HikariCP는 다른 CP에 비해 설정할 수 있는 값이 적음, 간단함을 추구하는 디자인 철학 HikariCP와 다른 CP들과의 다르게 PrepareStatement캐싱을 하지 않음\n\u001f 속성 정리 connectionTimeout 연결 타임아웃 기본 30초 짧게 설정할경우, 설정한 시간보다 조회하는 시간이 길면, time out error 발생 이외의 것들은 링크참고 https://github.com/brettwooldridge/HikariCP\nhttps://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#data.sql.datasource.connection-pool\n#Database\n","date":"2024-03-31T22:41:00Z","permalink":"https://sungho94.me/p/hikaricp/","title":"HikariCP"},{"content":" 커넥션 관련 쿼리 1 2 3 4 5 6 7 8 -- 현재 mysql server에서 동시에 지원가능한 connection 가능 개수 show variables like \u0026#39;%max_connections%\u0026#39;; -- 서버가 시작된 후로 동시에 연결된 최대 connection 개수 SHOW STATUS WHERE `variable_name` = \u0026#39;Max_used_connections\u0026#39;; -- 현저 서버에 연결된 connection 수 SHOW STATUS WHERE `variable_name` = \u0026#39;Threads_connected\u0026#39;; #MySQL\n","date":"2024-03-31T22:41:00Z","permalink":"https://sungho94.me/p/mysql-connection-check-query/","title":"Mysql Connection check query"},{"content":"Fixture 소프트웨어를 일관되게 테스트 할 수 있게 해주는 장치 테스트를 실행하고, 특정결과를 예상하기 위해 필요한 모든것 링크 테스트 더블과는 다른 용어임 SUT(System Under Test)\n우리가 테스트하고 싶어하는 모든것, 테스트 관점에서 정의됨\n단위테스트를 작성할 때는 테스트를 하는 클래스(CUT), 객체(OUT), 메서드(OUT),\n통합 테스트를 작성할때는 어플리케이션(AUT)\nTest Double 테스트 목적으로 실제 객체 대신 올 수 있는 모든 종류의 객체를 의미함 테스트를 진행하기 어려운 경우, 이를 대신해 테스트를 진행할 수 있도록 만들어 주는 객체 영화 촬영시 위험한 역할을 대신한느 스턴트 더블에서 비롯됨\nDummy Object, Test Stub, Test Spy, Mock Object, Fake Object 과 같은 구현이 존재함 Dummy SUT의 메소드 시그니처에 필요한 객체들 테스트에 영향은 가지 않지만, SUT 메소드 시그니처에 필요한 객체 null 오브젝트, 하드코딩된 값들 실제로 테스트에 영향이 가지않아, Test Double로 보지않는 의견도 있음\nTest Stub SUT가 의존하는 실제 컴포넌트를 대체하기 위해 사용 실제 컴포넌트를 대체하여 간접적인 입력에 대해 제어할 수 있음 Test Spy Test Stub보다는 더 강력한 버전의 Test Double로써, SUT 간접적인 입력의 관찰지점(observation point)임 간접적인 입력에 대해 관찰이 가능하며, SUT에 대한 간접적인 출력을 capture함 capture한 간접적인 출력에 대해 검증 가능 Mock Object와 동일한 목적으로 사용하지만, Test Spy를 사용한다면, 테스트 스타일은 Test Stub과 더 유사함 Mock Object SUT의 간접적인 출력을 검증할 수 있는 관찰지점 테스트에 실패하지 않은 경우, SUT에 반드시 값을 리턴하는, Test Stub의 기능을 포함함 간접 출력의 검증에 더 치우쳐져 있음 단순히 Test Stub에 assertion이 추가된것이 아닌, 근본적인 차이가 있음 Fake Object SUT의 간접 입력 및 출력 확인하는 것 이외의 이유로 실제 의존하는 객체의 기능을 대체하기 위해 사용 실제 객체와 동일한 기능을 하지만, 간단하게 구현됨 테스트를 위해 특별히 구축 되지만, 제어지점이나 관찰지점으로 사용되지 않음 실제 의존하는 객체가 아직 사용가능하지 않거나, 테스트에 사용할 수 없을때 Fake Object를 사용함 데이터베이스를 인메모리 해시 테이블로 대체하여 테스트를 50배 빠르게 실행 가능하도록 할 수 있음 https://martinfowler.com/articles/mocksArentStubs.html\nhttp://xunitpatterns.com/Test%20Double.html\n","date":"2024-03-31T22:41:00Z","permalink":"https://sungho94.me/p/test-double/","title":"Test Double"},{"content":"https://jfrog.com/artifactory/\n코드, 컨테이너, cloud component를 한번에 관리해주는 툴\n비쌈\n","date":"2024-03-20T23:29:00Z","permalink":"https://sungho94.me/p/jfrog/","title":"Jfrog"},{"content":"Threading and Scheduler Flux나 Mono를 얻는다고 실행되지 않음 따로 지정하지 않으면 Reactor는 subscribe가 발생한 쓰레드에서 모든 연산자가 실행됨 Reactor가 실행되는 위치는 스케줄러에 의해 정해짐 Schedulers.immediate() 직접적으로 현재 실행되고 있는 쓰레드에서 실행됨 Schedulers.single() 쓰레드를 생성하여 스케줄러가 dispose될때까지 모든 호출자에 대해 동일한 쓰레드를 재사용 호출별 새로운 쓰레드를 생성하고 싶다면 Schedulers.newSingle()을 사용해야함 Schedulers.elastic() 배압 문제를 숨기고 너무많은 쓰레드를 생성하기에 Schedulers.boundedElastic()가 도입된 이후로 잘 사용되지 않음 Schedulers.boundedElastic() 필요에 따라 워커풀을 생성하고, idle한 워커풀이 있다면 재사용함 워커풀이 일정시간 사용되지 않으면 삭제됨(기본 60초) Schedulers.elastic()과 달리 워커풀 생성에 제한이 있음(기본 cpu core*\\10) 한도에 도달한다면 최대 100,000 작업이 큐에 추가됨 쓰레드가 다시 재사용 될때 큐에 추가됨 100,000이 넘게 추가되면 에러발생 블로킹\b프로세스에 자체 쓰레드를 부여하여 다른 리소스 묶이지 않도록 할 수 있음 링크참고 Schedulers.parallel() 병렬 작업에 맞게 고정된 워커풀을 생성 CPU Core개수만큼 워커풀을 생성함 추가 Schedulers.fromExecutorService(ExecutorService)를 사용하여 ExecutorService를 Scheduler로 사용할 수 있음 newXXX를 사용하여 다양한 스케줄러 타입의 인스턴스를 생성할 수 있음 boundedElastic()은 single과 parallel과 다르게 피할 수 없는 legacy blocking콜을 사용하는데 single과 perallel을 사용한다면 blocking api(block(), blockFirst(), blockLast())를 사용하면 IllegalStateException을 발생시킴 어떤 연산자는 기본으로 특정 Schduler를 사용함 ex) Flux.interval는 Schedulers.parallel()을 사용함 변경가능함 publishOn, subscribeOn Reactor에서는 Reactor chain 내에서 실행 컨택스트를 바꿀 수 있는 publishOn과 subscribeOn을 제공함 publishOn 다른 오퍼레이터들과 같이 체인 내에서 적용될 수 있음 연관된 Scheduler의 worker에서 콜백이 실행되는 동안 업스트림에서 신호를 받아, 다운스트림으로 재생해줌 따라서 후속 오퍼레이터가 실행되는 곳에 영향을 미침 스케줄러에서 선택된 하나의 쓰레드로 실행 컨텍스트를 변경함 시퀀스 내에서 onNext를 호출하면 선택된 쓰레드로 실행됨 이후 특정 스케줄러를 지정하지 않는 한, publishOn 이후의 연산자는 동일한 쓰레드에서 실행됨 1 2 3 4 5 6 7 8 9 Scheduler s = Schedulers.newParallel(\u0026#34;parallel-scheduler\u0026#34;, 4); 1번 쓰레드 final Flux\u0026lt;String\u0026gt; flux = Flux .range(1, 2) // 2번 쓰레드로 실행 .map(i -\u0026gt; 10 + i) // 2번 쓰레드로 실행 .publishOn(s) .map(i -\u0026gt; \u0026#34;value \u0026#34; + i); // 1번 쓰레드로 실행 new Thread(() -\u0026gt; flux.subscribe(System.out::println)); - 2번 쓰레드 subscribeOn backward chain이 구성될때, 구독처리과정에서 subscribeOn을 적용함 중간 연산자가 실행컨택스트에 영향을 줄 수 있으므로 데이터 소스 바로 뒤에 적용하는 것이 좋음 publishOn동작에는 영향을 미치지 않음 구독하는 전체 체인의 Scheduler의 쓰레드를 변경함 스케줄러에서 하나의 쓰레드를 선택함 1 2 3 4 5 6 7 8 9 Scheduler s = Schedulers.newParallel(\u0026#34;parallel-scheduler\u0026#34;, 4); - 1번 쓰레드 final Flux\u0026lt;String\u0026gt; flux = Flux .range(1, 2) .map(i -\u0026gt; 10 + i) // 1번쓰레드로 실행 .subscribeOn(s) // 1번쓰레드로 실행 .map(i -\u0026gt; \u0026#34;value \u0026#34; + i); // 1번쓰레드로 실행 new Thread(() -\u0026gt; flux.subscribe(System.out::println)); - 2번쓰레드 subscribeOn이 있다면 어디서 구독하든 subscribeOn의 Scheduler를 사용하여 시작함\n스케줄러 공부자료 링크참고\nSink signal을 수동으로 트리거 할 수 있는 구조 여러 Subscriber를 처리할 수 있는 Publisher구조를 가짐 unicast()는 아님 Hot vs Cold Cold 구독이 생성될때마다 새로운 데이터를 생성 구독이 생성되지 않으면, 데이터를 생성하지 않음 HTTP 요청에 비유하면, 구독이 생성될때마다 HTTP 요청을 보냄 Hot 구독자의 수에 영향을 받지 않음 즉시 데이터를 publishing 할 수 있음 구독하기 전에 실제로 어떠한 일이 발생할 수 있음 데이터 생성 중간에 \b새로운 구독자가 들어오면, 새로온 구독자는 그전의 데이터를 알지 못하고, 구독 이후에 데이터만 전달받음 Hot publisher의 예시로 just가 있는데 어셈블리 시점에 데이터를 캡처하고, 나중에 오는 구독자에게 이를 생성함 HTTP요청에 비유하면, 인스턴스화 할때 네트워크 요청이 한번 실행되고 구독자에게 이 결과를 전달함 구독이 늘어난다고 해서 HTTP요청을 여러번 실행하지 않음 just를 cold publisher로 변환하려면 defer를 사용하면 됨\nshare 또는 replay를 사용한다면 cold publisher를 hot publisher로 전환가능\n관련공부자료 default scheduler 변경방법 Schedulers.Factory를 사용하여 가능 링크 참고 Context 명령형 프로그래밍에서 사용하는 Thread Local의 대안 세부사항 Map자료 구조와 유사함 key와 value가 Object, Object타입으로 다양한 값들을 넣을 수 있음 다양한 라이브러리들과 호환 위해 불변임, put 또는 putAll이 발생한다면 새로운 인스턴스가 생성됨 ContextView인 read only api는 write와 관련된 메서드를 제공하지 않음 실제로 체인에 있는 구독자에게 연결됨 구독 전파매커니즘을 통해 최종 구독자로부터 위로 올라가면서 각각의 operator가 Context를 사용하게 해줌 inner sequence에서 외부의 context를 읽을 수 있음 thread local 데이터를 자동으로 context에 넣어주는 Context-Propagation관련 기능도 있음 링크참고 context 공부 예제 링크 참고 https://projectreactor.io/docs/core/release/reference/index.html\nhttps://brunch.co.kr/@springboot/153\n","date":"2024-03-05T22:41:02Z","permalink":"https://sungho94.me/p/11-reactor-java2/","title":"11-Reactor Java(2)"},{"content":" callback보다 나은점 callback hell이 발생하지 않음 Future보다 나은점 더 많은 연산자를 지원함 Flux Flux\u0026lt;T\u0026gt;는 0개에서 N개의 비동기 시퀀스 항목을 방출하는 Publisher\u0026lt;T\u0026gt;임 onComplete 혹은 onError로 종료됨 onNext, onComplete, onError 로 downstream을 호출할 수 있음 종료를 포함한 모든 이벤트는 선택사항힘 onNext가 없고 onComplete만 있다면 빈 유한 시퀀스임 onNext\u001d 있고 onComplete가 없다면 무한 시퀀스임 Mono 최대 하나의 항목만을 emit하는 Publisher onNext이후 onComplete가 호출되거나 하나의 onError가 호출됨\u001c Mono는 Flux에 비해 제한된 연산자를 제공함 하나의 항목만 방출하니까 Mono#concatWith(Publisher) 등 여러 메스드로 Mono를 Flux로 변경가능함 Mono\u0026lt;Void\u0026gt;로 완료개념만 있는 비동기 시퀀스를 생성가능 그외 개념 Hot Sequence vs Cold Sequence Hot Sequence 한번 구독하면 생성된 시퀀스를 재사용함 나중에 구독한 구독자는 이전꺼 시퀀스를 받지 못하고 구독이후의 시퀀스를 받을 수 있음 Cold Sequence 구독할때마다 시퀀스가 재 생성됨 Disposable subscribe()이 리턴하는 값 Disposable을 사용해서 cancel가능 Disposables.composite()를 사용해서 Disposable을 묶을 수 있으며 한번에 취소가능 BaseSubscriber Reactor에서 사용자 정의 Subscriber를 구현할 수 있는 추상클래스 BaseSubscriber를 사용하여 Subscriber를 lambda가 아닌 클래스로 구성가능 requestUnbounded()를 통해 unbounded한 reqeust를 구현가능 request(Long.MAX_VALUE)과 동일 Backpressure reactor에서 Backpressure를 구현하는 방법은 request를 사용하는것 최대 Long.MAX_VALUE까지 가능함 DownStream에서 Demand가 바뀔 수 있음 request로 몇개의 item을 받을 것인지 결정됨 하지만 중간에 buffer와 같은 연산자로 생산되는 item이 바뀔 수 있음 request가 2고 중간에 버퍼가 2라면 2*2인 4개의 item이 생산됨 limitRate, prefetch라는 개념도 있음 링크참고 Sequence를 생성하는법 generate 동기적으로 하나하나씩 생성 create 비동기, 멀티쓰레드 방식으로 생성 Flux sink를 사용 push 비동기, 싱글쓰레드 방식으로 생성 create와 push를 사용한 후에는 onCancel과 onDispose로 끝내야함\nhandle 인스턴스 메소드로 동기로 하나씩 생성된 것들에 대해 값을 변형하거나, 필터링할 수 있음 ","date":"2024-03-05T22:41:01Z","permalink":"https://sungho94.me/p/10-reactor-java1/","title":"10-Reactor Java(1)"},{"content":"정의 처리량이 많은 동시성 애플리케이션을 작성, 유지관리 및 관찰는데 드는 수고를 획기적으로 줄여주는 경량쓰레드임 jep-444 Platform Thread 기존 Java의 Thread 모델 하나의 java쓰레드에 OS Thread를 할당해서 사용 새로운 쓰레드가 필요하면 os에 요청해서 가져옴 Virtual Thread Virtual Thread의 쓰레드 모델 Virtual Thread 생성시 OS에 요청해서 생성하지 않고. java library에서 생성 실제 OS쓰레드에는 Carrier Thread가 매핑이 되고, Carrier Thread를 가지고 있는 Virtual Thread가 현재 실행되고 있는 쓰레드임 Carrier Thread가 없는 Virtual Thread는 동작중이지 않음 쓰레드 관리를 JVM에서 함 컨텍스트 스위칭 처리를 OS단이 아닌 JVM내에서 처리함 비교 유의사항 CPU bound한 상황에서는 Platform Thread가 더 나은 성능을 보여줌 정말 스트리밍 데이터를 사용한다면 reactor를 고려하자 syncronized 또는 JNI call 시 carrier thread에 블로킹(pinning)이 발생 syncronized을 reenterantLock으로 변경 thread local데이터를 Heap에 저장하므로 무분별하게 사용시 OOM발생 가능성이 있음 https://techblog.woowahan.com/15398/\nhttps://tech.kakao.com/2023/12/22/techmeet-virtualthread/\nhttps://medium.com/deno-the-complete-reference/springboot-virtual-threads-vs-webflux-performance-comparison-for-jwt-verify-and-mysql-query-ff94cf251c2c\nhttps://www.diva-portal.org/smash/get/diva2:1763111/FULLTEXT01.pdf\nhttps://docs.oracle.com/en/java/javase/20/core/virtual-threads.html#GUID-2BCFC2DD-7D84-4B0C-9222-97F9C7C6C521\nhttps://github.com/brettwooldridge/HikariCP/issues/2151\nhttps://perfectacle.github.io/2022/12/29/look-over-java-virtual-threads/\ndeep-dive-link https://blog.rockthejvm.com/ultimate-guide-to-java-virtual-threads/\nhttps://openjdk.org/jeps/425\nhttps://softwaremill.com/what-is-blocking-in-loom/\nhttps://wiki.openjdk.org/display/loom/Main\nhttps://stackoverflow.com/questions/74581601/how-does-a-java-virtual-thread-know-when-the-thread-is-waiting\nhttps://stackoverflow.com/questions/70174468/project-loom-what-happens-when-virtual-thread-makes-a-blocking-system-call\n#need-to-deep-dive\n","date":"2024-03-05T22:41:00Z","permalink":"https://sungho94.me/p/13-virtual-thread-1/","title":"13-Virtual Thread 1"},{"content":"서론 Reactor에 대해 여러가지 공부해 보았는데, reactor Scheduler에 대한 글이 없어 소스코드를 보며 분석하였다.\nreactor-netty에서 디폴트로 제공하는 BoundedElasticScheduler에서 어떻게 쓰레드에 작업이 할당되는지 알아보자\nReactor Scheduler 실제 작업이 실행될 쓰레드를 할당하는 인터페이스이다.\njava reactor에서는 제공하는 여러가지 스케줄러를 제공하는데, BoundedElasticScheduler는 Scheduler의 구현체이다\nSchedulers subscribeOn, publishOn에는 Schedulers의 정적 메서드를 사용하여 스케줄러를 지정하기에 Schedulers클래스부터 알아보자\n필드에 대한 설명이다\nDEFAULT_POOL_SIZE 기본 풀 사이즈로, ParallelScheduler 사용 시\b쓰레드 수를 지정하는 필드이다. reactor.schedulers.defaultPoolSize 설정으로 값을 지정할 수 있으며 디폴트 값은 시스템의 CPU개수이다 DEFAULT_BOUNDED_ELASTIC_SIZE BoundedElasticScheduler에서 사용하는 쓰레드 풀 사이즈를 지정하는 필드이다. reactor.schedulers.defaultBoundedElasticSize로 설정할 수 있으며 디폴트는 시스템의 CPU개수 * 10개이다 DEFAULT_BOUNDED_ELASTIC_QUEUESIZE BoundedElasticScheduler에서 쓰레드 별 큐사이즈를 지정하는 필드이다 reactor.schedulers.defaultBoundedElasticQueueSize로 설정할 수 있으며 디폴트는 100,000개이다 DEFAULT_BOUNDED_ELASTIC_ON_VIRTUAL_THREADS BoundedElasticScheduler사용 시 가상쓰레드 여부를 결정하는 필드이다 reactor.schedulers.defaultBoundedElasticOnVirtualThreads로 설정할 수있으며, 디폴트로 false이다 이제 스케줄러를 생성하는 메서드에 대해 알아보자\n1 2 3 public static Scheduler boundedElastic() { return cache(CACHED_BOUNDED_ELASTIC, BOUNDED_ELASTIC, BOUNDED_ELASTIC_SUPPLIER); } 스케줄러를 생성하는 메서드는 static메서드이고 내부에서 cache로 관리한다.\n한번 스케줄러를 생성하면 내부에서 캐싱된 스케줄러를 가져온다는것을 알 수있다. ImmediateScheduler, BoundedElasticScheduler, ParallelScheduler는 다 아래와 같은 형태이다 prefix로 new가 붙은 메서드를 사용하거나 fromExecuter를 사용해서 새로운 스케줄러를 생성할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 static CachedScheduler cache(AtomicReference\u0026lt;CachedScheduler\u0026gt; reference, String key, Supplier\u0026lt;Scheduler\u0026gt; supplier) { CachedScheduler s = reference.get(); if (s != null) { return s; } s = new CachedScheduler(key, supplier.get()); if (reference.compareAndSet(null, s)) { return s; } return reference.get(); } cache메서드 간단하다.\n캐싱된 스케줄러가 있는지 확인하고, 있으면 캐싱된 스케줄러를 반환하고, 없다면 인자로 받은 Scheduler Supplier로 스케줄러를 생성하고, 이를 캐싱한다.\n그럼 이제 BoundedElasticScheduler를 생성하는 BoundedElasticSchedulerSupplier에 대해 알아보자\n1 2 3 4 5 6 7 8 9 10 11 12 class BoundedElasticSchedulerSupplier implements Supplier\u0026lt;Scheduler\u0026gt; { @Override public Scheduler get() { ... return newBoundedElastic(DEFAULT_BOUNDED_ELASTIC_SIZE, DEFAULT_BOUNDED_ELASTIC_QUEUESIZE, BOUNDED_ELASTIC, BoundedElasticScheduler.DEFAULT_TTL_SECONDS, true); } } newBoundedElastic메서드에 Schedulers의 BoundedElasticScheduler의 설정값이 들어가는 것을 볼 수 있다.\nBoundedElasticScheduler 이제 BoundedElasticScheduler에서 작업을 할당하는 schedule메서드를 알아보자\n1 2 3 4 5 6 7 8 9 10 11 @Override public Disposable schedule(Runnable task, long delay, TimeUnit unit) { //tasks running once will call dispose on the BoundedState, decreasing its usage by one final BoundedState picked = state.currentResource.pick(); try { return Schedulers.directSchedule(picked.executor, task, picked, delay, unit); } catch (RejectedExecutionException ex) { // ensure to free the BoundedState so it can be reused picked.dispose(); throw ex; } 로직은 간단한데, schedule메서드는 currentResource의 pick메서드를 호출하여 BoundedState를 가져오고, 스케줄러에 작업을 예약한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 BoundedState pick() { for (; ; ) { if (busyStates == ALL_SHUTDOWN) { return CREATING; } int a = get(); if (!idleQueue.isEmpty()) { BoundedState bs = idleQueue.pollLast(); if (bs != null \u0026amp;\u0026amp; bs.markPicked()) { boolean accepted = setBusy(bs); if (!accepted) { // shutdown in the meantime bs.shutdown(true); return CREATING; } return bs; } } else if (a \u0026lt; parent.maxThreads) { if (compareAndSet(a, a + 1)) { ScheduledExecutorService s = Schedulers.decorateExecutorService(parent, parent.createBoundedExecutorService()); if (newState.markPicked()) { boolean accepted = setBusy(newState); if (!accepted) { // shutdown in the meantime newState.shutdown(true); return CREATING; } return newState; } } } else { BoundedState s = choseOneBusy(); if (s != null \u0026amp;\u0026amp; s.markPicked()) { return s; } } } } pick메서드는 무한 루프를 돌며 사용 가능한 BoundedState를 가져온다\nline 3에서 busyState가 전부 종료되어 있다면 종료상태의 BoundedState를 리턴한다\nCREATE enum으로 되어있지만, CREATE는 기본 실행기로서 종료와 같은 상태이므로 종료된 BoundedState를 리턴함 종료된 상태의 executer가 전달되기에 작업은 실행되지 않음 line 8에서는 idle한 BoundedState가 있는지 확인하고, 있다면 idleQueue에서 BoundedState를 하나 꺼내 리턴함\nline 19에서는 현재 생성된 쓰레드 수가 최대 생성 가능한 쓰레드보다 작은지 확인 한다. 작다면 새로운 스케줄러 스레드를 생성해 BoundedState를 만들어 리턴함\nline 33에서는 busy상태에 있는 BoundedState 중 작업이 가장 적게 할당된 BoundedState를 가져와 리턴한다.\n다시 \bschedule메서드를 보자\n1 2 3 4 5 6 7 8 9 10 11 12 @Override public Disposable schedule(Runnable task, long delay, TimeUnit unit) { //tasks running once will call dispose on the BoundedState, decreasing its usage by one final BoundedState picked = state.currentResource.pick(); try { return Schedulers.directSchedule(picked.executor, task, picked, delay, unit); } catch (RejectedExecutionException ex) { // ensure to free the BoundedState so it can be reused picked.dispose(); throw ex; } } pick으로 가져온 BoundedState의 executer를 directSchdule의 인자로 넘긴다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 static Disposable directSchedule(ScheduledExecutorService exec, Runnable task, @Nullable Disposable parent, long delay, TimeUnit unit) { task = onSchedule(task); SchedulerTask sr = new SchedulerTask(task, parent); Future\u0026lt;?\u0026gt; f; if (delay \u0026lt;= 0L) { f = exec.submit((Callable\u0026lt;?\u0026gt;) sr); } else { f = exec.schedule((Callable\u0026lt;?\u0026gt;) sr, delay, unit); } sr.setFuture(f); return sr; } directSchedule메서드를 살펴보자\n10번, 13번 라인에서 executer에게 작업을 할당한다\n작업을 할당하는 메서드를 살펴보자\n1 2 3 4 5 @Override public synchronized \u0026lt;T\u0026gt; Future\u0026lt;T\u0026gt; submit(Callable\u0026lt;T\u0026gt; task) { ensureQueueCapacity(1); return super.submit(task); } synchronized 메서드이다\nsynchronized 메서드이므로 객체마다 lock이 걸리고, 해당 메서드를 가지고있는 BoundedScheduledExecutorService는 static클래스이므로 해당 메서드는 하나의 프로세스에서 동시에 실행될 수 없다. ensureQueueCapacity를 살펴보자\n1 2 3 4 5 6 7 8 9 10 11 12 13 void ensureQueueCapacity(int taskCount) { if (queueCapacity == Integer.MAX_VALUE) { return; } int queueSize = super.getQueue().size(); if ((queueSize + taskCount) \u0026gt; queueCapacity) { throw Exceptions.failWithRejected( \u0026#34;Task capacity of bounded elastic scheduler reached while scheduling \u0026#34; + taskCount + \u0026#34; tasks (\u0026#34; + ( queueSize + taskCount) + \u0026#34;/\u0026#34; + queueCapacity + \u0026#34;)\u0026#34;); } } 위 메서드는 현재 큐의 크기와, 추가된 작업의 개수의 합이 DEFAULT_BOUNDED_ELASTIC_QUEUESIZE를 넘기는지 확인하고, 넘으면 에러를 리턴하는 로직이다.\npick메서드에서 최대 스레드 생성 개수, ensureQueueCapacity메서드에서 쓰레드 당 최대 작업개수를 검증하는 것을 확인할 수 있었다.\npick메서드에서는 compareAndSet으로 동시성을 제어한다.\nensureQueueCapacity메서드에서는 호출하는 메서드가 syncronized 메서드로 동시성을 제어한다.\n추가 - BoundedElasticScheduler의 inner class BoundedElasticScheduler 내부에 4개의 클래스가 있다.\n내부 클래스들을 알게 되면 BoundedElasticScheduler의 동작과정을 더 이해할 수 있다.\n먼저 BoundedElasticScheduler의 선언부를 보자\n1 2 3 4 5 6 7 8 9 final class BoundedElasticScheduler implements Scheduler, SchedulerState.DisposeAwaiter\u0026lt;BoundedElasticScheduler.BoundedServices\u0026gt;, Scannable { ... volatile SchedulerState\u0026lt;BoundedServices\u0026gt; state; @SuppressWarnings(\u0026#34;rawtypes\u0026#34;) static final AtomicReferenceFieldUpdater\u0026lt;BoundedElasticScheduler, SchedulerState\u0026gt; STATE = AtomicReferenceFieldUpdater.newUpdater(BoundedElasticScheduler.class, SchedulerState.class, \u0026#34;state\u0026#34;); BoundedElasticScheduler는 Scheduler, SchedulerState.DisposeAwaiter, Scannable의 구현체이다.\n필드로 SchedulerState\u0026lt;BoundedServices\u0026gt; 타입의 필드가 있는데, BoundedServices로 스케줄러의 상태를 관리한다.\n1 2 3 4 5 6 7 8 9 10 11 12 static final class BoundedServices extends AtomicInteger{ ... final BoundedElasticScheduler parent; final Deque\u0026lt;BoundedState\u0026gt; idleQueue; volatile BusyStates busyStates; ... BoundedState pick() { ... } 선언부를 보면, BoundedServices는 AtomicInteger를 상속받은 클래스이다.\nBoundedServices의 Integer 값은, 현재 실행되고 있는 쓰레드의 개수를 의미한다.\nparent필드에서는 부모인 BoundedElasticScheduler을 가지고 있다\nidleQueue는 idle 상태인 BoundedState를 가지고 있다.\nbusyStates는 BusyStates타입인데, busy상태인 BoundedState을 가지고 있다.\npick메서드는 앞서 설명한 바와 같이, 작업을 실행할 BoundedState을 결정한다.\n1 2 3 4 5 6 7 8 9 static final class BusyStates { final BoundedState[] array; final boolean shutdown; public BusyStates(BoundedState[] array, boolean shutdown) { this.array = array; this.shutdown = shutdown; } } BusyStates에서는 array 필드에 busy상태인 BoundedState을 가지고 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 static class BoundedState implements Disposable, Scannable { final BoundedServices parent; final ScheduledExecutorService executor; volatile int markCount; BoundedState(BoundedServices parent, ScheduledExecutorService executor) { this.parent = parent; this.executor = executor; } } parent필드는 부모인 BoundedService를 가지고 있다.\nexecuter는 ScheduledExecutorService을 가지고 있는데, 실제 생성자로 들어오는 클래스는 ScheduledExecutorService가 아닌, BoundedScheduledExecutorService을 가진다.\nmarkCount는 executer가 실행하고 있는 작업의 개수를 나타낸다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 static final class BoundedScheduledExecutorService extends ScheduledThreadPoolExecutor implements Scannable{ final int queueCapacity; void ensureQueueCapacity(int taskCount) { if (queueCapacity == Integer.MAX_VALUE) { return; } int queueSize = super.getQueue().size(); if ((queueSize + taskCount) \u0026gt; queueCapacity) { throw Exceptions.failWithRejected( \u0026#34;Task capacity of bounded elastic scheduler reached while scheduling \u0026#34; + taskCount + \u0026#34; tasks (\u0026#34; + ( queueSize + taskCount) + \u0026#34;/\u0026#34; + queueCapacity + \u0026#34;)\u0026#34;); } } @Override public synchronized ScheduledFuture\u0026lt;?\u0026gt; schedule( Runnable command, long delay, TimeUnit unit) { ensureQueueCapacity(1); return super.schedule(command, delay, unit); } } BoundedScheduledExecutorServices는 ScheduledThreadPoolExecutor구현체이다\nScheduledThreadPoolExecutor와 큰 차이라면 queueCapacity필드와 ensureQueueCapacity메서드를 가지고 있다는 것이다.\nschedule을 할때마다 현재 큐사이즈+새 태스크 개수를 확인해서 queueCapacity를 넘으면 에러를 발생시킨다.\n","date":"2024-03-05T22:11:03Z","permalink":"https://sungho94.me/p/12-reactor-schedulerboundedelasticscheduler/","title":"12-Reactor Scheduler(BoundedElasticScheduler)"},{"content":"개념 논블로킹 배압(back pressuer)을 사용한 비동기 스트리밍 처리를 위한 표준 network protocol 뿐만아니라 JVM, Javascript와 같은 런타임 환경에 대한 표준도 포함함 스트림 데이터라고도 표현되는 크기가 정해지지 않은 \u0026rsquo;live\u0026rsquo;데이터는 비동기 시스템에서 주의가 필요함 들어오는 데이터가 처리되는 속도보다 빠르면 안되기 때문 데이터가 많으면 쌓이고, 그러다 보면 메모리가 터지기때문 Reactive Streams의 주요 목표는 비동기 경계를 넘은 데이터 스트림의 교환(데이터를 다른쓰레드 혹은 쓰레드 풀로 전달하는)하며 수신측에서는 임의의 데이터양을 버퍼로 관리하지 않는것임 backpressure는 스레드 사이의 대기열을 제한하기 위한 필수적인 부분임 또한 백프레셔 신호가 동기식일 경우 비동기 처리의 이점이 없어지기에, Reactive Streams의 구현은 모든측면에서 비차단, 비동기식으로 구성되도록 주의를 기울임 구성요소 Publisher는 잠재적으로 무한한 수의 시퀀스 요소를 제공하며, Subscriber의 요청을 받으면 요소를 제공하기 시작함 Publisher.subscribe(Subscriber)에 대한 응답으로 Subscriber는 아래의 신호를 받음``` 1 onSubscribe onNext* (onError | onComplete)? Publisher.subscribe를 호출하면, 반드시 한번 onSubscribe가 호출되며, 무한한 onNext를 방출\u001f 이후 Subscription이 cancel되지 않으면, 에러가 발생하면 onError, 더 이상 전달할 요소가 없다면 onComplete를 호출 Subscription이 cancel되면 onError, onComplete를 호출하지 않을 수 있음 어떻게 구현해야 하는지에 대한 설명으로, 필자는 구현보다는 사용에 관한 관점에 대해 정리함\n너무 구현에 관한 설명에 대해서는 작성하지 않으므로 구현내용이 궁금하다면 링크를 참조\nPublisher 1 2 3 public interface Publisher\u0026lt;T\u0026gt; { public void subscribe(Subscriber\u0026lt;? super T\u0026gt; s); } 무한한 시퀀스 요소를 Subscriber에게 제공 publisher는 요청된 수만큼, 혹은 요청된 수보다 적은 onNext를 호출해야함 요청된 수보다 적은 onNext를 보내고, onError 혹은 onCompelete로 구독의 종료를 알릴 수 있음 에러발생시 onError, 더이상 전달한 요소가 없다면 onComplete를 반드시 호출해야함 Subscriber에게 onError 혹은 onComplete를 보낼 시, Subscriber는 해당 Subscription을 취소된 것으로 간주해야함 종료신호(onError 혹은 onComplete)를 보낸 후에는 더이상 \b신호가 발생하지 않아야함 Publisher가 subscribe호출을 받으면 반드시 Subscriber의 onSubscribe을 호출해야함 제공된 구독자가 null인 상황에서는 NullPointerException예외를 던져야함 제공된 구독자가 null이 아닌 상황에서는 정상적으로 응답해야함 Subscriber 1 2 3 4 5 6 public interface Subscriber\u0026lt;T\u0026gt; { public void onSubscribe(Subscription s); public void onNext(T t); public void onError(Throwable t); public void onComplete(); } onNext 신호를 받기위해서는 반드시 Subscription.request(long n)신호를 보내야함 onComplete() 및 onError(Throwable t)는 신호를 수신한다면 구독이 취소된것으로 간주해야함 Subscriber가 이미 활성화된 Subscription을 가지고 있을때, 새로운 Subscription을 받는다면 새로운 Subscription에 대해 cancel을 호출해야함 Subscriber는 반드시 하나의 Publisher를 가져야함 Subscription이 더 이상 필요하지 않다면 Subscriber는 cancel을 호출해야함 Subscriber는 반드시 Subscription의 request와 cancel이 순차적으로 호출되도록 보장해야함 Subscription 1 2 3 4 public interface Subscription { public void request(long n); public void cancel(); } Subscription.request과 Subscription.cancel은 반드시 Subscriber 컨택스트 내에서 호출되어야함 Subscription이 취소되면 Subscription.request(long n)은 NOP을 반환해야함 Subscription이 취소되면 Subscription.cancel()은 NOP을 반환해야함 Subscription은 반드시 무한한 request를 지원해야하며, 최대 2^63-1까지 지원해야함 2^63-1보다 크거나 같은 수요는 무한하다고 간주할 수 있음 구독은 한명의 Publisher와 한명의 Subscriber가 공유하며, 이 쌍간의 데이터 교환을 중계하기 위한 목적으로 사용됨 이러한 위와같은 이유로 subscribe()가 Subscription을 반환하는게 아니라 void를 반환하는 것 Subscription은 onSubscribe콜백을 통해서만 구독자에게 전달됨 Processor 1 2 public interface Processor\u0026lt;T, R\u0026gt; extends Subscriber\u0026lt;T\u0026gt;, Publisher\u0026lt;R\u0026gt; { } Processor는 처리 단계를 나타내며, \bSubscriber이자 Publisher인 동시에 양쪽의 계약을 모두 준수해야 함 onError발생시 복구할 수 있도록 선택할 수 있음 복구를 선택한다면 Subscription은 취소된 것으로 간주함 복구를 선택하지 않는다면 Subscriber에게 onError를 전파\u001c해야함 필수사항은 아니지만, 마지막 Subscriber가 Subscription을 취소할때 upStream의 구독을 취소하여 취소신호가 upStream으로 전파되게 하는것이 좋음 \bpublisher - subscriber간 프로세스 https://www.reactive-streams.org/\nhttps://github.com/reactive-streams/reactive-streams-jvm/blob/v1.0.4/README.md\nhttps://souljit2.tistory.com/78\n","date":"2024-03-04T22:41:09Z","permalink":"https://sungho94.me/p/9-reactive-streams/","title":"9-Reactive Streams"},{"content":" 데이터가 도착하거나 생성되는 즉시\u001c실시간으로 데이터를 처리하는 패러다임\n데이터가 쌓일때까지 기다리지 않고, 데이터가 흐르는 대로 즉각적으로 처리하여 통찰와 조치가 가능하도록 함\n실시간 데이터\u001f분석이 중요한 분야에서 많이 사용됨\n주식 구매 위험 감지 위치 데이터 IT인프라 분석 및 대응 batch처리는 예약된 시간에 일괄로 데이터를 처리하는 방식이라면, stream처리는 데이터가 전송되는 대로 실시간으로 데이터를 처리하는 방식\nhttps://docs.oracle.com/cd/E19455-01/805-7478/index.html\nhttps://atlan.com/batch-processing-vs-stream-processing/#batch-processing-vs-stream-processing-7-differences-to-know\n","date":"2024-03-04T22:41:08Z","permalink":"https://sungho94.me/p/8-stream-processing/","title":"8-Stream Processing"},{"content":" 2013년 어플리케이션의 요구사항(짧은 응답시간, 100%가용성)의 변화로 리액티브 시스템을 정의한 리액티브 선언문(reactive manifesto)가 작성됨 (현재 최신 버전 2014년 v2.0) 리액티브 선언문에서는 리액티브 시스템이란 Responsive, Resilient, Elastic, Message Driven을 가진 시스템이라고 정의 이중 jvm을 타겟으로한 비동기, 논블로킹의 표준인 reactive streams나왔고 이를 구현한 Project Reactor와 rxJava가 나왔다. 이중 Project Reactor와 Spring Framework가 손잡고 나온것이 Spring Webflux이다. 현재 Spring Webflux에서 많이 사용하는 Http Server인 Reactor Netty는 Project Reactor의 프로젝트중 하나이다 Responsive(응답성) 시스템은 가능한 적시에 응답해야함 사용성과 유용성 때문에 중요한것도 맞지만, 문제를 신속하게 감지할수 있다는 더 중요한 장점이 있음 응답성이 높은 시스템은 신속하고 일관된 응답을 주는것에 중점에 두며, 신뢰할 수 있는 상한선을 두어 일관된 서비스 품질을 제공함 위와같은 일관된 행동은 오류를 간소화하고, 최종 사용자와의 신뢰를 구축하며, 더 많은 상호작용을 장려함 Resilient(회복성) 시스템은 장애가 발생하여도 응답성을 유지해야함 고 가용성의 중요한 시스템 뿐만아니라, 중요하지 않은 시스템도 포함됨 회복성은 복제, 격리, 위임, 고립를 통해 달성됨 구성요소에 장애 발생시, 장애가 발생한 구성요소를 격리하여 전체 시스템에 영향을 주지않으며, 시스템 일부만 장애발생 및 복구가 가능하게함 장애가 발생한 시스템에 대한 복구는 다른 구성요소에게 위임되며, 필요한 경우 복제를 통해 고가용성을 달성함 구성요소의 클라이언트는 장애를 복구하는데 부담을 덜 느낄수 있음 Elastic(탄력성) 다양한 작업량(갑자기 요청이 많아지는 경우)에도 응답성이 유지되어야함 reactive system은 이러한 다양한 요청량을 처리하기 위해 자원을 늘리거나 줄이는 것으로 대응할 수 있음 컴포넌트를 샤딩이나 복제하고, 이들에게 입력을 분산시키는 기능을 제공하는, 경합지점이나 병목이 없는 설계를 의미함 reactive system은 실시간 성능 측정 기능을 통해 예측 및 반응형 확장 알고리즘을 제공함 이 시스템은 상용 하드웨어 및 소프트웨어 플랫폼에서 비용 효율적인 측면에서 탄력성을 달성함 aws에서 툭하면 elastic이 나오게 되는데 선언문에 나온 elasitc의 개념이다.링크\n리액티브 선언문을 많이 읽어보며, 어떻게 개발해야 할지 개발 방향에 좀 감을 잡은거 같다.\nMessage Driven(메시지 전달) reactive system은 비동기 메세지 전달에 의존하여 느슨한 결함, 격리 및 위치 투명성을 보장하는 구성요소간에 경계를 설정함 이 메세지는 실패를 메시지로 위임할 수 있는 수단도 제공함 명시적 메시지 전달을 사용하면 시스템에서 대기열을 형성 및 모니터링 하고, 필요시 배압을 사용하여 부하관리 및 탄력성, 흐름제어가 가능함 위치 투명 메시징을 사용하면 클러스터 전체, 혹은 단일 호스트 내에서 동일한 구조로 장애를 관리할 수 있음 비차단 통신을 통해 수신자는 활성상태일 때만 리소스를 사용하여 시스템의 오버헤드가 줄어듬 https://www.reactivemanifesto.org/ko\nhttps://www.reactive-streams.org/\nhttps://github.com/reactor/reactor\n#Reactive\n#Concept\n","date":"2024-03-04T22:41:07Z","permalink":"https://sungho94.me/p/7-reactive-manifesto/","title":"7-Reactive Manifesto"},{"content":"\nFilter Dispatcher Servlet으로 가기전 적용되는 필터 모든 request에 적용되는 필터 설정을 통해 특정 path로 갈때, 우선순위 등 여러 설정 가능 DispatcherServlet request를 분석하여 처리를 위해 적절한 컨트롤러로 보냄 스프링은 FrontController패턴을 사용하여 하나의 Servlet(DispatcherServlet)만 사용 여러 Servlet을 사용할경우 중복코드가 \b생성되기에 하나의 Servlet에서 요청을 처리함 스프링은 하나의 Dispatcher Servle만 생성 참고링크 Hander Mapping request가 등록된 controller 중 어떤 controller와 매핑되는지 찾음 Hander Adapter Hander Mapping으로 찾은 controller 호출 View Resolver 전달받은 view name가지고 view를 찾음 https://terasolunaorg.github.io/guideline/1.0.1.RELEASE/en/Overview/SpringMVCOverview.html\nhttps://justforchangesake.wordpress.com/2014/05/07/spring-mvc-request-life-cycle/\nhttps://velog.io/@hsw0194/Spring-MVC-HandlerMapping%EC%9D%98-%EB%8F%99%EC%9E%91%EB%B0%A9%EC%8B%9D-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1%ED%8E%B8\n","date":"2024-03-04T22:41:06Z","permalink":"https://sungho94.me/p/6-spring-mvc-request-%EC%B2%98%EB%A6%AC-%EA%B3%BC%EC%A0%95/","title":"6-spring mvc request 처리 과정"},{"content":" Jakarta Servlet, Jakarta Server Page, Jakarta Expression Language, Jakarta WebSocket, Jakarta Annotations, Jakarta Authentication 의 세부사항을 구현한 오픈소스 소프트웨어 Architecture Server Server는 웹 컨테이너 자체를 의미 사용자가 거의 customize하지 않는 설정들의 기본 구현들을 제공 Service Server내에있는 중간 구성 요소(intermediate component)로 하나 이상의 커넥터를 정확히 하나의 엔진과 연결시킴 기본 구현들이 간단하고 충분하므로, Server와 마찬가지로 사용자들이 거의 customize하지 않음 Engine 특정 서비스에 대한 요청 처리 파이프라인을 나타냄 Service는 여러 connector를 가질 수 있고, Engine은 이러한 커넥터로부터 온 모든 요청을 수신하고 처리하여, 클라이언트에 전달한 적절한 커넥터로 응답을 다시 전달함 Engine 인터페이스는 사용자에 의해 구현될 수 있지만, 자주 발생하는 일은 아님 Host 호스트는 네트워크 이름(예: www.yourcompany.com)을 Tomcat 서버에 연결한 것 엔진에는 여러 개의 호스트가 포함될 수 있으며, 호스트 요소는 yourcompany.com 및 abc.yourcompany.com과 같은 네트워크 별칭도 지원 표준 호스트 구현은 상당한 추가 기능을 제공하기 때문에 사용자가 사용자 지정 호스트를 만드는 경우는 거의 없음 Context 웹 어플리케이션을 나타냄 호스트에는 고유한 경로를 가진 여러개의 context를 가질 수 있음 사용자정의 컨텍스트를 생성하기 위해 인터페이스를 구현할 수 있지만, 표준 컨텍스트가 충분히 많은 기능을 제공하기에 이런 경우는 드뭄 Connector 클라이언트와 통신을 처리 HTTP 트래픽에 처리되는 HTTP 커넥터와 HTTPD와 같은 웹서버와 연결할때 필요한 ajp프로토콜을 구현한 ajp커넥터가 존재함 https://tomcat.apache.org/tomcat-9.0-doc/architecture/overview.html\nhttps://medium.com/chequer/tomcat-spring-bootstrapping-sequence-1%ED%8E%B8-tomcat-4402102c0585\n","date":"2024-03-04T22:41:05Z","permalink":"https://sungho94.me/p/5-apache-tomcat/","title":"5-Apache Tomcat"},{"content":" Servlet Engine이라고도 불림 서블릿을 실행하고 관리함 서블릿 메서드를 실행하고, 서블릿이 호출될때 필요한 서비스들을 제공함 서블릿에서 header나 parameter를 쉽게 접근할 수 있도록함 서블릿이 호출되면 웹서버는 http요청을 서블릿 컨테이너를 호출함 컨테이너는 차례로 요청을 서블릿에 전달함 요청이 들어오면 servlet conatiner는 다음과 같은 일련의 작업을 거침 서블릿 인스턴스를 생성 후 init메서드를 호출하여 초기화함 서블릿에 전달한 request객체를 구성함 http header, 클라이언트에서 전달된 파라미터, 서블릿 요청의 전체 URI 서블릿에 대한 응답 객체를 생성함 서블릿의 service메서드를 호출함 적절한 상황에 destroy메서드를 호출해 서블릿이 garbage collector에 의해 폐기되도록 함 성능상의 이유로 서블릿 컨테이너는 작업을 완료할때마다 서블릿을 파괴하지 않고, 메모리에 보관하는것이 일반적임 웹서버 종료와 같은 드물게 발생하는 이벤트에 대해서만 소멸시킴 https://docs.oracle.com/cd/A97688_16/generic.903/a97680/overview.htm\n","date":"2024-03-04T22:41:04Z","permalink":"https://sungho94.me/p/3-servlet-container/","title":"3-Servlet Container"},{"content":" Server + applet의 합성어 서버에서 특정기능을 수행하는 작은 어플리케이션 C++, JAVA HTTP 등 많은 Servlet이 존재 main method를 가지고 있지 않아 다른 외부 컨테이너의 제어하에 실행됨 google definition 참고 ","date":"2024-03-04T22:41:03Z","permalink":"https://sungho94.me/p/2-sevlet/","title":"2-Sevlet"},{"content":" 1990 년 PC 매거진에서 처음 사용된 단어 하나의 프로그램에서 특정 기능을 수행하는 작은 어플리케이션 독립적으로 사용되지 않으며 작은 기능을 가지고 잇음 https://en.wikipedia.org/wiki/Applet\nhttps://ko.wikipedia.org/wiki/%EC%95%A0%ED%94%8C%EB%A6%BF\n","date":"2024-03-04T22:41:02Z","permalink":"https://sungho94.me/p/1-applet/","title":"1-Applet"},{"content":" 웹서버 소프트웨어와 웹사이트의 구성파일을 저장하는 컴퓨터 인터넷에 연결되며 웹에 연결된 다른 장치와의 물리적 데이터 교환을 지원함 #Webserver\nhttps://developer.mozilla.org/en-US/docs/Learn/Common_questions/Web_mechanics/What_is_a_web_server\n","date":"2024-03-04T22:41:01Z","permalink":"https://sungho94.me/p/0-static-web-server/","title":"0-Static Web Server"},{"content":"JOB은 코루틴이 상속하지 않는 유일한 코루틴 컨텍스트임 생명주기 위 그림과 같이 Job은 New, ACTIVE, COMPLETEING, COMPLETED, CANCELLING, CANCELLED 6가지 상태를 가진다 ACTIVE 코루틴이 Job을 실행하고 있는 상태 대부분의 Coroutine은 Active상태로 시작 NEW Job생성시 CoroutineStart.Lazy옵션을 주면 NEW상태로 Job이 생성됨 ACTIVE상태가 되기위해서는 \bJob을 실행해야함 COMPLETING 코루틴의 Job은 끝났고, 자식들의 종료를 기다리는 상태 자식들도 종료가 된다면 COMPLETED상태로 변경됨 COMPLETED 코루틴의 JOB과 자식들이 정상적으로 종료된 상태 final상태이므로 상태가 변경되지 않음 CANCELLING Job이 실행도중 취소되거나 실패했을때 변경되는 상태 여기서 연결을 끊거나 자원을 바납하는 후처리 작업 가능 후처리 작업이 완료되면 CANCELLED상태로 변경됨 CANCELLED CANCELLING에서 후처리 작업이 완료된 상태 final상태이므로 상태가 변경되지 않음 https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-job/\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-job.html\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/job.html\n","date":"2024-03-03T22:41:08Z","permalink":"https://sungho94.me/p/7-job/","title":"7-Job"},{"content":" suspend함수는 Continuation을 다른 suspend함수에 전달해야 함 일반함수에서 suspend를 호출 할 수 없음 어디서 suspend함수를 호출해야 하는가? Coroutine builder 일반세계와 \bsuspend세계를 연결하는 다리역할 launch 개념적으로 새로운 쓰레드를 생성하는 것과 유사함 코루틴을 시작하고, 독립적으로 실행함 1 2 3 4 5 6 7 8 9 10 11 12 public fun CoroutineScope.launch( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; Unit ): Job { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyStandaloneCoroutine(newContext, block) else StandaloneCoroutine(newContext, active = true) coroutine.start(start, coroutine, block) return coroutine } CoroutineScope의 extension function임 coroutine context를 받아, 해당 context내에서 3번쨰 인자로 받은 block을 실행시킴 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 fun main() { GlobalScope.launch { delay(1000L) println(\u0026#34;World!\u0026#34;) } GlobalScope.launch { delay(1000L) println(\u0026#34;World!\u0026#34;) } println(\u0026#34;Hello,\u0026#34;) Thread.sleep(1500L) }// Hello, // (1 sec) // World! // World! main 함수에서 Thread.sleep()을 호출하지 않는다면, Hello만 출력됨 launch내의 delay는 실제로 쓰레드를 block하지 않음 async 1 2 3 4 5 6 7 8 9 10 11 12 public fun \u0026lt;T\u0026gt; CoroutineScope.async( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; T ): Deferred\u0026lt;T\u0026gt; { val newContext = newCoroutineContext(context) val coroutine = if (start.isLazy) LazyDeferredCoroutine(newContext, block) else DeferredCoroutine\u0026lt;T\u0026gt;(newContext, active = true) coroutine.start(start, coroutine, block) return coroutine } launch와 비슷하지만 async는 값을 Deferred로 감싸서 return함 Deferred는 suspending method await를 가짐 값이 준비되면 Deferred에 저장되고, await호출시 값을 리턴함\u001c 값이 준비되기전 await호출 시, 값이 준비될 떄까지 suspend됨 runBlocking 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Throws(InterruptedException::class) public actual fun \u0026lt;T\u0026gt; runBlocking(context: CoroutineContext, block: suspend CoroutineScope.() -\u0026gt; T): T { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } val currentThread = Thread.currentThread() val contextInterceptor = context[ContinuationInterceptor] val eventLoop: EventLoop? val newContext: CoroutineContext if (contextInterceptor == null) { // create or use private event loop if no dispatcher is specified eventLoop = ThreadLocalEventLoop.eventLoop newContext = GlobalScope.newCoroutineContext(context + eventLoop) } else { // See if context\u0026#39;s interceptor is an event loop that we shall use (to support TestContext) // or take an existing thread-local event loop if present to avoid blocking it (but don\u0026#39;t create one) eventLoop = (contextInterceptor as? EventLoop)?.takeIf { it.shouldBeProcessedFromContext() } ?: ThreadLocalEventLoop.currentOrNull() newContext = GlobalScope.newCoroutineContext(context) } val coroutine = BlockingCoroutine\u0026lt;T\u0026gt;(newContext, currentThread, eventLoop) coroutine.start(CoroutineStart.DEFAULT, coroutine, block) return coroutine.joinBlocking() } coroutine의 일반적인 규칙은 thread를 block하지 않는다 이지만, runblocking은 다른 coroutine builder와는 다르게 쓰레드를 block함 main function과 같이, 쓰레드를 block하지마 않으면 프로세스가 종료되기 때문에 이러한 경우 runBlocking을 사용해야함 runBlocking은 새로운 코루틴을 실행하고, 현재 쓰레드를 코루틴이 완료될 때 까지 block함 runBlocking인자로 Dispatcher를 전달하여 다른 쓰레드에서 runBlocking을 실행하게 할 수 있음 다른 쓰레드에서 runBlocking을 실행해도 runBlocking을 실행한 쓰레드를 Block함 Dispatcher는 코루틴을 실행할 쓰레드를 선택하는 것으로, 현재 쓰레드를 block하는 것을 막을 수 없음 CoroutineScope의 확장함수가 아님, CoroutineScope외부에서 사용 가능 완료될때까지 쓰레드를 block하므로 CoroutineScope외부에서 사용하는건 권장하지 않음 Structured Concurrency launch와 async함수는 CoroutineScope의 extenstion함수 임\n따로 CoroutineScope를 지정하지 않는다면, 해당 함수를 실행한 CoroutineScope의 확장함수로 동작\n부모-자식관계 형성 부모자식 관계가 형성된다면 아래와 같은 관계가 됨\n자식 코루틴은 부모 코루틴으로부터 context를 상속 받음 부모 코루틴은 자식 코루틴이 끝날때까지 suspend됨 부모 코루틴이 cancel되면 자식 코루틴도 cancel됨 자식 코루틴에서 에러 발생시 부모 코루틴에도 전파됨 CoroutineScope를 따로 지정한다면 부모-자식 관계가 아니므로 launch와 async의 종료를 기다리지 않음\n1 2 3 4 5 6 7 8 9 10 11 12 fun main(){ runBlocking { println(\u0026#34;start\u0026#34;) CoroutineScope(EmptyCoroutineContext).launch(CoroutineName(\u0026#34;123\u0026#34;)) { delay(100) println(\u0026#34;another scope!\u0026#34;) } println(\u0026#34;end\u0026#34;) } } //start //end suspend 함수 내부에서 launch, async를 호출할떄는 coroutineScope{}로 코루틴스코프를 새로 생성 후 호출해야함\nwithContext 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 public suspend fun \u0026lt;T\u0026gt; withContext( context: CoroutineContext, block: suspend CoroutineScope.() -\u0026gt; T ): T { contract { callsInPlace(block, InvocationKind.EXACTLY_ONCE) } return suspendCoroutineUninterceptedOrReturn sc@ { uCont -\u0026gt; // compute new context val oldContext = uCont.context // Copy CopyableThreadContextElement if necessary val newContext = oldContext.newCoroutineContext(context) // always check for cancellation of new context newContext.ensureActive() // FAST PATH #1 -- new context is the same as the old one if (newContext === oldContext) { val coroutine = ScopeCoroutine(newContext, uCont) return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } // FAST PATH #2 -- the new dispatcher is the same as the old one (something else changed) // `equals` is used by design (see equals implementation is wrapper context like ExecutorCoroutineDispatcher) if (newContext[ContinuationInterceptor] == oldContext[ContinuationInterceptor]) { val coroutine = UndispatchedCoroutine(newContext, uCont) // There are changes in the context, so this thread needs to be updated withCoroutineContext(coroutine.context, null) { return@sc coroutine.startUndispatchedOrReturn(coroutine, block) } } // SLOW PATH -- use new dispatcher val coroutine = DispatchedCoroutine(newContext, uCont) block.startCoroutineCancellable(coroutine, coroutine) coroutine.getResult() } } 결과를 리턴한점에서 async와 많이 비교됨 withContext는 block이 끝날때까지 현재 coroutine을 suspend함 async와의 차이점 인자로 CoroutineStart을 받지않는 것 즉시 실행되므로 CoroutineStart가 필요없음 context의 디폴트 값이 없는 것 withContext는 현재 Context가 아닌 다른 Context로 실행할경우 사용하는것이기에, Context를 인자로 받아야함 CoroutineScope의 확장함수가 아니라는 것 CoroutineScope CoroutineStart 코루틴 빌더의 시작 옵션을 설정 DEFAULT 해당 컨텍스트에 코루틴을 실행하도록 즉시 예약함 LAZY 해당 코루틴이 필요할때까지, 코루틴 시작을 늦춤 ATOMIC 해당 컨텍스트에 실행할 코루틴을 원자적으로(취소할 수 없는 방식으로) 예약함 UNDISPATCHED 현재 쓰레드애 첫번째 suspension point를 만날때까지 즉시 코루틴을 실행함 https://medium.com/@wind.orca.pe/kotlin-coroutines-coroutine-builders-korean-recap-24a36300513b\nhttps://kotlinlang.org/docs/coroutines-basics.html#an-explicit-job\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-start/\n","date":"2024-03-03T22:41:07Z","permalink":"https://sungho94.me/p/6-coroutine-builder/","title":"6-Coroutine builder"},{"content":" Kotlin Coroutine은 일시중단을 구현하기 위해 ContinuosPassing style을 적용하였음 \bCPS스타일로 변환된 Suspend 함수 실제 코드가 아닌, 중요한 로직만 정리함 1 2 3 4 5 6 7 8 suspend fun printUser(token: String) { println(\u0026#34;Before\u0026#34;) val userId = getUserId(token) // suspending println(\u0026#34;Got userId: $userId\u0026#34;) val userName = getUserName(userId, token) // suspending println(User(userId, userName)) println(\u0026#34;After\u0026#34;) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 fun printUser( token: String, continuation: Continuation\u0026lt;*\u0026gt; ): Any { val continuation = continuation as? PrintUserContinuation ?: PrintUserContinuation( continuation as Continuation\u0026lt;Unit\u0026gt;, token ) var result: Result\u0026lt;Any\u0026gt;? = continuation.result var userId: String? = continuation.userId val userName: String if (continuation.label == 0) { println(\u0026#34;Before\u0026#34;) continuation.label = 1 val res = getUserId(token, continuation) if (res == COROUTINE_SUSPENDED) { return COROUTINE_SUSPENDED } result = Result.success(res) } if (continuation.label == 1) { userId = result!!.getOrThrow() as String println(\u0026#34;Got userId: $userId\u0026#34;) continuation.label = 2 continuation.userId = userId val res = getUserName(userId, continuation) if (res == COROUTINE_SUSPENDED) { return COROUTINE_SUSPENDED } result = Result.success(res) } if (continuation.label == 2) { userName = result!!.getOrThrow() as String println(User(userId as String, userName)) println(\u0026#34;After\u0026#34;) return Unit } error(\u0026#34;Impossible\u0026#34;) } class PrintUserContinuation( val completion: Continuation\u0026lt;Unit\u0026gt;, val token: String ) : Continuation\u0026lt;String\u0026gt; { override val context: CoroutineContext get() = completion.context var label = 0 var result: Result\u0026lt;Any\u0026gt;? = null var userId: String? = null override fun resumeWith(result: Result\u0026lt;String\u0026gt;) { this.result = result val res = try { val r = printUser(token, this) if (r == COROUTINE_SUSPENDED) return Result.success(r as Unit) } catch (e: Throwable) { Result.failure(e) } completion.resumeWith(res) } } 함수의 오퍼레이션이 변경됨 마지막 인자로 continuation이 생김 continuation은 현재 코루틴의 상태를 가지고 있는 상태머신임 항상 function의 마지막 인자로 추가됨 return 타입이 Any로 변경됨 Any?로 바뀌는 이유는 실제 리턴타입 뿐만아니라, suspend된다면 COROUTINE_SUSPENDED을 반환해야하기 때문 추후 kotlin에 유니온 타입이 추가된다면 User?|COROUTINE_SUSPENDED가 될 수 있음\n5번 라인, Continuation이 해당 함수의 Continuation인지 확인하고, 아니라면 생성\nresume될떄는 해당 함수의 Continuation이므로, 처음 실행될때만 생성함 11,12,13번 라인, 지역변수들을 선언하고, 값을 대입\n11번 result변수는 직전에 호출한 suspend 함수의 결과 가짐 12번 userId는 여러 단계(1,2)에 걸쳐서 필요하므로 Continuation에 저장됨 13번 userName은 한번의 단계에서만 사용하므로 result로 가져올수 있어 따로 저장되지 않음 Continuation은 label을 가짐\nlabel로 현재 어디까지 코드가 진행되었는지 파악하고, 다음 실행때 어디부터 시작할지 결정함 suspend된다면, COROUTINE_SUSPENDED을 리턴 후 중단이 끝난 후 다시시작함\nio작업이 발생한다면 작업을 끝내지 못하므로 우선 COROUTINE_SUSPENDED을 리턴함 suspend이후 resume된다면, PrintUserContinuation의 resumeWith가 호출됨\n22번 라인과 56번라인이 동일 기능을 함 앞서 말한다로 직전에 호출한 suspend 함수의 결과를 result변수에 넣음 콜스택 마지막에 있는 함수의 continuation이 supend후 resume되고, 작업을 다 끝마치면, 바로 상위 함수의 continuation의 resume을 호출함\nhttps://kt.academy/article/cc-under-the-hood\n","date":"2024-03-03T22:41:06Z","permalink":"https://sungho94.me/p/5-coroutine-cps/","title":"5-Coroutine  CPS"},{"content":" coroutine의 suspend는 게임을 일시 중단하는 것과 유사함 게임을 잠깐 중단했다가 resume하면 게임이 다시 시작됨 이것은 suspend와 유사 1 2 3 4 5 6 7 8 9 suspend fun main() { println(\u0026#34;Before\u0026#34;) suspendCoroutine\u0026lt;Unit\u0026gt; { continuation -\u0026gt; continuation.resume(Unit) } println(\u0026#34;After\u0026#34;) } suspend 만 있다면 중지되고 재시작되지 않음 suspend 후 작업을 재개하려면 suspend 내에서 continuation을 resume을 호출해야함 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 private val executor = Executors.newSingleThreadScheduledExecutor { Thread(it, \u0026#34;scheduler\u0026#34;).apply { isDaemon = true } } suspend fun delay(timeMillis: Long): Unit = suspendCoroutine { cont -\u0026gt; executor.schedule({ cont.resume(Unit) }, timeMillis, TimeUnit.MILLISECONDS) } suspend fun main() { println(\u0026#34;Before\u0026#34;) delay(1000) println(\u0026#34;After\u0026#34;) } // Before // (1 second delay) // After 위 코드는 delay 함수의 간략한 구현임 로직을 지연 후 재실행할때 쓰레드를 새로 생성하지 않고 지연이 가능 delay 함수는 타이머를 사용하여 설정된 시간이 지나면 resume을 수행합니다. delay를 실행하는 하나의 쓰레드만 존재 모든 delay를 하나의 스레드로 관리 delay를 100번해도 하나의 쓰레드로 관리되므로 쓰레드가 더 생성되지 않음 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 suspend fun requestUser(): User { return suspendCancellableCoroutine\u0026lt;User\u0026gt; { cont -\u0026gt; requestUser { resp -\u0026gt; if (resp.isSuccessful) { cont.resume(resp.data) } else { val e = ApiException( resp.code, resp.message ) cont.resumeWithException(e) } } } } suspend fun requestNews(): News { return suspendCancellableCoroutine\u0026lt;News\u0026gt; { cont -\u0026gt; requestNews( onSuccess = { news -\u0026gt; cont.resume(news) }, onError = { e -\u0026gt; cont.resumeWithException(e) } ) } } 위와같이 suspendCancellableCoroutine으로 성공시와 실패시 로직을 다르게 구현할 수 있음 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // Do not do this var continuation: Continuation\u0026lt;Unit\u0026gt;? = null suspend fun suspendAndSetContinuation() { suspendCoroutine\u0026lt;Unit\u0026gt; { cont -\u0026gt; continuation = cont } } suspend fun main() { println(\u0026#34;Before\u0026#34;) suspendAndSetContinuation() continuation?.resume(Unit) println(\u0026#34;After\u0026#34;) } // Before suspend은 함수를 중지하는것이 아닌, coroutine을 중지하는 것임 suspendAndSetContinuation에서 suspend후 바로 다음 라인(14번) continuation?.resume(Unit)이 실행되어 실행이 재개될 것 처럼 보이지만 재개되지 않음 https://kt.academy/article/cc-suspension\n","date":"2024-03-03T22:41:05Z","permalink":"https://sungho94.me/p/4-coroutine-suspend/","title":"4-Coroutine suspend"},{"content":" 이전의 이름음 java servlet임 eclipse재단과 oracle과의 상표권 분쟁으로 jakarta로 변경됨 링크 HTTP 요청과 응답을 처리하기 위한 서버측 api를 정의한것 링크 요청을 수신하고 요청에 따라 응답을 생성하는 객체에 대한 정의 요청과 관련된 3가지의 메소드가 존재 init 서블릿이 서비스에 배치되었다는것을 알리기 위해 서블릿컨테이너에서 호출 서블릿 컨테이너는 서블릿을 인스턴스 한 후 정확히 한번만 호출함 서블릿이 요청을 정상적으로 처리하기 위해서는 초기화가 성공적으로 완료되어야함 service 반드시 init 메소드가 호출된 이후에 호출됨 서블릿 컨테이너에서 호출하여 서블릿이 요청에 응답할 수 잇도록함 오류를 던지거나 전송하는 서블릿은 항상 상태코드를 전송해야함 서블릿은 일반적으로 여러 요청을 동시에 처리할 수 있는 멀티 스레드 컨테이너 내에서 실행됨 공유리소스에 대한 동기화에 대해 고려해야함 destroy 서블릿 컨테이너에서 호출하며, 서비스가 중단중임을 서블릿에 알림 서블릿의 서비스 메서드 내의 모든 쓰레드가 종료되거나 시간초과가 지난 후에 호출됨 destroy가 호출된 이후에는 service가 다시 호출되지 않음 ","date":"2024-03-03T22:41:05Z","permalink":"https://sungho94.me/p/4-jakarta-servlet/","title":"4-Jakarta Servlet"},{"content":" dispatcher의 사전적 정의 사람이나 차량, 특히 긴급 차량을 필요한 곳으로 보낼 책임이 있는 사람 코루틴에서는? 코루틴을 실행시킬 thread를 결정 코루틴을 실행시킬 쓰레드를 제한함 쓰레드 풀로 dipath하거나, unconfined한 상태로 실행할 수 있음 coroutine builder에서는 CoroutinContext를 optional하게 받는데 여기서 dispatcher를 인자로 받을 수 있음 CoroutineDispatcher는 RxJava의 Scheduler와 유사함\nDefault dispatcher 코루틴에서 아무것도 설정하지 않는다면 기본으로 제공되는 dispatcher CPU-intensive한 작업을 실행하기 위해 디자인됨 기본 thread개수는 최소 2개, 최대 cpu core수만큼 생성됨 이론상 cpu-intensive한 작업을 하고, blocking하지 않는다고 가정하면 최적의 개수임 limitedParallelism\n하나의 무거운 코루틴에서 모든 DefaultDispatcher를 사용하면 다른 코루틴에서 사용할 DefaultDispatcher가 부족할 수 있음\nlimitedParallelism을 사용해서 현재 코루틴에서 사용할 쓰레드 수를 제한할 수 있음\nIO Dispatcher 파일 읽기/쓰기, 네트워크 요청과 같은 I/O작업에 사용하기 위해 만들어짐 코어의 수에 따라 다르지만, 최대 64개 thread를 생성 thread 개수가 무제한이라면 쓰레드를 계속 생산할것이고, 쓰레드를 생성/삭제하는 것도 비용이므로 적절한 thread 수를 관리해야함 또한 thread가 무한정 생성하면 Out-Of-Memory가 발생 Default Dispatcher와 IO Dispatcher를 함께쓴다면? 1 2 3 4 5 6 7 8 suspend fun main(): Unit = coroutineScope { launch(Dispatchers.Default) { println(Thread.currentThread().name) withContext(Dispatchers.IO) { println(Thread.currentThread().name) } } } 풀을 공유하기에 Default Dispather안에서 IO Dispatcher를 사용한다고 redispatching이 발생하지 않음 하지만 서로의 limit은 공유하지않음 Default Dispather안에서 IO Dispatcher로 바꼈을때, thread는 변경되지 않지만, 서로가 서로를 고갈시키지 않기 위해, IO Dispathcer의 thread로 count함 limit을 공유하지 않으므로, Default Dispather과 IO Dispatcher를 동시에 최대로 사용했을떄, 8코어 환경에서는 (Default Dispather의 개수(8) + IO Dispatcher(64)) 쓰레드풀에 총 72개의 쓰레드가 관리됨 IO Dispatcher에서의 limitedParallelism IO Dispatcher에서 limitedParallelism는 다른 Dispatcher와 다르게 동작함 새로운 독립된 쓰레드 풀을 가진 Dispatcher를 생성함 원하는 만큼, 64개보다 더 많은 쓰레드를 지정할 수 있음 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import kotlinx.coroutines.* import kotlin.system.measureTimeMillis suspend fun main(): Unit = coroutineScope { launch { printCoroutinesTime(Dispatchers.IO) // Dispatchers.IO took: 2074 } launch { val dispatcher = Dispatchers.IO .limitedParallelism(100) printCoroutinesTime(dispatcher) // LimitedDispatcher@XXX took: 1082 } } ​ suspend fun printCoroutinesTime( dispatcher: CoroutineDispatcher ) { val test = measureTimeMillis { coroutineScope { repeat(100) { launch(dispatcher) { Thread.sleep(1000) } } } } println(\u0026#34;$dispatcher took: $test\u0026#34;) } IO Dispatcher에서 limitedParallelism을 사용하면 특정 작업을 위한 새로운 쓰레드 풀이 생성됨\nDefault Dispatcher에서는 limitedParallelism사용시 기존 쓰레드풀 내에서 특정작업을 위한 쓰레드개수를 지정함\n쓰레드에 대한 더 세밀한 조정을 위해 asCoroutineDispatcher함수로 dispatcher를 지정할 수 있음\n1 2 3 4 val NUMBER_OF_THREADS = 20 val dispatcher = Executors .newFixedThreadPool(NUMBER_OF_THREADS) .asCoroutineDispatcher() limitedParallelism(1)로 동시성 제어를 할 수 있음\nVirtualThread를 위한 지원도 있음\n1 2 3 val LoomDispatcher = Executors .newVirtualThreadPerTaskExecutor() .asCoroutineDispatcher() Unconfined Dispatcher 다른 Dispatcher들과 다르게 쓰레드를 변경하지 않음 Unconfined Dispatcher를 사용하면, suspend를 만날때까지 이를 실행한 쓰레드에서 작업이 시작됨 suspend 후 resume시에는 resume을 실행한 쓰레드에서 작업을 이어함 성능 측면에서는 쓰레드를 변경시키지 않아 유용할 수 있지만, main쓰레드를 중단할 수 있기에 추천되지 않음 일반적인 상황에서 유용하지 않음 Unit Test시 사용 Main dispatcher UI를 다루는 어플리케이션에서 사용하는거 ex) Android, JavaFx https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-dispatcher/\nhttps://kt.academy/article/cc-dispatchers\nhttps://medium.com/@wind.orca.pe/dispatchers-kotlin-coroutines-659a5681f329\nhttps://kotlinlang.org/docs/coroutine-context-and-dispatchers.html#dispatchers-and-threads\n","date":"2024-03-03T22:41:04Z","permalink":"https://sungho94.me/p/3-coroutindispatcher/","title":"3-CoroutinDispatcher"},{"content":" 새로운 coroutine에 대한 Scope를 정의함 \blaunch와 async와 같은 coroutine builder는 CoroutineScope의 확장함수임 팩토리 메서드인 CoroutineScope()와 MainScope()로 standalone CoroutineScope생성 더 이상 필요가 없을때는 메모리누수 방지를 위해 cancel을 사용해야함 모든 Coroutine builder(async, launch 등)와 모든 scope function(coroutineScope, withContext 등)은 실행하는 코드 내부 블록에 자체 Job 인스턴스와 함께 자신들의 scope를 제공 관습적으로 모든 coroutine builde와 scope function은 내부의 모든 coroutine이 완료될때까지 기다렸다가 완료하는 구조화된 동시성을 제공 https://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-scope/\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-scope/\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-coroutine-scope.html\n","date":"2024-03-03T22:41:03Z","permalink":"https://sungho94.me/p/2-coroutinescope/","title":"2-CoroutineScope"},{"content":"정의 Persistent context for the coroutine. It is an indexed set of Element instances. An indexed set is a mix between a set and a map. Every element in this set has a unique Key*\n코루틴의 영속 컨텍스트 Element 인스턴스의 색인된 set이고, 색인된 set은 set과 map을 합친것, set안에 있는 각각의 element는 unique Key를 가짐 CoroutineContext가 쓰이는곳 coroutine builder의 첫번째 파라미터 1 2 3 4 5 6 7 public fun CoroutineScope.launch( context: CoroutineContext = EmptyCoroutineContext, start: CoroutineStart = CoroutineStart.DEFAULT, block: suspend CoroutineScope.() -\u0026gt; Unit ): Job { ... } Coroutine Scope의 인자 1 2 3 public interface CoroutineScope { public val coroutineContext: CoroutineContext } Continuation의 인자 1 2 3 4 public interface Continuation\u0026lt;in T\u0026gt; { public val context: CoroutineContext public fun resumeWith(result: Result\u0026lt;T\u0026gt;) } 코루틴의 대부분의 곳에 쓰이므로 매우 중요한 요소임! 설명 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public interface CoroutineContext { public operator fun \u0026lt;E : Element\u0026gt; get(key: Key\u0026lt;E\u0026gt;): E? public fun \u0026lt;R\u0026gt; fold(initial: R, operation: (R, Element) -\u0026gt; R): R public operator fun plus(context: CoroutineContext): CoroutineContext{ ... } public fun minusKey(key: Key\u0026lt;*\u0026gt;): CoroutineContext public interface Key\u0026lt;E : Element\u0026gt; public interface Element : CoroutineContext { public val key: Key\u0026lt;*\u0026gt; public override operator fun \u0026lt;E : Element\u0026gt; get(key: Key\u0026lt;E\u0026gt;): E? = @Suppress(\u0026#34;UNCHECKED_CAST\u0026#34;) if (this.key == key) this as E else null public override fun \u0026lt;R\u0026gt; fold(initial: R, operation: (R, Element) -\u0026gt; R): R = operation(initial, this) public override fun minusKey(key: Key\u0026lt;*\u0026gt;): CoroutineContext = if (this.key == key) EmptyCoroutineContext else this } } 위의 코드는 CoroutineContext의 선언부를 간략화 한 것임\nCoroutineContext 내부에는 get, fold, plus, minusKey메서드와 Key, Element의 선언부가 잇음\nCoroutineContext는 minus, plus, fold와 같은 연산이 가능\nplus시에는 두개의 CoroutineContext내부의 Key가 합쳐짐 두개의 CoroutineContext가 같은 \bKey를 가지고 있다면 더하는 쪽의 키가 우선임 같은 키를 가지고 있을때 더하면 항상 새로운 키가 저장됨 두개의 CoroutineContext합치면, CombinedContext가 됨 CombinedContext는 CoroutineContext의 구현 중 하나임 CombinedContext는 내부에 CoroutineContext타입의 left필드가 존재 CombinedContext에서 getKey를 호출하면, left를 반복호출하여 해당하는 키가 있는지 찾고 없으면 null 리턴 CoroutineContext가 여러 Key를 가지고 있을 수 있는 이유임 Element는 Context를 상속받는 요소\nElement의 구현으로는 Job, CoroutineName, CouroutineDispatcher등 여러가지가 존재 각 Element는 Key로 식별이 가능하며, 각 Key는 참조로 비교됨 하위 context에서 같은키를 가지고 있다면, 하위 context의 키가 우선함 참고자료\nhttps://kt.academy/article/cc-coroutine-context\nhttps://kotlinlang.org/api/latest/jvm/stdlib/kotlin.coroutines/-coroutine-context/\nhttps://kotlinlang.org/api/kotlinx.coroutines/kotlinx-coroutines-core/kotlinx.coroutines/-global-scope/coroutine-context.html\nhttps://kotlinlang.org/api/latest/jvm/stdlib/kotlin.coroutines/-coroutine-context/-element/\nhttps://github.com/JetBrains/kotlin/blob/0938b46726b9c6938df309098316ce741815bb55/libraries/stdlib/src/kotlin/coroutines/CoroutineContext.kt#L59\n","date":"2024-03-03T22:41:02Z","permalink":"https://sungho94.me/p/1-coroutinecontext/","title":"1-CoroutineContext"},{"content":" 작은 쓰레드, 하나의 쓰레드를 어떻게 효율적으로 처리할것인가에 대한 방안 중 하나 block작업(io요청)이 발생했을때, thread를 block하지않고 해당 작업을 suspend시키고 다른작업을 처리함 Asynchronous or non-blocking programming is an important part of the development landscape. When creating server-side, desktop, or mobile applications, it\u0026rsquo;s important to provide an experience that is not only fluid from the user\u0026rsquo;s perspective, but also scalable when needed.\nKotlin solves this problem in a flexible way by providing coroutine support at the language level and delegating most of the functionality to libraries.\nIn addition to opening the doors to asynchronous programming, coroutines also provide a wealth of other possibilities, such as concurrency and actors.\nhttps://kotlinlang.org/docs/coroutines-overview.html ","date":"2024-03-03T22:41:01Z","permalink":"https://sungho94.me/p/0-coroutine/","title":"0-Coroutine"},{"content":" 여러 트랜잭션이 동시에 변경을 수행하고 쿼리를 수행할 때 성능과 안정성, 일관성 및 결과 재현성 간의 균형을 미세 조정하는 설정 Read Uncommitted 가장 낮은 격리 수준 커밋되지 않은 다른 트랜잭션의 변경 내용을 읽을 수 있음 어떤 트랜잭션의 변경 내용이 COMMIT이나 ROLLBACK과 상관없이 다른 트랜잭션에서 보여짐 Read Committed 다른 트랜잭션에서 커밋되지 않은 데이터는 읽을수 없음 Dirty Read(더티 리드)문제는 해결되지만, Phantom Read(유령 읽기) 문제는 발생함 REPEATABLE READ 한 트랜잭션 내에서 같은 쿼리를 여러 번 실행했을 때, 항상 동일한 결과를 얻을 수 있음\n첫번째 읽기 작업이 이루어진 때를 기준으로 스냅샷을 생성함\nInnoDB의 default isolation level임\nSerializable 어떤 한 트랜잭션이 데이터를 읽었다면, lock을 걸어 이 트랜잭션이 끝날때까지 다른트랜잭션이 읽기, 쓰기가 불가능하도록 하는 level\nautocommit이 활성화 되어있지 않으면, select 문을 select \u0026hellip; for share 문으로 변경함\nMysql doc을 보고 작성했으며, ANSI Isolation level이 궁금하다면 참고\nhttps://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_isolation_level\nhttps://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_serializable\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/10-isolation-level%EA%B2%A9%EB%A6%AC-%EC%88%98%EC%A4%80/","title":"10-Isolation level(격리 수준)"},{"content":" 데이터의 변경단위로 다루는 연관 객체의 묶음 Root Entity와 Boundary Entity가 존재 Root Entity 전역 식별성을 가짐 Boundary Entity 지역 식별성을 가짐 매우 상대적인 개념\n자동차와 바퀴의 예시\n자동차에만 관심만 있고 바퀴에 대한 관심사가 따로 없을 경우, 루트엔티티는 자동차, 경계 엔티티는 바퀴가됨\n하지만 바퀴의 수명주기, 일련번호 어떤 타이어를 찾아 어느 자동차에 있는지 알아야하는 비즈니스가 생긴다면 바퀴또한 루트 엔티티가 될 수 있음\nAggregate에 적용되어야 하는 규칙 루트 Aggregate는 전역 식별성을 가지며 궁극적으로 불변식을 검사할 책임이 있다. 경계안의 Entity는 지역식별성을 지니며, 이러한 지역식별성은 해당 Aggregate안에서만 유일하다. Aggregate 경계 밖에서는 루트 Entity를 제외한 Aggregate내부의 구성요소를 참조할 수 없다. Aggregate안의 객체는 다른 Aggregate의 루트만 참조할 수 있다. 삭제연산은 Aggregate안의 모든 요소를 제거해야 한다. Aggregate경계 안의 어떤 객체를 변경하더라도 전체 Aggregate의 불변식은 지켜져야 한다. ","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/aggregate/","title":"Aggregate"},{"content":"Factory Aggregate를 생성하는 일이 복잡하거나 내부구조를 너무 많이 드러내는 경우, Factory로 캡슐화\nFactory의 사용 이유\n객체 생성이 그 자체로 주요한 연산이 될 수 있지만 복잡한 조립 연산은 생성된 객체의 책임으로는 어울리지 않음\n이 책임을 클라이언트에 두면 클라이언트의 설계가 지저분해 지고 조립되는 객체나 Aggregate의 캡슐화가 위반됨\n클라이언트와 생성된 객체사이의 구현이 지나치게 결합됨\nFactory사용이 위와 같은 장점이 있지만, 복잡하지 않거나 다른 로직이 필요없을 경우 생성자로 대체\n우리는 복잡한 소프트웨어 구조를 적절한 패턴으로 덜 복잡하게 만드는게 목표임\n간단한 구조를 패턴을 사용할 경우 간단한게 복잡해 보일 수 있음\n트레이드 오프를 항상 생각하자\nRepository 객체를 재구성, 제거를 담당\n객체의 재구성이란?\n저장되어있는 객체로부터 인스턴스를 만들어내는 것\nAggregate내부에 존재하는 모든 객체는 루트에서부터 탐색을 토대로 접근할것\n팩토리는 객체의 생성을, 레포지토리는 객체의 재구성, 제거를 담당\n#Aggregate\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/aggregate-%EC%83%9D%EB%AA%85%EC%A3%BC%EA%B8%B0factory-repository/","title":"Aggregate 생명주기(Factory, Repository)"},{"content":"비동기 메시징 결합도를 낮춰줌 중간의 매개체를 통해 메시지를 전달하므로 수신자와 발신자가 서로를 몰라도 메시지 송/수신이 가능 publisher와 consumer가 서로를 알 필요가 없음 consumer수를 늘림으로써 가용성 확보가 가능해짐 consumer가 죽더라도 메시지 큐에 쌓이기 때문에 메시지 유실을 방지할 수 있음 방식 Database(Transaction Outbox Pattern) 구성 데이터베이스 테이블을 messaging box로 이용 해당 데이터 + 상태 로 구성됨 상태는 진행예정, 진행중, 완료 등의 상태가 있음 2번에서 outbox를 읽는 방법으로 polling이나 cdc를 사용하는 방법이 있음 polling시에는 relay서버가 해당 테이블을 주기적으로 확인 cdc를 사용한다면, cdc를 사용해 relay서버로 request보냄 응답성이 낮아도 되고, relay server 1개로 부하가 감당 가능할때 사용하기 좋음 장점 거의 모든 서비스가 데이터베이스를 사용하므로 추가 인프라가 필요 없음(비용절감) \u001e단점 다른 방식에 비해 느림 cdc를 사용하던 polling을 사용하던 늘미 relay서버 증설 시 부담이 있음 한테이블을 여러 서버가 읽을때 락관리를 어떻게 할것인가 깔끔하게 transaction level을 SERIALIZED로 올린다? 인스턴스가 2개 이상이면 lock을 걸어줘야함 스케일링시 부담있음 Redis Pub-sub subscriber가 해당 channel을 구독하고 있을때, publisher가 데이터를 publish하면 구독하고 있는 모든 subscriber에게 데이터를 전달함 subscriber가 존재하지 않는다면 따로 보관하지 않으므로 데이터는 사라짐 100프로 전송 보장이 되지 않아도 문제없는 케이스에서 사용하기 좋음 주로 채팅이나 푸쉬알림 등에 사용됨 장점 데이터를 따로 저장하지 않으므로 빠름 단점 컨슈머가 항상 해당 토픽을 확인하고 있어야하며 컨슈머가 없을시 데이터가 사라짐 Message queue(메시지큐) pull 방식과 push 방식이 존재 pull 방식은 컨슈머가 메시지큐에 요청을 보내 메시지를 가져와서 처리하는 방식 push방식은 메시지큐가 요청이 생겼을 때 컨슈머에게 메시지를 보내는 방식 메모리에 저장하는방식, 파일기반 저장방식, jdbc로 저장하는 방식이 있음 kafka, rabbitMQ, ZeroMQ, Pulsar, SQS 등이 존재 참고자료 https://blog.bytebytego.com/p/why-do-we-need-a-message-queue\nhttps://blog.iron.io/message-queue-vs-streaming/\nhttps://dreamix.eu/insights/message-queue-vs-message-broker-whats-the-difference/\nhttps://www.baeldung.com/pub-sub-vs-message-queues\nhttps://www.linkedin.com/pulse/differences-between-message-queue-event-stream-frank-lieu\nhttps://risingwave.com/blog/differences-between-messaging-queues-and-streaming-a-deep-dive/\nhttps://www.cloudamqp.com/blog/why-is-a-database-not-the-right-tool-for-a-queue-based-system.html\nhttps://stackoverflow.com/questions/48099098/message-broker-vs-database-and-monitoring\nhttps://docs.oracle.com/cd/E19636-01/819-3567/mq_service.html\nhttps://oliveyoung.tech/blog/2023-08-07/async-process-of-coupon-issuance-using-redis/BC\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/async-messaging/","title":"Async-messaging"},{"content":"Eviction 주기적으로 사용하지 않는 데이터를 삭제 주로 LRU(Least Recently Used)를 사용 Expiration 캐시가 만료되는 시간 Passivation 인메모리 캐시에서 지우기전, 다른 저장소(파일시스템, 데이터베이스)저장하는것 참고자료 https://access.redhat.com/documentation/es-es/jboss_enterprise_application_platform_common_criteria_certification/5/html/jboss_cache_user_guide/cl.pass\n#Cache\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/cache-passivation-expiration-eviction/","title":"Cache Passivation, Expiration, Eviction"},{"content":"어디에 저장할 것인가? In-memory caching 데이터를 데이터베이스나 디스크가 아닌 RAM에 저장하는 방식 높은 조회 성능을 가짐 비 휘발성, 서버가 종료되면 삭제됨 중요한 데이터를 보관하기 힘듦 정말 성능이 중요한 서버라면 RAM에 저장하고 분산 합의 알고리즘(ex. Raft 알고리즘)으로 분산해서 저장 Distributed caching 하나의 네트워크에 있는 서버, 노드들의 데이터를 한곳에 캐싱하는 \b방식 ex) Redis, memcached 높은 가용성과 확정성이 필요한 서비스에서 유용함 다른 지역에있는 데이터베이스의 정보를 가져오면 시간이 오래 걸리기에 지역마다 caching server를 두어 지역간 지연시간을 줄임 Client-Side caching 데이터를 사용자의 장비(ex. 웹브라우저)에 저장하는 방식 javaScript, image같은 정적 리소스에 자주 접근해야하는 경우 유용함 최신의 데이터가 아닌 옛날 데이터를 가져오지 않을 수 있기에, 정책과 만료시간을 잘 고려해야함 캐시 전략 Cache-Aside 캐시에서 데이터를 확인 후, 캐시에 데이터가 없다면 데이터베이스에 요청하는 방식 어플리케이션이 캐시 관리의 책임을 가짐 캐시를 최신상태로 관리하도록 노력이 많이 필요함 한번에 많은 캐시를 refresh할때 부하가 발생할 수 있음 ex) 캐시서버가 재시작할떄, 모든 캐시를 12시에 초기화 할때 이때 캐시서버에 많은 부하가 갈 수 있으므로 재시작시에는 어플리케이션에 바로 연결하는 것보다는 캐시를 warming후 연결하는것이 부하가 적음 일정 시간에 초기화시 한번에 많은 부하가 갈 수 있으므로 정각에 모든 캐시를 초기화 하는것이 아닌, 무작위 텀을 두고 초기화 하는것이 부하가 적음 Read-Through 캐시에 데이터를 확인하고, 데이터가 없다면 데이터베이스를 읽어 캐시에 데이터를 작성하고 다시 캐시에서 데이터를 읽는 방식 어플리케이션에서는 캐시에서만 데이터를 읽음 Write-Through 쓰기작업시 캐시와 데이터베이스 두곳 모두에 데이터를 쓰는 방식 캐시에 항상 최신의 데이터가 있다는것을 보장 쓰기성능이 좋지 않음 비동기 처리로 쓰기성능을 향상시킬 수 있지 않을까?\nWrite-Behind 쓰기작업시 캐시에 데이터를 모아두었다가 쓰기성능이 증가됨 캐시를 제대로 관리하지 않으면 데이터 불일치가 발생할 수 있음 Write-Around 모든 데이터는 데이터베이스에 저장되고, 읽은 데이터만 캐시에 저장되는 방식 Cache miss가 발생하는 경우에만 캐시에 저장되므로 데이터 불일치가 발생할 수 있음 캐시 성능 분석 요소 hit rate 요청에서 얼만큼 데이터가 적절히 반환되었는가 판단 데이터의 일관성 데이터가 얼마나 일관되게 읽혀졌는지 실데이터와 불일치가 얼마나 적게 발생했는지 참고자료 https://medium.com/@mmoshikoo/cache-strategies-996e91c80303\nhttps://yoongrammer.tistory.com/101\n#Cache\n#Infrastructure\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/caching-strategy/","title":"Caching Strategy"},{"content":"domain model 현실세계의 해결하고싶은 문제를 프로그래밍 언어로 특정 측면을 구현한것\n특정측면인 이유는 비즈니스에 중요한것을 더 부각하고, 중요하지않은것을 적게 표현하거나 생략하기 때문\nEntity 해당 객체의 식별성을 가질경우 그 객체를 Entity라 한다\nEntity의 상대성 Entity는 매우 상대적이다.\n경기장 좌석이 지정석인 경우, 각 좌석들은 구분해야할 필요가 있기 때문에 식별성을 가진 Entity이다.\n경기장 좌석이 자유석일경우, 각 좌석들의 구분하지않는다. 이는 Entity가 아니다.\nVO 모델에 포함된 어떤 요소의 식별성이 아닌, 속성에만 관심이 있다면 vo라고 한다\n불변의 VO vo는 불변이다\nvo가 바뀔때 내부 속성이 바뀌는 것이 아닌, vo전체가 수정되어야 한다.\nbut 변경가능성을 허용하는 케이스가 존재한다.\nex) 자주 변경되는경우, 객체 생성이나 삭제에 비용이 많이드는 경우 등..\n도메인 엔티티란? 현실세게의 해결하고 싶은 문제를, 프로그래밍 언어적으로 구현한 모델인데, 식별성을 가지는것 식별성을 가지지 않는다면, VO라고 부름 성능 최적화를 위해 Fly Weight를 사용할 수도 있다\ndto는?\ndata transform object로 계층간, 혹은 메서드간 데이터 이동시, 변수가 너무 많아지는 것 보다는 묶어서 변수들을 조금 더 잘 표현하는 역할\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/entity-vo/","title":"Entity, VO"},{"content":"Service 도메인의 중대한 프로세스나 변환과정이 ENTITY나 VO의 고유한 책임이 아닌 연산을 선언하는 독립 인터페이스 모델\nEntity난 VO의 일부를 구성하는 것이 아닌, 도메인 개념과 연관되어 있음 인터페이스가 도메인 모델의 외적 요소의 측면에서 정의됨 연산이 상태를 갖고있지 않음 Service의 계층 응용 도메인 인프라스트럭처 계층 위 세개의 서비스 계층은 클린아키텍쳐에서도 나온다\n응용계층 - 어플리케이션용 계층\n도메인계층 - 도메인 계층\n인프라스트럭처 계층 - 외부 어플리케이션과 소통\n응용계층과 인프라 계층은 도메인을 감싸고 있다.\nwhy?\n도메인은 우리가 해결해야 하는 문제로 비즈니스에서 가장 중요한 영역이다.\n응용과 인프라가 변경된다고 도메인계층이 변경되서는 안되기 때문이다.\n#Software-design\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/service/","title":"Service"},{"content":" 기능에 대한 명세이다 내가 개발한 기능의 동작방법 및 현재 잘 동작하는것을 보증한다 다른사람이 수정시 기존의 동작을 보장 코드 퀄리티에 대한 보장이다 코드가 복잡하면 테스트짜기 어렵기 때문이다 하나의 메서드에 대해 테스트가 너무 많다면 해당 메서드가 기능이 너무 많지 않은지 확인 객체에 모킹할게 너무 많다면 객체가 너무 많은 일을 하고 있는지 확인 #eventually-update\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/test/","title":"Test"},{"content":"협력 어플리케이션의 기능을 구현하기 위해 수행하는 상호작용\n책임 객체가 협력에 참여하기 위해 수행하는 로직\n역할 객체가 어떤 특정한 협력 안에서 수행하는 책임의 집합\n","date":"2024-03-02T22:41:32Z","permalink":"https://sungho94.me/p/%ED%98%91%EB%A0%A5-%EC%B1%85%EC%9E%84-%EC%97%AD%ED%95%A0/","title":"협력, 책임, 역할"},{"content":" record의 index에 거는 lock primary index가 없는 테이블에도 가능\nprimary index가 없더라도 mysql에서는 hidden clustered index를 생성하기 때문\nMysql Doc에는 row락이라는 용어가 등장하지 않음,\n스택오버플로우에는 record lock과 row lock이 동일 하다는 이야기가 있음\nhttps://stackoverflow.com/questions/74967004/row-level-locks-vs-index-record-locks\nhttps://dev.mysql.com/doc/refman/8.0/en/InnoDB-locking.html\n","date":"2024-03-02T22:41:04Z","permalink":"https://sungho94.me/p/9-record-locks/","title":"9-Record Locks"},{"content":" IS, IX lock과 S,X Lock과의 차이는 테이블까지 락이 걸림\nIS, IX lock을 걸면 해당 테이블에도 락이 걸림\n해당 테이블에 대해 다른 트래잭션에서 같은 테이블의 다른 row에 IS,IX락은 걸 수 있지만, 같은 테이블에 대해 S,X Lock을 걸 수 없음(실험완료)\nS,X와 같이, IS가 걸려있으면 해당 테이블에 대해 S락은 가능, X락은 불가 S,X와 같이, IX가 걸려있으면 해당 테이블에 대해 S,X락 둘다 불가 읽기나 쓰기 도중 테이블이 변경되는것을 막기 위함이라고 추측함 SELECT ... FOR SHARE로 S Lock을, SELECT ... FOR UPDATE로 X락을 걸 수 있음\nIS lock추가\n- select .. lock in share mode ;\n- select .. for share ;\n- 현재(8.0 기준) for share가 lock in share mode를 대체 하려하나 하위호환성 보장을 위해 lock in share mode를 유지하는중\n- 그러나, for share를 사용하면 OF table_name, NOWAIT, and SKIP LOCKED를 사용할 수 있음 SELECT \u0026hellip; FOR SHARE is a replacement for SELECT \u0026hellip; LOCK IN SHARE MODE, but LOCK IN SHARE MODE remains available for backward compatibility. The statements are equivalent. However, FOR SHARE supports OF table_name, NOWAIT, and SKIP LOCKED options. See Locking Read Concurrency with NOWAIT and SKIP LOCKED.\nhttps://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_shared_lock\nhttps://dev.mysql.com/doc/refman/8.0/en/InnoDB-locking.html\n","date":"2024-03-02T22:41:03Z","permalink":"https://sungho94.me/p/8-intention-shared-lock-exclusive-lock/","title":"8-Intention shared lock, exclusive lock"},{"content":" 특정 행을 읽기위해 거는 락 어떤 object에 S-lock이 걸려있다면 다른 트랜잭션에서 읽기는 가능하지만 변경은 불가능함 S-lock이 걸려있는 object에 S-lock를 또 걸 수 있지만 \bX-lock은 걸 수 없음 https://dev.mysql.com/doc/refman/8.0/en/InnoDB-locking.html\n","date":"2024-03-02T22:41:02Z","permalink":"https://sungho94.me/p/7-shared-locks-lock/","title":"7-Shared Lock(S-lock)"},{"content":"1- X-Lock이 걸린 객체에 대해 다른 트랜잭션에서 읽기, 쓰기 불가능\nX-Lock이 걸린 객체에 대해 다른 객체에서 S-Lock, X-Lock 걸수 없음\n변경 또는 삭제를 위해 락을 걸떄 활용\nMysql의 Repeatable-Read는 Constent Read 기술을 사용해여 X-Lock걸린 row를 읽도록 함으로써 효율을 높임\nX-Lock이 걸리기 전의 값을 읽음 https://dev.mysql.com/doc/refman/8.0/en/InnoDB-locking.html\n","date":"2024-03-02T22:41:01Z","permalink":"https://sungho94.me/p/6-exclusive-lockx-lock/","title":"6-Exclusive Lock(X-Lock)"},{"content":" CAS(compare and Set)이라고도 함 데이터베이스 수준이 아닌 어플리케이션 수준에서 자원을 관리 record에 version관련 컬럼을 추가하여 자원을 관리 변경이 발생할때마다 version값에 1을 추가 0,1으로 하면 안됨 변경이 두번 발생하면 0,1,0이 되버리기 때문에 오류가 발생함 장점 데이터베이스에서 lock을 걸지 않기 때문에 pessimistic lock보다 데이터 베이스 부하가 적음 참고자료 https://en.wikipedia.org/wiki/Optimistic_concurrency_control\n","date":"2024-03-01T22:41:07Z","permalink":"https://sungho94.me/p/5-optimistic-lock/","title":"5-Optimistic Lock"},{"content":" 첫번째 읽을때 스냅샷을 생성함으로써, 다른 트랜잭션에서 발생한 변경과는 무관하게, 스냅샷을 생성했을 때의 데이터를 읽을수 있는 것을 말함\n다른 트랜잭션에서 데이터를 변경해도, \bundo log에 기록되어 변경전 데이터를 읽을 수 있음\n이로인해 동시성 문제를 해결\nundo log를 사용하지 않는다면, 어떤 row를 읽은 트랜잭션이 있다면 해당 트랜잭션이 끝날때 까지 해당 row를 접근하지 못하게 해야 일관된 읽기를 달성할 수 있음 하지만 undo log를 사용함으로 각각의 트랜잭션에서는 데이터를 자유롭게 변경해도, 변경전 데이터가 undo log에 있으므로, 변경된 데이터에 대해서는 undo log를 읽어와 일관된 읽기를 달성할 수 있음 REPEATABLE READ와 READ COMMITTED에서 기본으로 사용됨\nALTER TABLE문과 DROP TABLE문에서는 작동하지 않음\n참고자료 https://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_consistent_read\nhttps://dev.mysql.com/doc/refman/8.0/en/InnoDB-consistent-read.html\n","date":"2024-03-01T22:41:05Z","permalink":"https://sungho94.me/p/4-consistent-read%EC%9D%BC%EA%B4%80%EB%90%9C-%EC%9D%BD%EA%B8%B0/","title":"4-Consistent Read(일관된 읽기)"},{"content":" 동시성을 가지는 작업들이 공유하는 자원 여러 작업에서 하나의 자원에 대해 동시에 접근하면, 예기치 못한 동작이나 오류가 발생할 수 있음 여러 작업에서 하나의 자원을 동시에 엑세스를 방지하도록 보호해야함 엑세스를 방지해야하는 자원을 임계영역이라고 부름 참고자료 https://en.wikipedia.org/wiki/Critical_section\n#Concurrency\n","date":"2024-03-01T22:41:04Z","permalink":"https://sungho94.me/p/3-critical-section%EC%9E%84%EA%B3%84%EC%98%81%EC%97%AD/","title":"3-Critical section(임계영역)"},{"content":" 임계영역을 보호하는 방법\n여러 스레드의 임계영역에 대한 엑세스를 제어\nMutex와의 차이점은 Mutex는 하나의 자원에 대한 엑세스를 제어하는 반면, Semaphore는 여러자원에 대한 엑세스를 제어\n화장실이 3개이고 키도 3개일때\n키가 하나도 없다면 화장실 이용불가\n키가 1개 있다면 화장실 이용가능\n키가 2개 있어도 화장실 이용가능\nbut, 어느 화장실 칸이 비었는지 모르기에 추가적인 정보가 더 필요함\n추가적인 정보가 궁금하다면 여기\n참고자료 식사하는 철학자들 문제\nhttps://stackoverflow.com/a/2332868/22483906\nhttps://stackoverflow.com/questions/2350544/in-what-situation-do-you-use-a-semaphore-over-a-mutex-in-c/2350628#2350628\nhttps://stackoverflow.com/questions/34519/what-is-a-semaphore/40238#40238\n#Concurrency\n","date":"2024-03-01T22:41:03Z","permalink":"https://sungho94.me/p/2-semaphore/","title":"2-Semaphore"},{"content":" Mutual exclusion의 약자 프로세스 간 동기화에 사용할 수도 있는 동기화 기본 형식입니다. 둘 이상의 스레드가 동시에 공유 리소스에 액세스해야 하는 경우 시스템은 한 번에 하나의 스레드만 리소스를 사용하도록 하기 위한 동기화 메커니즘 공유 리소스에 대한 단독 액세스 권한을 하나의 스레드에만 부여하는 동기화 기본 형식입니다. 스레드가 뮤텍스를 획득하면 첫 번째 스레드가 뮤텍스를 해제할 때까지 해당 뮤텍스를 획득하려는 두 번째 스레드가 일시 중단됩니다. 화장실 비유 화장실에 가고싶은데 키가 하나밖에 없는경우 키가 있어야만 화장실에 갈 수 있음 화장실에 아무도 없다면 키를 가져갈 수 있음 화장실에 사람이 있다면, 사람이 나와 키를 줄때까지 기다려야함 Mutex와 Lock은 동일한 개념임\nMutex는 Lock보다는 시스템 전체에 적용될 수 있음\n참고자료 https://learn.microsoft.com/ko-kr/dotnet/api/system.threading.mutex?view=net-7.0#remarks\nhttps://en.wikipedia.org/wiki/Lock_(computer_science)\nhttps://stackoverflow.com/questions/2332765/what-is-the-difference-between-lock-mutex-and-semaphore\n","date":"2024-03-01T22:41:02Z","permalink":"https://sungho94.me/p/1-mutexlock/","title":"1-Mutex(Lock)"},{"content":"개념 프로그램, 알고리즘, 또는 문제의 부분이나 단위 등이, 결과에 영향을 주지 않고 특정한 순서없이 실행되거나 부분적인 순서만을 가지고 실행될 수 있는 성질 링크 하나의 작업을 정말 빠르게 처리하면 되지 않을까?\n대부분의 서비스에서는 cpu bound보다는 io bound가 많은 일을 처리하기에 동시성이 중요 동시성은 한번에 많은일을 처리하는것,\n병렬성은 한번에 많은 일을 하는것을 의미\n왜 중요한가? 한번에 여러가지 일을 처리하니 한번에 많은일을 처리할 수 있음 성능이 증대됨 But, 무결성의 문제 하나의 자원을 가지고 하나이상의 작업이 수행될때 자원의 무결성의 문제 Lost Update Problem(write-write conflict) 하나의 로우에 동시에 여러번 변경이 발생했을 때 발생하는 문제\nUnrepeatable Read Problem 다른 트랜잭션에서 변경이 되어, 같은 조회 쿼리에서 다른 데이터가 오는 현상\nTemporary Update Problem( dirty read problem) 커밋되지 않은 데이터를 읽어서 발생하는 문제\nPhantom Read Problem 데이터가 삭제되어 같은 트랜잭션에서 데이터를 못가져오는 문제\n해결책 동시성 문제는 어떻게 동시에 처리하지 않을까에 대한 고민 추상화한것들 어떻게 구체화 할것인가 개념\ncritical section mutex semaphore JAVA에서 코드레벨 lock 참고자료\nsynchronized lock Semaphore Guava’s Monitor 데이터베이스에서 동시성 문제 처리\nlock mode Shared Lock Exclusive Lock lock type row lock Record Lock Gap Lock Next-key Lock auto increment lock table lock insert intention lock isolation level \bNamed Lock\nredis database 참고자료 https://medium.com/@bindubc/distributed-system-concurrency-problem-in-relational-database-59866069ca7c\n","date":"2024-03-01T22:41:01Z","permalink":"https://sungho94.me/p/0-%EB%8F%99%EC%8B%9C%EC%84%B1concurrency/","title":"0-동시성(Concurrency)"},{"content":"https://docs.oracle.com/javase/tutorial/\n","date":"2024-02-27T18:04:24Z","permalink":"https://sungho94.me/p/java%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/","title":"java튜토리얼"},{"content":"Serial GC CPU 코어나 메모리가 적을 때 유용 하나의 서버에 여러 jvm이 실행되는 환경에서 유용 major GC와 minor GC가 serially하게 적용됨 mark-compact-swap 방식을 사용 오래된 메모리를 heap의 시작점에 두고, 새로 생성된 메모리를 heap의 마지막에 두어 새로 생성된 메모리가 연속적으로 할당되게함 -XX:+UseSerialGC 로 사용가능 Parallel GC 사용하는 알고리즘은 Serial GC와 같으나, 여러 스레드를 사용함\nCPU코어가 1개 이상일때 많을때 유용함\nCPU코어가 N개일때 N개의 garbage Collector를 사용\n옵션으로 garbage Collector개수 설정 가능 CPU코어가 1개인 환경에서는 Parallel GC를 사용하더라도 해당 Serial GC가 사용됨\nParallelGC는 2가지 가 있음\nParallelGC Old영역은 싱글스레드, Young 영역은 멀티스레드로 동작 Old영역의 compact도 싱글스레드로 동작 -XX:+UseParallelGC로 사용가능 ParallelOldGC Old영역, Young영역 둘다 멀티스레드로 동작 compact도 멀티스레드로 동작 -XX:+UseParallelOldGC로 사용가능 The Concurrent Mark Sweep (CMS) Collector tenured영역을 collect하는 GC GC를 애플리케이션 스레드와 동시에 수행하여 애플리케이션의 일시중단 시간을 최소화 하려함 live객체를 이동, 복사하거나 압축하지 않음\u001c 조각화가 문제가 되는경우 더 큰 힙을 할당해야함 -XX:+UseConcMarkSweepGC로 사용가능 거의 사용되지 않음 G1 GC 아래와 같이 바둑판 영역에 객체를 할당하고 GC를 실행함 해당 영역에 데이터가 꽉 차면 다른 영역에 객체를 할당하고 gc를 실행함 https://d2.naver.com/helloworld/1329\nhttps://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html\n","date":"2024-02-22T23:19:00Z","permalink":"https://sungho94.me/p/2-garbage-collection-types/","title":"2-Garbage Collection Types"},{"content":" 앞의 Garbage Collection Concept에서는 heap이 나누어져 저장되는 것을 이해함 여기서는 나누어져 저장되는 것들의 상호작용에 대해 알아봄 1. Object Allocation 모든 새 객체들은 Eden 영역에 할당됨 애플리케이션을 처음 시작한다면 두 survivor영역은 비어있음 2. Filling the Eden Space \bEden 영역이 꽉 찬다면, minor GC가 실행됨 3. Copying Referenced Objects Referenced 객체는 S0 servivor 영역으로 이동됨 Unreferenced 객체는 삭제됨 4. Object Aging 다음 miner GC때 3의 동작이 한번 더 발생됨 Referenced 객체는 suvivor 영역으로 이동하고, Unreferenced 객체는 삭제됨 3과 다른점은 S0에 존재했던 객체들이 S1영역 으로 간다는 것 S0에서 S1으로 이동한 객체는 이동하면서 1살을 더 먹음 miner GC가 발생하므로서 Eden과 S0은 비워지고 S1에만 객체가 존재함 5. Additional Aging 다음 minor GC때 4의 과정이 반복되며 나이를 먹음 S1에 있던 Referenced 객체들이 S0으로 이동하며 나이를 먹고, Eden과 S2 영역은 비워짐 6. Promotion - 1 계속 minor gc가 발생하고, 특정 임계값(예제에서는 8)을 넘은 객체들은 Old Generation(Tenured)영역으로 이동함 Promotion -2 minor GC가 계속 발생하면서 Old Generation으로 객체가 계속 승격됨 GC Process Summary 결국에는 Old Generation에도 객체가 꽉차고 major GC가 발생함 https://d2.naver.com/helloworld/1329\nhttps://d2.naver.com/helloworld/0128759\nhttps://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html\nhttps://developers.redhat.com/articles/2021/08/20/stages-and-levels-java-garbage-collection#generational_garbage_collection\nhttps://developers.redhat.com/articles/2021/09/09/how-jvm-uses-and-allocates-memory#how_to_check_the_thread_stack_size\n","date":"2024-02-22T23:15:48Z","permalink":"https://sungho94.me/p/1-garbage-collection-process/","title":"1-Garbage Collection Process"},{"content":" Garbage Collection 파트에서 Full garbage collection에 대한 추가 설명 직접 실험해보면서 체크필요 #wait-to-update\nhttps://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html\nhttps://dzone.com/articles/minor-gc-vs-major-gc-vs-full\n","date":"2024-02-22T23:11:30Z","permalink":"https://sungho94.me/p/full-garbage-collection/","title":"Full garbage collection"},{"content":" 1 2 3 4 5 6 7 8 SELECT DISTINCT column, AGG_FUNC(_column_or_expression_), … FROM mytable JOIN another_table ON mytable.column = another_table.column WHERE _constraint_expression_ GROUP BY column HAVING _constraint_expression_ ORDER BY _column_ ASC/DESC LIMIT _count_ OFFSET _COUNT_; 1. FROM and JOIN 전체 데이터 집합을 찾기 위해 FROM과 \bJOIN절이 먼저 실행됨 서브쿼리가 있다면 JOIN될 데이터 테이블을 만들기 위해 임시 테이블을 생성할 수 있음 2. WHERE 1에서 얻은 전체 데이터 집합의 각각의 row에 WHERE에 정의된 제약조건이 적용되고, 제약조건을 만족하지 않는 row는 버려짐 FROM절에서 요청된 테이블의 열에만 접근 가능 SELECT절의 Alias로 된 컬럼은 사용불가 아직 실행되지 않은 부분에 의해 값이 바뀔 수 있으므로 당장 처리하지 않음 3. GROUP BY 2에서 제약조건을 충족한 row들을 GROUB BY에 지정된 컬럼의 공통값으로 그룹화됨 지정된 컬럼의 고유한 개수만큼 row가 생성됨 4. HAVING 3에서 그룹화된 테이블은 2와 마찬가지로 제약조건을 적용하여 제약조건을 만족하지 않는 row는 버려짐 2와 마찬가지로 Alias로된 컬럼은 사용 불가 5. SELECT SELECT부분의 모든 표현식이 최종적으로 계산됨 6. DISTINCT 5에서나온 데이터에서 DISTINCT로 표시된 컬럼의 중복값이 제거됨 7. ORDER BY 지정된 데이터를 따라 오름차순 또는 내림차순으로 정렬됨 쿼리의 SELECT절이 수행되었으므로 SELECT의 Alias로 정렬 가능 8. LIMIT, OFFSET LIMIT 및 OFFSET으로 지정된 범위를 벗어나는 행은 삭제되고 최종 결과값만 남음 https://sqlbolt.com/lesson/select_queries_order_of_execution\n#Database\n#Query\n","date":"2024-02-19T23:19:10Z","permalink":"https://sungho94.me/p/%EC%BF%BC%EB%A6%AC-%EC%8B%A4%ED%96%89-%EC%88%9C%EC%84%9C/","title":"쿼리 실행 순서"},{"content":" 메모리 관리 기법중 하나로 프로그램이 동적으로 할당했던 메모리 영역 중에서 필요없게된 영역을 해제하는 기능 Reference counting이 0이되면 삭제함 Garbage Collection 과정 Step 1. Marking Garbage Collector가 메모리 조각중에서 사용되고 있는 것과 사용되지 않는것을 찾아 marking하는 단계\n그림에서 참조된 객체는 blue, 참조되지 않은 객체는 주황색임 marking단계에서는 삭제를 하기 위한 객체를 찾는 과정 시스템을 모두 스캔해야 하는 경우 시간이 많이 소요될 수 있음 Step 2. Normal Deletion Step 1에서 찾은 객체를 삭제하는 단계\nmemory allocator는 새 객체를 할당 할 수 있는 여유 공간 블록에 대한 참조를 보유 memory allocator는 비어있는 공간에 대한 참조를 가지고, 할당이 필요한 비어있는 공간을 검색 Step 2a. Deletion with Compacting 추가적인 성능 향상을 위해, 참조되지 않는 객체를 삭제하면서 남아있는 참조 객체를 압축할 수 있음 참조된 \b객체를 함께 이동함으로써, 메모리 할당은 더 빠르고 쉬워짐\nMemory Allocator는 비어있는 공간에 대한 첫번째 참조를 가지고, 메모리를 순차적으로 할당 Generation Garbage Collection JVM의 모든 객체를 marking하고 compact하는것은 비효율적임 시간이 지날수록 객체의 숫자는 늘어가며 이에따라 garbage collection의 시간은 증가할것임 하지만 대부분의 객체의 수명은 짧기에 Generation Garbage Collection을 사용함 경험적으로 증명됨 위의 그래프에서 알 수 있듯이 대부분의 객체의 수명은 짧고, 시간이 지남에 따라 객체의 숫자가 줄어든다는 것을 파악할 수 있음 JVM heap은 위와 같이 3가지 구역(Young, Old, Permanent)으로 나뉨 Yong Generation 새로운 객체가 할당되고, aged되는 곳 Yong Generation이 가득차면 minor gc가 발생함 minor gc는 객체의 사망률이 높을때 최적화됨 dead object는 빠르게 수거됨 살아남은 일부 객체는 Old Generation으로 이동함 minor gc가 발생할때 Stop-the-world가 발생함 Stop-the-world가 발생하면 모든 어플리케이션의 쓰레드가 중지됨\nOld Generation\n오래 살아남은 객체가 저장되는곳 Yong Generation에는 임계값이 존재하고 임계값을 넘어서 생존하는 경우 Old Generation으로 이동함 언젠간 Old Generation에도 Garbage Collection이 발생해야 하고 이것을 major GC로 명명함 major gc에서도 Stop-the-world가 발생함 major gc는 모든 살아있는 객체를 대상으로 하기에 느림 반응형 애플리케이션에서는 major gc가 최소한으로 발생해야함 major gc는 Old Generation에서 사용하는 garbage collector 종류에 따라 Stop-the-world의 시간이 결정됨 Permanent Generation\nJVM의 class와 Method를 describe하기 위한 메타데이터가 저장됨 Permanent Generation는 어플리케이션에서 사용중인 클래스를 기반으로 런타임에 JVM에 의해 채워짐 Java SE 라이브러리 클래스 및 메서드가 채워질 수 있음 JVM이 더 이상 필요없다고 판단하거나, 다른 클래스를 위한 공간이 필요할경우 unload될 수 있음 Permanent Generation은 full garbage collection에 포함됨 full garbage collection이란?\nhttps://d2.naver.com/helloworld/1329\nhttps://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html\n","date":"2024-02-19T13:24:16Z","permalink":"https://sungho94.me/p/0-garbage-collection-concept/","title":"0-Garbage Collection Concept"},{"content":"https://teachyourselfcs.com/\nhttps://github.com/minnsane/TeachYourselfCS-KR\nhttps://missing.csail.mit.edu/\n","date":"2024-02-06T23:14:22Z","permalink":"https://sungho94.me/p/%EC%BB%B4%ED%93%A8%ED%84%B0%EA%B3%BC%ED%95%99-%EC%8A%A4%EC%8A%A4%EB%A1%9C-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0/","title":"컴퓨터과학 스스로 학습하기"},{"content":" 1 SELECT @@InnoDB_buffer_pool_size/1024/1024/1024; ","date":"2024-02-06T16:25:30Z","permalink":"https://sungho94.me/p/%EB%B2%84%ED%8D%BC%ED%92%80-%ED%81%AC%EA%B8%B0-%ED%99%95%EC%9D%B8-%EC%BF%BC%EB%A6%AC/","title":"버퍼풀 크기 확인 쿼리"},{"content":" 1 2 3 4 5 6 7 SELECT table_name AS \u0026#39;TableName\u0026#39;, ROUND(SUM(data_length+index_length)/(1024*1024), 2) AS \u0026#39;All(MB)\u0026#39;, ROUND(data_length/(1024*1024), 2) AS \u0026#39;Data(MB)\u0026#39;, ROUND(index_length/(1024*1024), 2) AS \u0026#39;Index(MB)\u0026#39; FROM information_schema.tables GROUP BY table_name ORDER BY data_length DESC; ","date":"2024-02-06T16:24:56Z","permalink":"https://sungho94.me/p/%ED%85%8C%EC%9D%B4%EB%B8%94-%ED%81%AC%EA%B8%B0-%ED%99%95%EC%9D%B8%ED%95%A0-%EC%BF%BC%EB%A6%AC/","title":"테이블 크기 확인할 쿼리"},{"content":" dms로 운영-\u0026gt;스테이지 디비 마이그레이션 하는데 인덱스가 사라져서 인덱스 추가를 위해 정보를 찾아보았다. 직접 index를 넣어주는 방법과 AWS Schema Conversion Tool(AWS SCT)를 사용하는게 있었음 macOS를 따로 지원하지 않아 mysqldump를 사용하여 스키마를 설정하기로함 방법 5.7.mysql_aurora.2.11.2 대상 mysql버전에 맞는 mysqldump가 필요 현재 로컬컴퓨터에 설치된 mysql버전과 대상 데이터베이스 버전이 다르다면 대상 데이터베이스 버전의 mysql-client 설치 필요 데이터 덤프 데이터를 가져올 데이터베이스 1 mysqldump -u [유저명] -P [포트] -h [호스트명] --no-data -p --databases [스키마명] \u0026gt; schema.sql 데이터 복구 데이터를 넣을 데이터베이스 1 mysql -u [유저명] -p -P [포트번호] -h [호스트명] \u0026lt; schema.sql 1 ERROR 1227 (42000) at line 1715: Access denied; you need (at least one of) the SUPER privilege(s) for this operation 이런 에러가 날 수 있다\n해당 라인(예제에서는 1715라인)을 확인해서 삭제 or 주석처리 하거나 아래 링크를 참고하면 됨\naws에서 제공하는 아래 가이드가 있는데 효과가 있지 않았음\nhttps://aws.amazon.com/ko/premiumsupport/knowledge-center/error-1227-mysqldump/\n에러에 대한 정보 에러가 나는 라인은 아래 3줄이다 언뜻 보면 세개의 변수에 특정값을 넣는건데 어떤 의미일까 찾아보았 1 2 3 SET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN; SET @@SESSION.SQL_LOG_BIN= 0 SET @@GLOBAL.GTID_PURGED=\u0026#39;\u0026#39;; 1 2 SET @MYSQLDUMP_TEMP_LOG_BIN = @@SESSION.SQL_LOG_BIN; SET @@SESSION.SQL_LOG_BIN= 0 먼저 이 두줄은 SESSION.SQL_LOG_BIN 변수를 수정하기 위한 옵션이다 첫번째줄은 원래 설정으로 돌리기 위해 SESSION.SQL_LOG_BIN값을 MYSQLDUMP_TEMP_LOG_BIN에 임시로 저장한다 두번째줄이 핵심인데 SESSION.SQL_LOG_BIN를 0, false값으로 변경한다 sql_log_bin은 현재 세션에서 바이너리 로그에 대한 로깅을 활성화할지 여부를 제어 off로 설정시 현재 세션에서 바이너리 로그를 로깅하지 않음 세션뿐만아니라 글로벌로 적용 가능 sql_log_bin값을 변경하려면 SUPER권한이 필요한데 없어서 에러가 발생하는 GLOBAL.GTID_PURGED는 선행지식이 좀 필요해보여 넘김\n시간날때 더 공부해보자 에러 참고 링크\nhttps://stackoverflow.com/questions/60320794/aws-rds-mysql-import-db-access-denied\nhttps://dev.mysql.com/doc/refman/8.0/en/set-sql-log-bin.html\nhttps://dev.mysql.com/doc/refman/8.0/en/replication-options-gtids.html#sysvar_gtid_purged\n참고자료\nhttps://serverfault.com/questions/934879/copying-over-indexes-with-aws-dms\nhttps://www.lesstif.com/dbms/mysqldump-db-backup-load-17105804.html\nhttps://stackoverflow.com/questions/44015692/access-denied-you-need-at-least-one-of-the-super-privileges-for-this-operat\nhttps://medium.com/@pushkarjoshi0410/solved-aws-rds-import-you-need-super-privilege-s-71e350b41989\n","date":"2024-01-29T22:59:24Z","permalink":"https://sungho94.me/p/mysqldmup/","title":"mysqldmup"},{"content":"Spring handler에 대해 공부하던 중, 실제로 어떻게 동작하는지 궁금하여 알아보았습니다.\nDispatcherServlet의 doDispatch는 요청을 핸들러로 실제로 디스패치 하는 메서드입니다\n먼저 request로 getHandler메서드에서 매핑된 핸들러를 가져옵니다\n이후 해당 핸들러를 사용하여 HandlerAdaptor를 들거와서 핸들링합니다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { ModelAndView mv = null; Exception dispatchException = null; try { processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) { noHandlerFound(processedRequest, response); return; } // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); ... // Actually invoke the handler. mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) { return; } applyDefaultViewName(processedRequest, mv); mappedHandler.applyPostHandle(processedRequest, response, mv); ... } getHander메서드에서는 현재 인스턴스의 handlerMappings에 존재하는 mapping에서 현재 request를 인자로 getHandler요청을 호출합니다\nmapping의 getHandler는 AbstractHandlerMapping의 getHandler를 사용합니다\n1 2 3 4 5 6 7 8 9 10 11 protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { if (this.handlerMappings != null) { for (HandlerMapping mapping : this.handlerMappings) { HandlerExecutionChain handler = mapping.getHandler(request); if (handler != null) { return handler; } } } return null; } AbstractHandlerMapping의 getHandler는 getHandlerInternal을 호출하여 handler를 가져옵니다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { Object handler = getHandlerInternal(request); if (handler == null) { handler = getDefaultHandler(); } if (handler == null) { return null; } // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); } // Ensure presence of cached lookupPath for interceptors and others if (!ServletRequestPathUtils.hasCachedPath(request)) { initLookupPath(request); } HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); ..... return executionChain; } getHandlerInternal에서는 \brequest를 확인하여 lookupPath를 만들고, lookupHandlerMethod메서드를 통해 HandlerMethod를 가져옵니다\n1 2 3 4 5 6 7 8 9 10 11 protected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception { String lookupPath = initLookupPath(request); this.mappingRegistry.acquireReadLock(); try { HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request); return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null); } finally { this.mappingRegistry.releaseReadLock(); } } path와 request를 가지고 HandlerMethod를 확인합니다.\ngetMappingsByDirectPath메서드를 사용하여 path와 직접 되는 매핑을 확인하고 matches list에 넣습니다 없다면 mapping registry에서 모든 매핑정보를 가져와 확인합니다. 매핑후 matches list의 개수에 따라 1개를 초과한다면정렬을 하고, 첫번째와 두번째 mapping의 우선순위가 없다면 IllegalStateException를 리턴합니다 없다면 null을 리턴합니다 1개만 존재한다면 매칭된 핸들러 메소드를 리턴합니다 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 protected HandlerMethod lookupHandlerMethod(String lookupPath, HttpServletRequest request) throws Exception { List\u0026lt;Match\u0026gt; matches = new ArrayList\u0026lt;\u0026gt;(); List\u0026lt;T\u0026gt; directPathMatches = this.mappingRegistry.getMappingsByDirectPath(lookupPath); if (directPathMatches != null) { addMatchingMappings(directPathMatches, matches, request); } if (matches.isEmpty()) { addMatchingMappings(this.mappingRegistry.getRegistrations().keySet(), matches, request); } if (!matches.isEmpty()) { Match bestMatch = matches.get(0); if (matches.size() \u0026gt; 1) { Comparator\u0026lt;Match\u0026gt; comparator = new MatchComparator(getMappingComparator(request)); matches.sort(comparator); bestMatch = matches.get(0); ... else { Match secondBestMatch = matches.get(1); if (comparator.compare(bestMatch, secondBestMatch) == 0) { Method m1 = bestMatch.getHandlerMethod().getMethod(); Method m2 = secondBestMatch.getHandlerMethod().getMethod(); String uri = request.getRequestURI(); throw new IllegalStateException( \u0026#34;Ambiguous handler methods mapped for \u0026#39;\u0026#34; + uri + \u0026#34;\u0026#39;: {\u0026#34; + m1 + \u0026#34;, \u0026#34; + m2 + \u0026#34;}\u0026#34;); } } } request.setAttribute(BEST_MATCHING_HANDLER_ATTRIBUTE, bestMatch.getHandlerMethod()); handleMatch(bestMatch.mapping, lookupPath, request); return bestMatch.getHandlerMethod(); } else { return handleNoMatch(this.mappingRegistry.getRegistrations().keySet(), lookupPath, request); } } addMatchingMappings을 따라가다보면 getMatchingCondition메서드를 만납니다\n메서드, 파라미터, 헤더, path 등을 확인하며 RequestMappingInfo를 리턴합니다 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public RequestMappingInfo getMatchingCondition(HttpServletRequest request) { RequestMethodsRequestCondition methods = this.methodsCondition.getMatchingCondition(request); if (methods == null) { return null; } ParamsRequestCondition params = this.paramsCondition.getMatchingCondition(request); if (params == null) { return null; } .... RequestConditionHolder custom = this.customConditionHolder.getMatchingCondition(request); if (custom == null) { return null; } return new RequestMappingInfo(this.name, pathPatterns, patterns, methods, params, headers, consumes, produces, custom, this.options); } getHandlerInternal에서 가져온 handlerMethod를 인자로 getHandlerExecutionChain호출하는데 HandlerExecutionChain에서 interceptor를 적용합니다\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 public final HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { Object handler = getHandlerInternal(request); if (handler == null) { handler = getDefaultHandler(); } if (handler == null) { return null; } // Bean name or resolved handler? if (handler instanceof String) { String handlerName = (String) handler; handler = obtainApplicationContext().getBean(handlerName); } // Ensure presence of cached lookupPath for interceptors and others if (!ServletRequestPathUtils.hasCachedPath(request)) { initLookupPath(request); } HandlerExecutionChain executionChain = getHandlerExecutionChain(handler, request); ..... return executionChain; }``` HandlerExecutionChain메서드 ```java protected HandlerExecutionChain getHandlerExecutionChain(Object handler, HttpServletRequest request) { HandlerExecutionChain chain = (handler instanceof HandlerExecutionChain ? (HandlerExecutionChain) handler : new HandlerExecutionChain(handler)); for (HandlerInterceptor interceptor : this.adaptedInterceptors) { if (interceptor instanceof MappedInterceptor) { MappedInterceptor mappedInterceptor = (MappedInterceptor) interceptor; if (mappedInterceptor.matches(request)) { chain.addInterceptor(mappedInterceptor.getInterceptor()); } } else { chain.addInterceptor(interceptor); } } return chain; } ","date":"2024-01-28T13:54:21Z","permalink":"https://sungho94.me/p/servlet%EC%97%90%EC%84%9C-handler%EC%99%80-interceptor%EA%B0%80-%EC%A0%81%EC%9A%A9%EB%90%98%EB%8A%94-%EA%B3%BC%EC%A0%95/","title":"Servlet에서 handler와 interceptor가 적용되는 과정"},{"content":"debugging시 break point를 걸고 Tread dump를 캡처했는데 해당 쓰레드가 나타나지 않건, 스택트레이스를 확인하지 못하는 경우가 있다.\n이때 force return을 사용하면 해당 메서드를 바로 리턴하고, 호출한 곳을 확인할 수 있음\n","date":"2024-01-28T13:50:29Z","permalink":"https://sungho94.me/p/%EB%94%94%EB%B2%84%EA%B9%85/","title":"디버깅"},{"content":"먼저 Handler란, 특정 유형의 데이터에 특화되어 있거나, 특정한 작업에 초점에 맞춘 루틴/함수/메서드입니다.\n스프링에서 handlerAdaptor를 제공하는데, handlerAdaptor는 HTTP요청을 쉽게 처리할 수 있는 인터페이스입니다.\nHandlerMapping으로 특정 URL에 매핑됩니다.\nDispatcherServlet은 handlerAdaptor를 통해 Handler를 실행하고, 이로인해 DispatcherServlet과 Handler는 느슨한 연결을 유지할 수 있습니다.\n1 2 3 4 5 6 7 8 9 public interface HandlerAdapter { boolean supports(Object handler); ModelAndView handle( HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; long getLastModified(HttpServletRequest request, Object handler); } support메서드는 handle메서드를 호출하기 전, 인자로 받은 handler를 처리할 수 있는지 여부를 판단합니다\nhandle메서드는 실제로 HTTP요청을 처리하는 부분입니다.\ngetLastModified는 Deprecated되었습니다\nhttps://stackoverflow.com/questions/195357/what-is-a-handler\nhttps://www.baeldung.com/spring-mvc-handler-adapters\nhttps://www.baeldung.com/spring-handler-mappings\nhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/servlet/HandlerAdapter.html#getLastModified(jakarta.servlet.http.HttpServletRequest,java.lang.Object)\n","date":"2024-01-28T10:42:53Z","permalink":"https://sungho94.me/p/handler/","title":"Handler"},{"content":" 주어진 요청의 컨텍스트 내에서 메서드 매개 변수를 인수 값으로 해석하는 전략을 제공하는 Spring의 인터페이스 아래의 두 메서드가 있음 supportsParameter 해당 파라미터가 다른 변경이 일어나야 하는지 여부를 판단하는 파라미터입니다 해당 파라미터를 변경여부를 판단 resolveArgument 메서드의 주어진 파라미터를 resolve함 handler의 파라미터를 변경함 https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/web/method/support/HandlerMethodArgumentResolver.html\n","date":"2024-01-27T23:38:07Z","permalink":"https://sungho94.me/p/handlermethodargumentresolver/","title":"HandlerMethodArgumentResolver"},{"content":"handlerMapping의 구현으로 특정요청에 대해 특정 기능을 적용할때 사용합니다\n아래 3가지 메소드가 존재합니다\npreHandle 핸들러가 실행되기 전 실행됩니다 boolean을 리턴하는데, true를 리턴하면 이후 실행이 계속되지만, false나 예외를 리턴하면 이후의 interceptor 및 핸들러를 실행하지 않습니다 postHandle 핸들러가 실행된 후 실행됩니다 afterCompletion 모든 완료된 후 실행됩니다 vs Filter Filter와의 차이점으로 Filter는 \bDispatcher Servlet이 실행되기전 적용됩니다 Interceptor는 Dispatcher Servlet이 실행된 후 호출이 됩니다 Filter는 전체 수명주기를 대상으로하는 작업에 적합함 deep-dive\nhttps://eclipse-ee4j.github.io/jersey.github.io/documentation/latest/filters-and-interceptors.html\nwebflux에서는 webfilter가 동일한 기능을 제공함\nhttps://docs.spring.io/spring-framework/reference/web/webmvc/mvc-servlet/handlermapping-interceptor.html\nhttps://docs.spring.io/spring-framework/reference/web/webmvc/mvc-config/interceptors.html\nhttps://gngsn.tistory.com/153\nhttps://docs.spring.io/spring-framework/reference/web/webflux/reactive-spring.html#webflux-filters\nhttps://stackoverflow.com/questions/35856454/difference-between-interceptor-and-filter-in-spring-mvc\n#Spring\n","date":"2024-01-27T23:13:55Z","permalink":"https://sungho94.me/p/interceptor/","title":"Interceptor"},{"content":"연관관계의 소유 소유라는 개념은, 외래키를 관리하는 주체를 의미함 단방향에서는 소유하는 쪽만 존재 양방향에서는 소유하는쪽과 그 반대쪽 둘다 존재 manyToOne에서는 many쪽이 소유측을 가지고 있음 oneToOne에서는 외래키가 있는쪽이 소유측임 ManyToMnay에서는 둘 다 소유측이 될 수 있음 mappedBy로 관계의 소유자인 엔티티의 속성 또는 필드를 지정함 Cascade ALL, DETACH, MERGE, PERSIST, REFRESH, REMOVE 가 있으며 ALL은 다른 모든 속성을 포괄하는 개념 부모엔티티의 변경이 발생할때 자식까지 전파할건지에 대한 여부 ex) CascadeType.Merge가 지정된경우 부모가 merge되면 자식도 merge됨\nFetchType 해당 필드를 가져올 시기를 결정 Lazy *ToMany(oneToMany,ManyToMany)의 default FetchType 해당 필드를 엑세스할때 가져옴 Eager *ToOne(ManyToOne,OneToOne)의 default FetchType 소유자의 로딩의 일부로 해당 필드를 가져옴 소유자 로딩시 바로 가져옴\n**fetch=EAGER가 의미가 있는 유일한 시나리오는 연관된 객체가 두 번째 수준 캐시에서 발견될 확률이 항상 매우 높다고 생각하는 경우. 꺠알팁\noneToMany, manyToOne설정된 필드에는 Column어노테이션 불가, joinColumn사용해야함\nhttps://docs.jboss.org/hibernate/orm/6.4/introduction/html_single/Hibernate_Introduction.html#associations\nhttps://docs.jboss.org/hibernate/orm/6.4/userguide/html_single/Hibernate_User_Guide.html#associations-many-to-one\nhttps://docs.oracle.com/javaee/7/tutorial/persistence-intro001.htm#JEETT01154\n","date":"2024-01-23T22:39:11Z","permalink":"https://sungho94.me/p/hibernate-associate%ED%95%98%EC%9D%B4%EB%B2%84%EB%84%A4%EC%9D%B4%ED%8A%B8-%EC%97%B0%EA%B4%80%EA%B4%80%EA%B3%84/","title":"Hibernate Associate(하이버네이트 연관관계)"},{"content":"Hibernate Java로 작성된 프로그램에서 관계형 데이터를 자연스럽고, typesafe한 형태로 사용할 수 있게함 복잡한 쿼리를 작성하고, 그 결과를 쉽게 사용할 수 있도록함 프로그램이 메모리에 변경된 내용을 쉽게 데이터베이스와 쉽게 동기화 하고 ACID속성을 준수함 기본 영속성 로직이 작성된 후에 성능을 최적화 할 수 있음 JPA가 영감을 얻었으며, JPA의 최신 버전 specification을 구현 Persistence Context first-level cache라 불리는 일종의 캐시 영속 컨텍스트 내에서 데이터베이스에서 읽은 모든 엔티티 인스턴스와 새로 생성된 엔티티들에 대해, 영속성 컨택스트는 엔티티 인스턴스 식별자와 인스턴스 자체에 대한 고유한 매핑을 보유 persistence Context와 연관된 entity는 아래 4가지중 하나의 상태를 가짐 상태 transient 초기화 되었지만 영속성컨텍스트와 연관되지 않은 상태 데이터베이스에 나타나지 않았고, 식별자가 할당되지 않은 상태 managed or persistent 연관된 식별자가 있으면서, 영속성 컨텍스트에 연관되어 있음 물리적으로 데이터에 존재할수도, 안할 수 도 있음 detached 연관된 식별자가 있으면서, 영속성 컨텍스트와 연관되어있지 않은 상태 일반적으로, 영속성 컨택스트가 닫혔거나, 인스턴스가 컨텍스트에서 제외된 경우 removed 연관된 식별자를 가지며, 영속성 컨텍스트에 연관되어 있지만, 데이터베이스에서 삭제가 예약되어 있는 상태 Persistence context의 operation persist(Object) transient 객체를 영속화 하고, SQL insert문을 예약함 remove(Object) 영속 객체를 transient하게 만들고, SQL delete 문을 예약함 merge(Object) 주어진 detached된 객체를 영속 객체로 복사하고, 영속 객체를 반환 detach(Object) 데이터베이스에 영향을 주지 않고 세션과 영속객체의 연결을 분리함 clear() 영속성 컨텍스트를 비우고, 모든 엔티티들을 detache함 flush 세션과 연결된 영속객체의 변경을 확인하고, insert, update문을 통해 데이터베이스와 세션의 상태를 동기화함 https://docs.jboss.org/hibernate/orm/6.4/introduction/html_single/Hibernate_Introduction.html\nhttps://docs.jboss.org/hibernate/orm/6.4/userguide/html_single/Hibernate_User_Guide.html\n","date":"2024-01-19T22:29:15Z","permalink":"https://sungho94.me/p/hibernate/","title":"Hibernate"},{"content":" 먼저 네트워크에서 데이터가 들어오면 nic에서 데이터를 받아 kernel buffer에 저장함\n이때 데이터를 처리하는 방식이 4가지 존재 링크 데이터가 들어오면 바로 interrupt를 발생시켜 mainboard의 cpu를 사용하는방식 NIC의 cpu를 사용해서 데이터를 저장하고 저장이 끝나면 interrupt를 발생시키는 방식 커널 버퍼에 있는 데이터를 실제 사용할 프로세스에 전달하는 과정\n커널버퍼와 유저버퍼가 따로있다 커널버퍼는 모든 프로세스가 사용할수 있는 공유공간 유저버퍼는 우리가 실행한 프로세스가 사용하는 공간 커널버퍼에 있는 데이터를 유저버퍼에 가져오려면 system call을 호출해야함 소켓의 모드에 따라 blocking, non-blocking이 나눠짐 blocking 방식 accept 호출 시\u001f 쓰레드는 데이터를 가져올 때까지 계속 대기함 non-blocking 방식 accept 호출 시 데이터가 없을경우 ERROR WOULD BLOCK을 리턴하여 쓰레드가 block되지 않음, 데이터가 있을경우 데이터를 가져옴 I/O multiplexing\n하나의 쓰레드에서 하나이상의 소켓을 관리하는 방법\n- select, epoll, io_uring, IOCP 등이 사용됨\n- 바로 accept를 호출하는 것이 아니라, 소켓에서 변경이 발생했는지 여부를 먼저 확인하고 변경이 발생하면 accept를 호출함 왜 Block IO보다 IO Multiplexing이 느릴까? Block I/O 데이터가 커널로 들어오면 데이터가 바로 커널스페이스에서 유저스페이스로 이동함 Non Block I/O 방법이 2가지 있음 데이터가 들어왔는지 반복해서 확인 우선 반복적으로 확인하기 때문에 cpu 자원낭비가 됨 데이터가 들어온시점과 반복적으로 확인한 시점 사이에 시간차가 발생할 수 밖에 없기 때문에 Block I/O보다 느림 데이터가 들어오면 알려 줌 데이터가 들어오면 커널에서 알려줌 알려주면 쓰레드에서 read syscall을 날려서 데이터를 읽음 커널에서 데이터가 들어온걸 알려주고, 쓰레드가 확인해서 해당 데이터를 가져오기 까지 시간 텀이 발생함 https://marmelo12.tistory.com/287\nhttps://www2.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/\nhttps://www.youtube.com/watch?v=uagKTbohimU\u0026amp;list=PLBlnK6fEyqRgKl0MbI6kbI5ffNt7BF8Fn\u0026amp;index=13\nhttps://dfdeboer.github.io/BURKS/pcinfo/hardware/ethernet/nic.htm\nhttps://dfdeboer.github.io/BURKS/pcinfo/hardware/ethernet/hyperlin.htm\nhttps://d2.naver.com/helloworld/47667\nhttps://engineering.linecorp.com/ko/blog/do-not-block-the-event-loop-part1\nhttps://meetup.nhncloud.com/posts/54#:~:text=%EC%9C%84%EC%97%90%EC%84%9C%20%EB%91%90%20%EA%B0%92%EC%9D%80%20%EA%B0%81%EA%B0%81%20%EC%82%AC%EC%9A%A9%ED%95%A0%20%ED%8F%AC%ED%8A%B8%20%EB%B2%94%EC%9C%84%EC%9D%98,%EC%86%8C%EC%BC%93%20%EC%88%98%EB%8A%94%20%EC%9D%B4%EC%97%90%20%EB%AF%B8%EC%B9%98%EC%A7%80%20%EB%AA%BB%ED%95%A0%20%EC%88%98%20%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4\n#Network\n#ComputerScience\n#Non-Blocking-IO\n","date":"2024-01-06T22:09:41Z","permalink":"https://sungho94.me/p/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EC%97%90%EC%84%9C-%EB%93%A4%EC%96%B4%EC%98%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B0%80-%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%EC%97%90%EC%84%9C-%EC%82%AC%EC%9A%A9%EB%90%98%EA%B8%B0%EA%B9%8C%EC%A7%80/","title":"네트워크에서 들어온 데이터가 어플리케이션에서 사용되기까지"},{"content":"Why? 클라이언트가 서버에게 http요청을 보내는 상황이 아닌, 서버에서 클라이언트에게 요청을 보내는 상황이 발생시 유용함 서버에서 작업이 즉시 처리되지 않고, 처리되기까지 대기해야하는 상황 서버에서 어떤 이벤트 발생 시 클라이언트에게 알려야 하는 상황 이를 위한 방안으로 polling, Long polling, streaming, web socket, plugin 등의 방안이 존재 자세한 내용은 RFC파일을 참고 당장 사용할 사항이 아니고, 단지 궁금증에 알아보는 것이니 이 문서에서는 간단하게 요약 Long polling과 streaming은 RFC6202참고\nWeb socket은 RFC6455 참고\nPooling(폴링) 클라이언트가 주기적으로 서버에 요청을 보내서 확인하는 방식 클라이언트가 주기적으로 서버에 요청을 보내므로 서버의 변경에 즉시 대응하지 못함 다른 방법들은 서버에서 커넥션을 유지하고 있어야 하는 반면 폴링 방식에서는 커넥션을 유지하지 않아도 돼 서버에 부하가 적음 Long polling(롱폴링) 클라이언트가 요청을 보내면, 서버에서 커넥션을 유지하다가 이벤트가 발생하면 응답하는 방식 폴링에 비해 실시간 처리가 가능함 서버가 여러번 응답을 해야 하는 상황에서는 효율이 좋지 않음 서버가 응답을 한 후 클라이언트가 다시 요청해서 커넥션을 유지해야함 Time-out 오류가 발생할 수 있음 Streaming(스트리밍) 클라이언트가 요청을 보내면, 서버에서는 커넥션을 유지하고 리스폰스를 보내는 방식 한번 응답을 보내고 커넥션이 끊어지는 것이 아니라 계속 응답을 보낼 수 있음 HTTP/1.1 또는 HTTP/1.0에서 가능 RFC문서에서는 위 두버전만 명시되어 있지만, 해당 문서는 2011년에 작성되었기에, 위 두 버전만 명시한것으로 보임\n그 이후버전에서도 가능할것이라 생각함\nHTTP의 EOF와 chunked transfer를 사용하여 연결을 지속함 HTTP/1.0에서는 EOF만 사용가능함 HTTP/1.1에서는 EOF와 chunked transfer 둘다 사용가능함 Web Socket 위의 방식들은 HTTP를 잘 활용해서 만든 방식이라면 Web Socket은 HTTP 프로토콜을 사용하지 않음 양방향으로 통신이 가능한 방식으로 언제든 서로 데이터를 보낼 수 있음 https://dydtjr1128.github.io/etc/2019/09/23/polling-long-polling-streaming.html\nhttps://bcho.tistory.com/896\nhttps://stackoverflow.com/questions/12555043/my-understanding-of-http-polling-long-polling-http-streaming-and-websockets\nhttps://sendbird.com/ko/developer/tutorials/websocket-vs-http-communication-protocols\nhttps://datatracker.ietf.org/doc/html/rfc6202\nhttps://datatracker.ietf.org/doc/html/rfc6455\n","date":"2024-01-04T22:47:40Z","permalink":"https://sungho94.me/p/long-polling-streaming-web-socket/","title":"Long polling, Streaming, Web Socket"},{"content":"https://www.kernel.org/doc/\n","date":"2023-12-22T22:23:46Z","permalink":"https://sungho94.me/p/%EB%A6%AC%EB%88%85%EC%8A%A4-%EC%BB%A4%EB%84%90-doc/","title":"리눅스 커널 doc"},{"content":"Java 는 구글 컨벤션\nKotlin 은 코틀린 스탠다드 컨벤션\n","date":"2023-11-21T22:21:20Z","permalink":"https://sungho94.me/p/code-convention/","title":"code convention"},{"content":"\nPC Register 각각의 쓰레드마다 하나씩 가지고 있음 현재 실행중인 명령의 주소를 저장하고있음 실행중인 메서드가 native메서드가 아닐경우, 가상머신 명령어의 주소를 가지고 있음 Java Virtual Machine Stacks C stack이라는 범용적인 스택을 사용 내가 ollydbg봤던 스택 현재 실행중인 메서드의 정보를 포함함 지역변수, 파라미터, 리턴주소 등 각각의 쓰레드가 하나씩 가지고 있음 해당 스레드가 허용된것보다 더 큰 Native Method Stack이 필요한경우, StackOverflowError 해당 스레드가 허용된만큼 Native Method Stack이 필요하지만, 메모리가 부족한 경우 OutOfMemoryError Native Method Stack JVM 스택과 유사하지만, java가 아닌 다른 언어로 작성된 네이티브 메서드를 지원하기 위한 영역 C stack가지고, jvm stack과 같은 정보를 포함하고 있음 jvm stack과 같은 상황에서 StackOverflowError, OutOfMemoryError가 발생함 Heap Area 가상머신 쓰레드간 공유되는 메모리 영역 클래스의 인스턴스와 배열의 메모리가 할당되는 영역 가상머신이 시작될때 생성됨 gc에 의해 회수되고, 명시적으로 회수할 수 없음 초기 메모리를 할당받고, 메모리가 더 필요하면 시스템에 요청해 메모리를 더 받아옴 #JVM-option 참고 할당된 메모리보다 많은 메모리를 사용해야 할때 OutOfMemoryError발생 Method Area 가상머신 쓰레드간 공유되는 메모리 영역 운영체제 프로세스의 text영역과 유사함 런타임 상수 풀, 필드 및 메서드 데이터, 클래스 및 인터페이스 초기화 및 인스턴스 초기화에 사용되는 특수\u001f 메서드를 포함한 메서드 및 생성자 코드와 같은 클래스별 구조를 저장 가상머신이 생성될때 생성됨 논리적으로 heap의 일부임 간단한 구현에서는 gc가 발생하지 않을 수 있음 할당된 메모리보다 많은 메모리를 사용해야 할때 OutOfMemoryError발생 Run-Time Constant Pool Method Area에 포함됨 클래스 파일의 constant_pool에 있는 데이터를 가지고 있음 할당된 메모리보다 많은 메모리를 사용해야 할때 OutOfMemoryError발생 쓰레드와 메모리의 관계 pc register, jvm Stack, Native Method Stack은 각 쓰레드마다 가짐 Heap Area와 Method Area는 쓰레드간 공유되는 영역임 https://docs.oracle.com/javase/specs/jvms/se21/html/jvms-2.html\nhttps://www.devkuma.com/docs/jvm/memory-structure/\n#Java\n","date":"2023-11-14T23:06:28Z","permalink":"https://sungho94.me/p/jvm-memory-structure/","title":"JVM memory structure"},{"content":"현재 옵션 확인 java -XX:+PrintFlagsFinal -version 2\u0026gt;\u0026amp;1 | grep -i -E \u0026lsquo;heapsize|metaspace|version\u0026rsquo; Memory 고정값으로 설정 -Xmx(ex -Xmx4g) 최대값 -Xms(ex -Xms500m) 최소값 비율로 설정 -XX:MaxRAMPercentage(-XX:MaxRAMPercentage=75), 최대값 -XX:InitialRAMPercentage(-XX:InitialRAMPercentage=75) 최소값 메모리 설정시 팁! container메모리와 heap은 같은 사이즈로 가면 안됨 java에는 heap말고 non-heap도 있기때문\u001f 힙 공간 외에도 Java 스레드, 가비지 컬렉션, 메타스페이스, 네이티브 메모리, 소켓 버퍼를 위한 공간이 필요하기 때문 컨테이너 메모리와 같은 크기로 했을 때 컨테이너도 crash 발생하기 때문에 oom 후처리가 안됨 percentage로 75%정도 권장 ms홈페이지 참고 물론 절대적인건 아님 하나의 컨테이너에 하나의 어플리케이션만 돌아갈떄 min size와 max size를 같게 설정 메모리가 부족이 발생하면 os에 메모리를 더 달라고 요청하는데, 어차피 하나의 컨테이너에 하나의 프로세스만 돌아가는데 굳이 필요없는 요청을 늘릴 필요가없음 gc가 더 자주 실행됨 하나의 컨테이너에서 하나의 프로세스만 돌기 때문에 경쟁이 필요가 없음 OOM 처리 -XX:+HeapDumpOnOutOfMemoryError OOM이 발생하면 heap dump를 생성 -XX:HeapDumpPath=/var/log 힙 덤프 생성 위치 설정 위의 아래에 .hprof파일 생성됨 MaxRAMFraction\ndeprecated된 옵션 max heap memory를 설정하는 다른 방법 InitialRAMPercentage, MinRAMPercentage관련한 글\nhttps://blog.gceasy.io/2020/11/05/difference-between-initialrampercentage-minrampercentage-maxrampercentage/\nhttps://blog.ycrash.io/2020/11/23/best-practices-java-memory-arguments-for-containers/\n#JVM-option\nhttps://docs.oracle.com/en/java/javase/17/docs/specs/man/java.html\nhttps://www.merikan.com/2019/04/jvm-in-a-container/\nhttps://learn.microsoft.com/en-us/azure/developer/java/containers/overview\nhttps://stackoverflow.com/questions/43651167/is-there-any-advantage-in-setting-xms-and-xmx-to-the-same-value\nhttps://developer.jboss.org/thread/149559\nhttps://www.codementor.io/@suryab/outofmemoryerror-related-jvm-arguments-w6e4vgipt\nhttps://medium.com/nordnet-tech/setting-java-heap-size-inside-a-docker-container-b5a4d06d2f46\nhttps://dzone.com/articles/best-practices-java-memory-arguments-for-container\nhttps://docs.oracle.com/en/java/javase/17/docs/specs/man/java.html#overview-of-java-options\nhttps://d2.naver.com/helloworld/37111\n","date":"2023-11-14T11:26:23Z","permalink":"https://sungho94.me/p/jvm-option-for-container/","title":"jvm option for Container"},{"content":"문제 상황 msa 환경에서 도메인 서버스로 보낸 create, update, delete 이벤트는 반드시 수행되어야함 하지만 2pc가 지원이 안되는 환경에서, 이벤트를 발행하기는 부담이 있음 이벤트 발행후 롤백되는 문제 메시지가 순서가 보장되어야할 수도 있음 개념 메시지를 전송하는 서비스의 일부 비즈니스 엔티티를 저장한느 트랜잭션의 일부로 OUTBOX테이블에 데이터를 추가로 저장 이후 별도의 프로세스가 해당 메시지를 메세지 브로커에 전송\nSender - 메시지를 전송하는 서비스 Database - business entity와 message outbox를 저장하는 데이터베이스 Message outbox - 관계형 데이터베이스에서는 하나의 테이블, NoSql 디비에서는 각각의 데이터베이스 레코드의 property(document or item) Message relay - outbox에 저장되어있는 메시지를 메시지 브로커에게 보내는 역할 Message relay의 두가지 방법 Transaction log tailing 아래의 로그를 tailing하여 로그를 확인 하여 message broker에 전송 MySQL binlog Postgres WAL AWS DynamoDB table streams log tailing시 cdc를 고려 kafka connect도 사용할 수 있다니 확인해 볼것 Polling publisher outbox 데이터를 주기적으로 polling하여 변경 발생시 message broker에 이벤트 발행 주기적으로 db를 확인해야 하니 불필요한 자원 소모 발생 장점 모든 데이터가 outbox에 저장되므로 장애가 났을때 대응이 수월함 2PC가 지원이 안되는 환경에서 대안이 될 수 있음 단점 메시지를 직접 보내는 패턴보다 속도가 느릴 수 있음 메시지는 필요한상황에 바로 보내기때문 하지만 Transactional outbox는 중간에 Message Relay서버가 변경을 확인하고 서비스로 요청을 보낼때까지 시간이 빔 Message Relay 서버가 추가됨으로서 관리해야 할게 하나 더 늘어남 한번 이상 명령이 수행될 수 있음 그러므로 멱등성을 보장해야함 작업마다 id를 기록해놓고 해당 id를 가직 작업이 수행되었으면 재처리 하지 않아야함 정보는 Transactional outbox로 저장하고 끝난후 id와 함께 api요청을 보내는건 어떨까?\nconsumer에서 id와 함께 api요청을 받으면 id로 데이터를 확인 후 처리\nhttps://microservices.io/patterns/data/transactional-outbox.html\nhttps://microservices.io/patterns/data/transaction-log-tailing.html\n","date":"2023-11-05T22:21:43Z","permalink":"https://sungho94.me/p/transactional-outbox/","title":"Transactional outbox"},{"content":" 이전의 이름은 LLT(Long Lived Transaction) 이전의 이름에서 알수 있듯이 오래 살아있는 트랜잭션을 어떻게 처리할까는 문제의 해결책임 마이크로서비스화 되면서 서비스별 데이터베이스를 가지고 있음 그리고 각각의 서비스들이 트랜잭션을 가지고 있음 하나의 요청이 들어왔을때 각각의 서비스들에서 트랜잭션처리를 어떻게 관리할것인가? A-B-C서비스를 거처야 하는 요청인데, 이에 관한 트랜잭션 처리를 어떻게 할지 ex) 롤백 처리를 어떻게 하는지? 정의 SAGA는 로컬 트랜잭션의 연속임\n각각의 로컬 트랜잭션은 트랜잭션 완료후 다음 트랜잭션에 메시지를 보내거나, 이벤트를 발생시킴 이 과정에서 에러 발생시 보상트랜잭션을 실행하여, 이전 로컬 트랜잭션 내용을 롤백시킴 이를 구현하는 두가지 방법이 있음 아래의 예시는 e-커머스에서 주문을 넣는 예시로, 주문을 넣으면 고객의 잔고를 확인해서 잔고가 주문금액보다 많으면 잔고가 차감이 되며 주문이 승인되고, 적다면 주문이 거절됨 주문서비스에서는 고객의 잔고를 알 수 없기에, 고객 서비스에 요청을 해야 주문의 승인여부를 확인할 수 있음 Choreography-based saga 서비스 흐름 Order Service에서 Post /orders요청을 받고, PENDING 상태의 Order를 생성함 Order 생성 이벤트를 발생 Customer Service에서 잔고 차감을 시도 승인/거절 여부를 Order Service에 응답 Order Service에서는 결과를 가지고 승인할지, 거절할지 결정 각각의 서비스가 로컬트랜잭션을 수행하고, 작업이 끝나면 다음 서비스로 메시지를 보내는 방식 A -\u0026gt; B-\u0026gt; C 순서일때, A가 B를, B가 C를 호출함 롤백시 C-\u0026gt;B-\u0026gt;A 순으로 호출 Orchestration방식보다 구현이 간편함(중앙 관리자가 없기 때문) Orchestration-based saga 서비스 흐름 order Service에서 Post /orders요청을 받고, Order saga orchestrator를 생성함 saga orchestrator에서 PENDIN상태의 주문을 생성 saga orchestrator에서 Customer Service에 잔고 차감\b명령을 보냄 Customer Service에서 잔고 차감 명령을 시도함 그 후 orchestrator에 결과를 리턴함 saga orchestrator에서 주문을 승인 or 거절 Choreography방식보다 구현이 어려움(orchestrator가 추가되기 때문) 하지만 A-\u0026gt;B-\u0026gt;C상황보다 처리하기 쉬움(Orchestrator에서 A,B,C를 호출하면 되기 때문) 각 서비스가 다음에 호출해야할 서비스를 알 지 않아도 됨 orchestrator가 단일 실패 지점이 될 수 있음 장점 애플리케이션이 분산 트랜잭션을 사용하지 않고도 여러 서비스에서 데이터 일관성을 유지 가능 단점 낮은 일관성 송금을 예로 들면, 사용자 A의 계좌에서 돈이 인출되었지만 최종적으로 송금에 실패하는 중간 상태를 볼 수 있습니다. 보상 트랜잭션을 추가로구현해야 하기 때문에 개발 난이도가 높음 구조가 복잡함 주문한 고객이 결과를 바로 알수 없음 saga가 완료되면 결과를 고객에게 응답 saga가 시작할때 주문 ID를 포함한 응답으로 제공하고, client-side에서 결과를 주기적으로 폴링하여 결과 확인 saga가 시작할때 주문 ID를 포함한 응답으로 제공하고, saga가 완료되면 webhook으로 고객에게 결과를 알려줌 saga의 어원이 정확히 밝혀지지 않았음\n- 아래의 두가지 추측이 존재\n- 연결된 이벤트에 길고 자세한 이야기(문학에서 사용되는 용어)\n- Segregated Access of Global Atomicity의 약어\nhttps://stackoverflow.com/questions/63319018/why-the-pattern-for-microservices-distributed-transactions-named-as-saga\nhttps://microservices.io/patterns/data/saga.html\n","date":"2023-11-05T16:36:56Z","permalink":"https://sungho94.me/p/saga-pattern/","title":"Saga Pattern"},{"content":"https://tech.inflab.com/20231101-optimizing-ci-pipeline/\n","date":"2023-11-03T23:21:09Z","permalink":"https://sungho94.me/p/%EB%B9%8C%EB%93%9C%EC%8B%9C%EA%B0%84-%EB%8B%A8%EC%B6%95/","title":"빌드시간 단축"},{"content":"https://ijmacd.github.io/rfc3339-iso8601/\n","date":"2023-10-26T23:04:39Z","permalink":"https://sungho94.me/p/time-zone-%EA%B4%80%EB%A0%A8-%ED%8C%81/","title":"Time zone 관련 팁"},{"content":"https://d2.naver.com/helloworld/2922312\n","date":"2023-10-26T22:59:17Z","permalink":"https://sungho94.me/p/%EB%B8%8C%EB%9D%BC%EC%9A%B0%EC%A0%80-%EA%B3%B5%EB%B6%80%EC%9E%90%EB%A3%8C/","title":"브라우저 공부자료"},{"content":"cs설명이 잘되어 있음\nhttps://www.youtube.com/watch?v=mb-QHxVfmcs\n#Study-Material\n","date":"2023-10-19T23:28:30Z","permalink":"https://sungho94.me/p/%EA%B0%9C%EB%B0%9C%EA%B4%80%EB%A0%A8-%EC%9C%A0%ED%8A%9C%EB%B8%8C/","title":"개발관련 유튜브"},{"content":" Log Sequence Number의 약자 임의로 계속 증분하여 redo log에 저장됨\u001c 체크포인트 발생시 어느 LSN까지 처리되었는지 알려줌 로그 복구시 LSN으로 실행여부를 알 수 있음 https://www.percona.com/blog/mvcc-transaction-ids-log-sequence-numbers-and-snapshots/\nhttps://dba.stackexchange.com/questions/45716/what-is-log-sequence-number-how-it-is-used-in-mysql\nhttps://dev.mysql.com/doc/refman/8.0/en/glossary.html\n#InnoDB\n","date":"2023-10-11T23:20:55Z","permalink":"https://sungho94.me/p/database-lsn/","title":"Database LSN"},{"content":" 데이터베이스는 성능상의 이유로 매 변경마다 데이터를 디스크에 쓰는게 아닌 메모리에 기록함 이후 주기적으로 메모리에 있는 데이터를 디스크에 저장하는데, 성공적으로 디스크에 저장된 최신의 레코드가 체크포인트임 이 체크포인트는 성공적으로 저장된 것이므로 체크포인트 장애나 충돌로 인한 복구시 체크포인트 이후의 로그를 사용하여 복구하면 시간이 단축됨 레코드 뿐만 아니라 트랜잭션 정보도 저장함 \bcheck point recovery 방법 위 상황에서 T1, T2, T3는 redo list에 저장되고, T4는 undo list에 저장되어있음 해당 리스트에서 데이터를 재생하면됨 데이터베이스는 T4에서 T1순으로 읽음\nhttps://dev.mysql.com/doc/refman/8.0/en/glossary.html#glos_checkpoint\nhttps://learn.microsoft.com/en-us/sql/relational-databases/logs/database-checkpoints-sql-server?view=sql-server-ver16\n#Database\n#InnoDB\n","date":"2023-10-11T22:26:05Z","permalink":"https://sungho94.me/p/database-check-point/","title":"Database Check point"},{"content":" 오류 또는 수신 서버의 변경로 인해 처리할 수 없는 메시지를 임시로 저장하는 곳 임시로 저장해놨다가 retry하거나, retry로 해결이 안되면 관리자에게 알림을 구성할 수 있음 https://aws.amazon.com/ko/what-is/dead-letter-queue/\n","date":"2023-10-07T16:59:28Z","permalink":"https://sungho94.me/p/dlqdead-letter-queue/","title":"DLQ(Dead Letter Queue)"},{"content":"공통 컴포넌트를 제공하는 라이브러리\nhttps://ui.shadcn.com/\n#front-end\n","date":"2023-10-07T16:59:12Z","permalink":"https://sungho94.me/p/shadcn/","title":"shadcn"},{"content":"Design Instagram : https://bit.ly/3BFeHlh\nDesign Messenger App : https://bit.ly/3DoAAXi\nDesign Linkedin : https://bit.ly/3OjXy7c\nDesign Google Maps : https://bit.ly/3BDdTwn\nDesign Telegram : https://bit.ly/42N5LW2\nDesign Snapchat : https://bit.ly/3pRP3pW\nDesign One Drive : https://bit.ly/438bAwZ\nDesign BookmyShow : https://bit.ly/3FDFMWF\nDesign Quora : https://bit.ly/3FeD9dL\nDesign Foursquare : https://bit.ly/3VMYh1O\nDesign Tiny URL : https://bit.ly/3o58M57\nDesign Flipkart : https://bit.ly/3iS1a2P\nDesign Tinder : https://bit.ly/3Mcyj3X\nDesign Google Drive : https://bit.ly/3uXdQZ7\nDesign Twitter : https://bit.ly/3qIG9Ih\nDesign Ticketmaster: https://bit.ly/3HKLbOg\nDesign Quora : https://bit.ly/3FeD9dL\nDesign Flipkart : https://bit.ly/3iS1a2P\nDesign Flickr : https://bit.ly/3uCGkXJ\nDesign TikTok : https://bit.ly/3UUlKxP\nDesign Netflix : https://bit.ly/3GrAUG1\nDesign Foursquare : https://bit.ly/3VMYh1O\nDesign Uber : https://bit.ly/3fyvnlT\nDesign Youtube : https://bit.ly/3dFyvvy\nDesign Reddit : https://bit.ly/3OgGJrL\nDesign Facebook’s Newsfeed : https://bit.ly/3RldaW7\nDesign Amazon Prime Video : https://bit.ly/3hVpWP4\nDesign Web Crawler : https://bit.ly/3DPZTBB\nDesign API Rate Limiter : https://bit.ly/3BIVuh7\nDesign Dropbox : https://bit.ly/3SnhncU\nDesign Yelp : https://bit.ly/3E7IgO5\nDesign Whatspp : https://bit.ly/3M2GOhP\nDesign URL shortener : https://bit.ly/3xP078x\nDesign Bookmyshow : https://bit.ly/3FDFMWF\n#Study-Material\n","date":"2023-10-07T16:58:52Z","permalink":"https://sungho94.me/p/system-design-case-studies/","title":"System Design Case Studies"},{"content":"select * from information_schema.PROCESSLIST;\nID connection의 식별자 USER 해당 구문을 실행한 유저 event_schduler는 예약된 이벤트를 모니터링하는 스레드 HOST 해당 구문을 실행한 호스트명 DB 해당 스레드가 선택한 데이터베이스 COMMAND 실행하는 명령의 유형 sleep - 클라이언트에게 새로운 구문을 받기위해 대기하는 상태 query - 쿼리를 실행중인 상태 상태 참고 링크 TIME 쓰레드가 현재 상태에 있던 시간 초단위 STATE 스레드가 수행 중인 작업, 이벤트의 상태입니다 참고 링크 INFO 쓰레드가 실행하고있는 구문을 보여줌 nll일 때는 구문을 실행하고 있지 않다는것 https://dev.mysql.com/doc/refman/8.0/en/information-schema-processlist-table.html\n#Database\n#Query\n#Trouble-Shooting\n","date":"2023-10-06T23:30:28Z","permalink":"https://sungho94.me/p/mysql-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EB%A6%AC%EC%8A%A4%ED%8A%B8-%EB%B3%B4%EA%B8%B0/","title":"mysql 프로세스 리스트 보기"},{"content":"mysql 8.0\nselect * from performance_schema.data_locks;\nhttps://dev.mysql.com/doc/refman/8.0/en/performance-schema-data-locks-table.html\n테이블에 대한 설명 mysql 5.7\nselect * from information_schema.InnoDB_LOCKS;\n#Database\n#Query\n#lock\n#Trouble-Shooting\n#InnoDB\n","date":"2023-10-06T23:29:37Z","permalink":"https://sungho94.me/p/mysql-%EB%9D%BD%EA%B1%B8%EB%A6%B0-%EC%BF%BC%EB%A6%AC-%ED%99%95%EC%9D%B8/","title":"mysql 락걸린 쿼리 확인"},{"content":"영속성전이 cascade 부모 엔티티를 영속성 관리시 자식 엔티티도 같이 영향을 끼치게 하는것 ALL, PERSIST, REMOVE, MERGE, REFERESH, DETACH orphanRemoval 부모엔티티 삭제시 자식 엔티티를 삭제하는것을 포함 부모엔티티의 자식엔티티 리스트에서 제거하는 것으로도 자식엔티티를 삭제 프록시객체 lazy로딩을 구현하기 위해 사용 lazy로딩을 사용하면 실제 객체를 사용할때 데이터베이스에서 조회함 프록시 객체는 실제로 값을 가지고 있지 않고 데이터를 로딩하기 위한 정보만 가지고 있음 getReference메서드로 프록시 객체를 가져옴 https://vladmihalcea.com/how-does-a-jpa-proxy-work-and-how-to-unproxy-it-with-hibernate/\n#JPA\n","date":"2023-10-05T23:29:07Z","permalink":"https://sungho94.me/p/jpa-%EC%98%81%EC%86%8D%EC%84%B1%EC%A0%84%EC%9D%B4-%ED%94%84%EB%A1%9D%EC%8B%9C%EA%B0%9D%EC%B2%B4/","title":"JPA 영속성전이, 프록시객체"},{"content":" 분산 문서 장소 분산 시스템으로 구성되어 대용량 데이터와 빠른 검색 가능 역인덱스구조 Document 엘라스틱 서치의 단일 데이터 단위 JSON구조로 되어있음 디폴트로 schema-less구조 schema를 지정 하지 않아도 됨 schema를 지정할 수 있으며, schema를 지정했다면, 모든 document들은 schema를 따라야함 metadata _index document가 저장된 index를 나타냄 _id doucument의 id를 나타냄 Node 하나의 ElasticSearch 인스턴스 하나이상의 Node가 모여 Cluster를 구성 node는 여러 role을 가질 수 있음 master, data, data_content, data_hot, data_warm, data_cold, data_frozen, ingest, ml, remote_cluster_client, transform Master node 인덱스의 생성 또는 삭제, 클러스터의 일부인 노드추적, 어떤 샤드를 어떤 노드를 할당할지 결정하는 등 가벼운 작업을 담당 Data node 인덱싱한 문서가 포함된 샤드를 보관 CRUD, 검색, 집계와 같은 데이터 관련 작업 처리 I/O, 메모리, CPU 집약적인 작업 hot, warm, cold 등 여러 data노드들이 있음 Index 유사한 특성을 가진 문서들의 모음 es에서 쿼리할 수 있는 가장 높은 수준의 엔티티 Shard 하나의 인덱스는 하나 이상의 shard로 분리되어 저장됨 인덱스를 구성하는 기본단위 Lucene의 인스턴스이며, 그 자체로 완벽한 검색엔진임 document가 저장되어있고 primary shard와 replica shard가 존재함 primary shard 각각의 document는 하나의 primary shard에 속함 최대 Integer.MAX_VALUE - 128 만큼의 document를 저장할 수 있음 update시 즉시 업데이트 replica shard primary shard의 복제본 update시 즉시 업데이트 되지 않음 장애 복구 시 및 검색시 사용함 primary샤드수를 바꾸려면 reindexing해야함 역인덱스(inverted index) 해당 단어가 나타내는 문서들 간의 매핑을 제공해주는 데이터 구조 각 단어가 어떤 문서들에 등장하는지 알려줌 inverted index와 forward index는 방향성의 차이임 1 2 3 4 5 #forward index Document Keywords doc1 hello, sky, morning doc2 tea, coffee, hi doc3 greetings, sky 1 2 3 4 5 6 7 #inverted index Word Documents hello doc1 sky doc1, doc3 coffee doc2 hi doc2 greetings doc3 ex)\nhello를 찾는다? forward index 구조 document를 순회하며 hello라는 키워드가 있는지 확인함 inverted index 구조 word에서 hello를 찾고, 해당 document를 반환 https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#generic-data-node\nhttps://opster.com/guides/elasticsearch/glossary/elasticsearch-document/\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/documents-indices.html\nhttps://www.knowi.com/blog/what-is-elastic-search/\n","date":"2023-10-05T23:26:11Z","permalink":"https://sungho94.me/p/elasticsearch/","title":"ElasticSearch"},{"content":"정규화 정규화를 많이하면 join을 많이해야 함으로 성능저하가 올 수 있음 적게하면 확장성이 떨어짐 고려해야 할점 부모-자식관계에서 부모가 삭제되었을때 삭제되어야 하는데이터인지 확인 변경되었을때 같이 변경되어야 하는 데이터인지 고민할것 위 2개의상황에서는 정규화 해서는 안됨 역정규화 join을 적게하여 성능을 향상을 이룰 수 있음 중복되는 데이터 저장 #Database\n","date":"2023-10-05T23:22:05Z","permalink":"https://sungho94.me/p/%EC%A0%95%EA%B7%9C%ED%99%94-%EC%97%AD%EC%A0%95%EA%B7%9C%ED%99%94/","title":"정규화 역정규화"},{"content":"mac에서 Eclips memory Analyzer 사용시\nheap dump 분석하는 어플리케이션\nmat.app파일을 ./Application으로 이동할것!\nhttps://stackoverflow.com/questions/47909239/how-to-run-eclipse-memory-analyzer-on-mac-os\n어플리케이션이 느리다면 초기 메모리설정이 1g로 되어있으니 늘릴것\nhttps://wiki.eclipse.org/MemoryAnalyzer/FAQ\n#Java\n#Tool\n#Heap-dump\n","date":"2023-10-04T23:06:58Z","permalink":"https://sungho94.me/p/eclips-memory-analyzer/","title":"Eclips memory Analyzer"},{"content":"전체 tool 정보 https://docs.oracle.com/en/java/javase/20/docs/specs/man/index.html 트러블 슈팅(troubleshooting) 시 유용할만한 툴 jconsole\nstart a graphical console to monitor and manage Java applications 자바 어플리케이션의 모니터링 및 관리할수 있게 도와주는 graphical 콘솔 jmap\n프로세스 정보 제공 heap dump뜰수 있음 heap dump뜬거는 Eclips memory Analyzer로 분석 jmap -dump:format=b,file=heapdump.hprof jps\njvm에서 돌아가는 프로세스 조회 jstack\nthread dump뜰때 사용 jstack jstat\njvm상태 모니터링 https://tangoblog.tistory.com/16\n#Java\n#Jps\n","date":"2023-10-04T23:04:11Z","permalink":"https://sungho94.me/p/java-development-kit-version-20-tool-specifications/","title":"Java Development Kit Version 20 Tool Specifications"},{"content":"컴파일러의 도움 없이 Java 애플리케이션의 런타임 동안 Java 클래스를 생성 및 수정하기 위한 코드 생성 및 조작 라이브러리\n1 2 3 4 5 6 7 8 9 Class\u0026lt;?\u0026gt; dynamicType = new ByteBuddy() .subclass(Object.class) .method(ElementMatchers.named(\u0026#34;toString\u0026#34;)) .intercept(FixedValue.value(\u0026#34;Hello World!\u0026#34;)) .make() .load(getClass().getClassLoader()) .getLoaded(); assertThat(dynamicType.newInstance().toString(), is(\u0026#34;Hello World!\u0026#34;)); 위 방법으로 toString함수를 변경가능하다\njpa에 ByteBuddy관련한 내용이 나와서 찾아봤는데 추후 더 찾아봐야겠다.\nhttps://stackoverflow.com/questions/30769816/how-do-i-use-byte-buddy-to-create-a-lazy-loading-class\nhttps://bytebuddy.net/#/\n#Java\n#Tool\n","date":"2023-10-04T23:03:23Z","permalink":"https://sungho94.me/p/byte-buddy/","title":"Byte Buddy"},{"content":"가져오는 그룹 컬럼이 1개일떄\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql 5.7 SELECT name, year, month FROM ( SELECT *, IF(@prev \u0026lt;\u0026gt; name, @rn:=0,@rn), @prev:=name, @rn:=@rn+1 AS rn FROM example, (SELECT @rn:=0) rn, (SELECT @prev:=\u0026#39;\u0026#39;) prev ORDER BY name ASC, year DESC, month DESC ) t WHERE rn \u0026lt;= 2; mysql 8.0 SELECT name, year, month FROM ( SELECT name, year, month, ROW_NUMBER() OVER (PARTITION BY name ORDER BY year DESC, month DESC) AS rn FROM example ) t WHERE rn \u0026lt;= 2; 가져오는 그룹 컬럼이 1개일떄\n1 2 3 4 5 6 7 8 9 10 11 12 mysql 5.7 SELECT name, year, month FROM ( SELECT *, IF(@prev \u0026lt;\u0026gt; name + year, @rn:=0,@rn), @prev:=name + year, @rn:=@rn+1 AS rn FROM example, (SELECT @rn:=0)rn, (SELECT @prev:=\u0026#39;\u0026#39;)prev ORDER BY name ASC, year DESC, month DESC )t WHERE rn \u0026lt;= 2; Using MySQL 8.0 with ROW_NUMBER: mysql 8.0 SELECT name, year, month FROM ( SELECT name, year, month, ROW_NUMBER() OVER (PARTITION BY name, year ORDER BY year DESC, month DESC) AS rn FROM example https://stackoverflow.com/questions/58645949/emulating-partition-over-with-mysql-5-7\n#Database\n#Query\n","date":"2023-10-04T22:57:58Z","permalink":"https://sungho94.me/p/%EA%B7%B8%EB%A3%B9%EB%B3%84-%EC%88%9C%EC%9C%84-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0/","title":"그룹별 순위 가져오기"},{"content":" Data Tier는 Content, Hot, Warm, Cold, Frozen 5개의 티어로 나눔\nData Tier는 정말 사용하는 데이터(상품의 카탈로그)같은 것으로 다른 티어들과 다르게 시간의 지남에 따라 티어를 이동하지 않음\nHot, Warm, Cold, Frozen는 Time series data의 관리시 매우 유용함\n특히 시계열 인덱스일때 매우 유용 많은 경우, 자주 접하는 데이터와 자주 접하지 않는 데이터가 나누어 \u001f\n시계열일 경우 최근 데이터를 자주보고 시간이 지난 데이터를 덜 볼 것임 ex) 로그 데이터 Hot으로 갈수록 더 최근, 자주 접근하는 데이터이고 Frozen으로 갈수로 옛날, 잘 접근하지 않는 데이터\u001f\n데이터 관리 방법\n자주 접근하는 티어(ex Hot tier)는 더 좋은 장비(SSD, memory)를 두고 덜 접근하는 티어(Fozen)에는 낮은장비, 혹은 스냅샷을 이용하여 저장하고 필요시 복구하는 정도 티어를 나눔으로써 장비에 대한 비용을 아낄 수 있음\n하나의 샤드의 크기를 50GB이하로 유지할것, elastic search는 200M이상 50GB이하일때 성능이 가장 좋음\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/data-tiers.html\nhttps://www.elastic.co/kr/blog/implementing-hot-warm-cold-in-elasticsearch-with-index-lifecycle-management\n","date":"2023-10-04T22:54:59Z","permalink":"https://sungho94.me/p/elastic-search-data-tier/","title":"Elastic Search Data Tier"},{"content":" spring boot는 yml, properties를 통해 여러 환경에서 나의 코드가 실행되도록 외부에서 설정을 주입할 수 있게 만들어졌다. yml팁 \u0026lsquo;-\u0026lsquo;를 통해 리스트로 주입가능 spring.config.import를 통해 여러개의 yml 파일 설정가능 https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.external-config\n#Spring-boot\n#Tip\n","date":"2023-10-03T23:26:51Z","permalink":"https://sungho94.me/p/spring-boot-yaml/","title":"spring boot yaml"},{"content":" 테이블의 전체 개수를 얻기 위해 Count()과 Count(Column)를 사용할때는 Count(_)가 성능적으로 더 좋음 Count를 할때는 null값을 확인한 후 null이 아닌 개수만 리턴하는데, Count(Column)을 하게되면 Column의 null체크를 하기때문에 성능 저하가 발생함, 전체개수를 파악하기 위해서는 Count(*)을 사용하자 https://m.blog.naver.com/pjt3591oo/221030483713\n#Database\n#Query-turning\n","date":"2023-10-03T23:20:03Z","permalink":"https://sungho94.me/p/count-vs-countcolumn/","title":"Count(*) vs Count(Column)"},{"content":"OLTP(Online Transaction Processing)\n실시간 transaction처리 OLAP(Online Analytical Processing)\n복잡한 분석처리 DW(Data Warehouse)\n데이터를 효율적으로 저장, 관리 및 분석하기 위한 중앙 집중식 데이터 저장소 원시데이터를 처리하여 저장 ETL\n데이터 웨어하우스(DW)의 데이터 추출(Extract), 변환(Transform) 및 로드(Load) 프로세스 DL(Data Lake)\n다양한 종류의 데이터를 대규모로 저장하는 저장소 원시데이터를 저장 #Concept\n","date":"2023-10-03T23:19:15Z","permalink":"https://sungho94.me/p/oltp-olap-dw-dl/","title":"OLTP, OLAP, DW, DL"},{"content":" 개념 하나의 큰 테이블을 물리적으로 작은 단위로 \b분리하는 것 파티셔닝 방법 테이블, 인덱스 파티셔닝이 존재(테이블 또는 인덱스당 최대 15000개까지 지원함) 수평 파티셔닝 row의 조건에 따라 파티셔닝함 파티셔닝시 proportional fill algorithm에서 나눠지는 단위가 됨 데이터베이스의 데이터 저장 알고리즘 proportional fill algorithm. range, hash, list로 나누는 방법이 있음 이로인해 쿼리성능 향상, 대용량 삭제시 적은 영향으로 삭제 와 같은 이점이 존재 샤딩과 다름 샤딩은 다른 머신에 데이터를 나누어 저장, 수평 파티셔닝은 하나의 머신에 나누어 저장 수직 파티셔닝 컬럼 별로 파티션을 나눔 중요한정보와 중요하지 않은 정보를 따로 저장해여 보안을 강화할 수 있음 자주 조회되는 묶음끼리 나눔으로써 쿼리 성능 향상을 가져옴 필요하지 않은 컬럼을 메모리에 올리지 않음으로 I/O향상을 가져옴 단점 파티션을 잘못 나눌 시 오히려 성능이 저하될 수 있음 저장공간, 메모리의 비용이 증가함 잘 나눴는지에 대한 지속적인 모니터링 필요 Aggregate에 맞게 수직 파티셔닝 하면 어떨까?\nbucketing에 대해 알아보자\nhttps://docs.gitlab.com/ee/development/database/table_partitioning.html\nhttps://learn.microsoft.com/en-us/sql/relational-databases/partitions/partitioned-tables-and-indexes?view=sql-server-ver16\nhttps://learn.microsoft.com/en-us/sql/relational-databases/databases/database-files-and-filegroups?view=sql-server-ver16#file-and-filegroup-fill-strategy\nhttps://www.quora.com/Is-the-concept-of-a-database-partition-a-logical-concept-or-is-it-a-physical-concept\n#Database\n#Concept\n","date":"2023-10-03T23:02:09Z","permalink":"https://sungho94.me/p/%ED%8C%8C%ED%8B%B0%EC%85%94%EB%8B%9D/","title":"파티셔닝"},{"content":"PUT메소드는 현재 서버에 있는 대체하여 새로운 엔티티를 생성\nPATCH메소드는 현재 서버에 있는 엔티티를 수정하여 새버전을 생성하는것\n-\u0026gt; PUT메소드는 엔티티의 전체 변경 시, PATCH는 엔티티의 일부 변경 시 사용\nThe difference between the PUT and PATCH requests is reflected in the\nway the server processes the enclosed entity to modify the resource\nidentified by the Request-URI. In a PUT request, the enclosed entity\nis considered to be a modified version of the resource stored on the\norigin server, and the client is requesting that the stored version\nbe replaced. With PATCH, however, the enclosed entity contains a set\nof instructions describing how a resource currently residing on the\norigin server should be modified to produce a new version. The PATCH\nmethod affects the resource identified by the Request-URI, and it\nalso MAY have side effects on other resources; i.e., new resources\nmay be created, or existing ones modified, by the application of a\nPATCH.\nhttps://datatracker.ietf.org/doc/rfc5789/?include_text=1\n#Concept\n","date":"2023-10-03T23:00:14Z","permalink":"https://sungho94.me/p/http-method-put-vs-patch/","title":"HTTP Method PUT vs PATCH"},{"content":"Forward Proxy A: 사용자의 가정용 컴퓨터\nB: 정방향 프록시 서버\nC: 웹 사이트의 원본 서버(웹 사이트 데이터가 저장되는 곳)\n일반적으로 사용되는 프록시 서버를 의미 프록시가 없다면 A가 C로 직접 요청 Forward Proxy가 있다면 A가 B로 요청하고 B가 다시 C로 호출함, 응답은 C-\u0026gt;B-\u0026gt;A순 사용이유 주 당국 또는 기관의 검색 제한을 피하기 위해 온라인에서 자신의 신원을 보호하기 위해 Reverse Proxy D: 사용자의 가정용 컴퓨터\nE: 역방향 프록시 서버\nF: 웹 사이트의 원본 서버(웹 사이트 데이터가 저장되는 곳)\n인터넷과 서버를 연결할 때 대신 요청을 받아 처리 Forward Proxy는 클라이언트 보호가 목적이었다면, Reverse Proxy는 서버 보호가 목적 사용이유 부하분산 캐싱 SSL 암호화 https://www.cloudflare.com/ko-kr/learning/cdn/glossary/reverse-proxy/\n#Concept\n","date":"2023-10-03T22:58:54Z","permalink":"https://sungho94.me/p/forward-proxy-reverse-proxy/","title":"Forward Proxy, Reverse Proxy"},{"content":" File \u0026gt; Project Structure 에서 버전 변경 Edit configuration \u0026gt; Build and run에서 버전 변경 Settings \u0026gt; Build,Excution,Deployment \u0026gt; Gradle ","date":"2023-10-03T22:56:50Z","permalink":"https://sungho94.me/p/%EC%9D%B8%ED%85%94%EB%A6%AC%EC%A0%9C%EC%9D%B4-java-%EB%B2%84%EC%A0%84-%EB%B3%80%EA%B2%BD-%EC%8B%9C/","title":"인텔리제이 java 버전 변경 시"},{"content":" windows에서는 기본의로 제공하는 클립보드에 매우 만족하고 있었는데 mac으로 넘어오니 유료에다가 만족하는게 잘 없었다. https://github.com/Clipy/Clipy 간단하게 기능을 제공하면서 무료이다 ","date":"2023-10-03T22:54:44Z","permalink":"https://sungho94.me/p/clippy/","title":"Clippy"},{"content":"서비스를 확장, 구현하기위한 인터페이스\napi는 서비스를 사용하기위한 인터페이스라면, spi는 해당 서비스의 기능을 확장, 구현하기위한 인터페이스임\nspi는 인터페이스, 클래스 혹은 추상클래스로 나타남\nspi를 사용하므로서 클라이언트는 실제 구현을 신경쓰지 않고, 사용가능\nex) jdbc\nhttps://en.wikipedia.org/wiki/Service_provider_interface\nhttps://stackoverflow.com/questions/2954372/difference-between-spi-and-api\n#Concept\n#Definition\n","date":"2023-10-03T22:54:00Z","permalink":"https://sungho94.me/p/spiservice-provider-interface/","title":"SPI(Service Provider Interface)"},{"content":" google에서 개발한 압축방식 gzip 더 나은 압축성능을 보여줌 14% smaller JavaScript files 21% smaller HTML files 17% smaller CSS files IE는 지원안함\u0026hellip;ㅠㅠ\nhttps://en.wikipedia.org/wiki/Brotli\nhttps://github.com/google/brotli\nhttps://www.siteground.com/blog/brotli-vs-gzip-compression/\n#Library\n","date":"2023-10-03T22:52:38Z","permalink":"https://sungho94.me/p/brotli/","title":"Brotli"},{"content":" faceboock build tool 멀티모듈 빌드시 변경된 모듈만 재빌드 ","date":"2023-10-03T22:50:11Z","permalink":"https://sungho94.me/p/buck/","title":"buck"},{"content":" google build tool 멀티모듈 빌드시 변경된 모듈만 재빌드 ","date":"2023-10-03T22:49:58Z","permalink":"https://sungho94.me/p/bazel/","title":"Bazel"},{"content":"Cpu Bound CPU가 빨라지면 작업이 빨라지는 작업 CPU를 사용하는것이 주요한 작업일 경우 π값 계산\nI/O bound I/O 작업이 많은것 ex) 네트워크, 파일읽기 거대한 파일에서 특정 데이터 찾기\n#Concept\n#ComputerScience\n","date":"2023-10-03T22:47:20Z","permalink":"https://sungho94.me/p/cpu-bound-io-bound/","title":"CPU bound, IO bound"},{"content":"Concurrency(동시성) 두개이상의 작업이 겹치는 기간에 시작, 실행, 완료될 수 있다는 것\nex) multitasking on a single-core machine. Parallelism(병렬성) 말그대로 여러 task가 동시에 실행되는것\nex) multicore processor. https://freecontent.manning.com/concurrency-vs-parallelism/\nhttps://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism\n#ComputerScience\n#Concept\n","date":"2023-10-03T22:45:35Z","permalink":"https://sungho94.me/p/concurrency-vs-parallelism/","title":"Concurrency vs Parallelism"},{"content":" 코드 커버리지 reporting 솔루션 all-in-one code coverage reporting solution #Java\n#Test\n#Library\n","date":"2023-10-03T22:44:04Z","permalink":"https://sungho94.me/p/codecove/","title":"Codecove"},{"content":" kotlin aurgument를 자동으로 만들어줍니다 value 없이 생성 default value를 사용하여 생성 random value를 사용하여 생성 ","date":"2023-10-03T22:38:37Z","permalink":"https://sungho94.me/p/kotlin-auto-fill/","title":"Kotlin Auto fill"},{"content":"#Database\n#Library\n","date":"2023-10-03T22:37:47Z","permalink":"https://sungho94.me/p/kotlin-jdsl/","title":"kotlin-jdsl"},{"content":"최근에 id 생성 관려해서 정보를 찾아보던중 TSID라는 것을 알게되었다\ntwitter에서 개발한 snowflake id generator가 있다 분산처리환경에서 id를 생성하기 위해 만든 id 생성기인데 time값을 기반으로한다\ntime값을 기반으로해서 시간순 정렬도 되고, +순차적인 정보라서 값이 겹칠일이 매우 적다.\ntime값을 기반으로한 64비트 id generator인데 처음 1비트는 0 다음 41비트는 타임 스탬프값, 다음 10비트는 machine과 관련된 정보(node id 같은것들?) 다음 12비트는 같은 milisecond에 받은 순차적인정보로 이루어진다.\njava에서 snowflake를 구현한 라이브러리가 없는지 찾아봤는데 있긴한데 스타수가 적기도하고 마지막 업데이트가 4년전이라 쓰기도 약간 부담스러워 검색을 해보니 TSID아이디 generator라는걸 찾았다\nTSID는 snowflake_id와 ulid에서 아이디어를 얻어 만들었다고 한다.\nsnowflake와 마찬가지로 처음 42비트는 시간 기반 값, 이후 22비트는 랜덤값(node id+counter)라고 한다.\n개인적으로 UUID보다 TSID가 퍼포먼스가 더 낫고, 다양한 상황에서 더 좋을거라 생각된다 단, star 수가 적고 다양한 환경에서 테스트가 안된점이 아쉽지만 시간이 해결해 줄 문제라고 생각한다\nUUID를 잘 사용하는법 https://www.percona.com/blog/uuids-are-popular-but-bad-for-performance-lets-discuss/ https://www.percona.com/blog/store-uuid-optimized-way/ https://vladmihalcea.com/uuid-database-primary-key/\nhttps://discord.com/developers/docs/reference#snowflakes https://github.com/callicoder/java-snowflake https://github.com/f4b6a3/tsid-creator https://en.wikipedia.org/wiki/Snowflake_ID|\n#Concept\n","date":"2023-10-03T10:13:23Z","permalink":"https://sungho94.me/p/tsidsorted-unique-identifiers/","title":"TSID(Sorted Unique Identifiers)"},{"content":"0.0.0.0 is a valid address syntax. So it should parse as valid wherever an IP address in traditional dotted-decimal notation is expected.\n0.0.0.0주소는 모든 ip를 의미한다\n접근제어시 0.0.0.0으로 설정하여 모든 ip를 허용하거나 거부할 수 있다.\nhttps://www.howtogeek.com/225487/what-is-the-difference-between-127.0.0.1-and-0.0.0.0/\n#ComputerScience\n","date":"2023-10-03T10:10:26Z","permalink":"https://sungho94.me/p/0.0.0.0-ip-address/","title":"0.0.0.0 ip address"},{"content":"PK 테이블에서 하나의 로우를 식별할 수 있는 최소 집합 유일성 row마다 유일한 값을 가져야함 안정성 변경되지 않아야됨 자연키 장점 사람이 이해하기 쉬움 단점 잘 설계하지 않는다면 중복의 위험이 있음 대체키 장점 중복되지않음 단점 의미없는 키값이라 한눈에 파악하기 어려움 항상 대체키만 써왔고, \u0026lsquo;자연키를 쓰면 안될까\u0026rsquo;라는 생각을 종종 했었다.\n중복의 위험이 있고, 이로인해 기본키를 바꿔야 한다는 상황이 개인적으로 자연키의 가장 위험한 점이라 생각되고, 대체키를 쓰는게 더 안전할 것이라는 확실한 생각이 들었다.\n하지만 잘 설계한다면 대체키를 사용하면 좋을거같다\n설계를 잘못하면 바뀌야한다는 위험성 때문에 도전하지 못한다면 아무것도 도전하지 못한다\n자연키를 사용할 만한 상황이 나온다면 사용해보자!\nhttps://vertabelo.com/blog/primary-key/\n#Database\n#Definition\n","date":"2023-10-03T09:59:31Z","permalink":"https://sungho94.me/p/db-pk-%EC%9E%90%EC%97%B0%ED%82%A4-vs-%EB%8C%80%EC%B2%B4%ED%82%A4/","title":"DB PK 자연키 vs 대체키"},{"content":" \u0026lsquo;Search Argument-able\u0026rsquo;의 약자 DBMS 엔진이 인덱스를 활용해서 실행 속도를 높일 수 있는 쿼리를 말함 연산자 1 2 3 4 SARGable predicates include the following operators =, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, IN, BETWEEN, and LIKE (in the case of prefix matching) Non-SARGable operators include NOT, NOT IN, \u0026lt;\u0026gt;, and LIKE 컬럼을 함수로 감싸지 않은것 1 2 3 4 5 6 7 8 Bad: Select ... WHERE isNull(FullName,\u0026#39;Ed Jones\u0026#39;) = \u0026#39;Ed Jones\u0026#39; Fixed: Select ... WHERE ((FullName = \u0026#39;Ed Jones\u0026#39;) OR (FullName IS NULL)) Bad: Select ... WHERE SUBSTRING(DealerName,4) = \u0026#39;Ford\u0026#39; Fixed: Select ... WHERE DealerName Like \u0026#39;Ford%\u0026#39; Bad: Select ... WHERE DateDiff(mm,OrderDate,GetDate()) \u0026gt;= 30 Fixed: Select ... WHERE OrderDate \u0026lt; DateAdd(mm,-30,GetDate()) 생각해보면 간단한듯! 컬럼에 함수를 씌우면 컬럼마다 함수를 실행해야하니 속도가 느려짐\nhttps://en.wikipedia.org/wiki/Sargable\nhttps://stackoverflow.com/questions/799584/what-makes-a-sql-statement-sargable\n#Query-turning\n","date":"2023-10-03T09:58:50Z","permalink":"https://sungho94.me/p/sargable-query/","title":"Sargable query"},{"content":"https://www.youtube.com/watch?v=8BJUrHNFACA\n","date":"2023-10-03T09:57:56Z","permalink":"https://sungho94.me/p/msa-%EA%B4%80%EB%A0%A8-%EC%9C%A0%ED%8A%9C%EB%B8%8C/","title":"MSA 관련 유튜브"},{"content":" 각각의 컬럼들은 요구사항에 따라 카디널리티가 다름 카디널리티가 높다 모든 값들이 다를때 카디널리티가 낮다 모든 값들이 같을때 여러 컬럼을 인덱스로 만들때, 카디널리티가 높은순에서 낮은순으로 설정할것 필터링 되는 숫자가 다르기 때문 카디널리티는 데이터베이스가 정렬하거나, 검색시 성능에 영향을 끼침기에 데이터베이스가 최적의 플랜을 짜기한 중요한 요소임 인덱스는 데이터베이스에서 어떤 요소를 빨리 찾기 위한 자료구조임\n카디널리티가 낮은 컬럼을 인덱스로 잡는다면 하나의 인덱스에 많은 데이터가 있을것이고\n카디널리티가 높은 컬럼을 인덱스로 잡는다면 하나의 인덱스에 적인 데이터가 있겠지?\n이런것들을 고려해서 인덱스로 잡으면 좋겠다!\nhttps://stackoverflow.com/questions/2566211/what-is-cardinality-in-mysql\nhttps://learn.microsoft.com/en-us/sql/relational-databases/performance/cardinality-estimation-sql-server?view=sql-server-ver16\n#Database\n#Definition\n","date":"2023-10-02T23:32:28Z","permalink":"https://sungho94.me/p/cardinality/","title":"Cardinality"},{"content":"테이블에 대한 색인을 만들때,\n해당하는 색인에 데이터를 같이 놓는다면, 색인을 찾은 후 바로 데이터를 가져올 수 있습니다\n색인과 테이블을 따로 만들면 색인 에있는 데이터의 위치를 가지고 다시 데이터를 찾아야합니다\n색인이 여러개일때 색인과 데이터를 같이 놓는다면 데이터의 중복이 발생하고, 읽기 성능은 좋아지겠지만 쓰기성능이 저하됩니다.\n그래서 하나의 색인에만 데이터를 같이놓고(clustered index), 다른색인에는 색인과 데이터의 위치(non-clutered-index)를 가지고 있습니다ㅇ\nindex는 key-value 구조로, key는 index의 값입니다.\nvalue는 clustered index에서는 해당하는 데이터값(row)이고 non-clutered-index의 값은 해당하는 clustered index의 키값입니다\nclustered Index의 값이 길면, non-clutered-index는 각 인덱스마다 긴 clutered-index를 가져야해서 저장공간이 늘어 좋지않습니다\nClustering Index 데이터가 물리적으로 저장될떄 정렬 방식을 정의 테이블당 하나만 존재 가능 기본키 제약조건이 걸린 컬럼에 자동으로 생성됨 non-Clustering Index 데이터를 물리적으로 정렬하지 않음 테이블과 다른 물리적 공간에 저장됨 테이블에 여러개가 존재 가능 유니크 제약조건에 걸린 컬럼에 자동으로 적용됨 너무 많이 생성시 생성, 수정, 삭제의 오버헤드가 커짐 https://www.sqlshack.com/what-is-the-difference-between-clustered-and-non-clustered-indexes-in-sql-server/\nhttps://learn.microsoft.com/ko-kr/sql/relational-databases/indexes/clustered-and-nonclustered-indexes-described?view=sql-server-ver16\nhttps://gwang920.github.io/database/clusterednonclustered/\nhttps://mozi.tistory.com/320\nhttps://dev.mysql.com/doc/refman/8.0/en/InnoDB-index-types.html\n#InnoDB\n","date":"2023-10-02T23:31:55Z","permalink":"https://sungho94.me/p/clustered-index-non-clustered-index/","title":"Clustered Index, non-Clustered Index"},{"content":" 하나의 쿼리의 전체 요구사항이 인덱스인 상황 커버링 인덱스를 활용하므로서 실제 테이블에 접근하지 않고, Index tree만 검색 후 결과를 리턴 실제 테이블을 접근하지 않음으로 속도가 매우 빠름 출력되어야 하는 값까지 모두 인덱스일경우 https://planetscale.com/learn/courses/mysql-for-developers/indexes/covering-indexes\nhttps://www.sqler.com/board_SQLQA/707203\n#Database\n","date":"2023-10-02T23:30:52Z","permalink":"https://sungho94.me/p/covering-indexes%EC%BB%A4%EB%B2%84%EB%A7%81-%EC%9D%B8%EB%8D%B1%EC%8A%A4/","title":"Covering Indexes(커버링 인덱스)"},{"content":"테스트 자동화 도구\nBDD를 지원\n#Test\n","date":"2023-10-02T23:26:54Z","permalink":"https://sungho94.me/p/cucumber/","title":"Cucumber"},{"content":"java의 built in Annotation은\n@Deprecated\n@Override\n@SuppressWarnings\n@SafeVarargs\n@FunctionalInterface\n이 있고,\n다른 어노테이션에 붙을 수 있는 어노테이션은\n@Retention\n@Documented\n@Target\n@Inherited\n@Repeatable\n이 있다\n이 중 Retention의 정확한 의미가 와닿지 않아 정리해 보겠다.\nRetention 1 Indicates how long annotations with the annotated interface are to be retained -\u0026gt; annotation이 얼마나 유지되는 정도를 나타냄, 디폴트는 Class\nSource 컴파일될때 사라짐 Class 클래스파일에는 기록되지만, vm에 올라갈떄 사라짐 런타임시 리플렉션으로 정보를 가져올 수 없음 Runtime 클래스파일에도 기록되고, vm에 올라감 런타임시 리플렉션으로 정보를 가져올 수 있음 Source vs Class\nSource는 컴파일된 바이트 코드에서 아예 보이지 않음\nClass는 바이트코드에서 보이지만 invisible이라는 주석이 붙음\n바이트코드로 된 라이브러리를 만들때 사용\nClass vs Runtime\n런타임에 사용 가능 여부에 따라 다름\n@Lorg/example/RetentionSourceAnnotation;() // invisible \u0026lt;- Class\n@Lorg/example/RetentionSourceAnnotation;() \u0026lt;- Runtime\njavaasist 라이브러로 두개다 확인가능\nhttps://www.javassist.org/html/javassist/bytecode/AnnotationsAttribute.html\nhttps://docs.oracle.com/javase/tutorial/java/annotations/predefined.html\nhttps://minkukjo.github.io/language/2020/09/30/Java-02/\n#Java\n","date":"2023-10-01T23:06:17Z","permalink":"https://sungho94.me/p/java-built-in-annotation/","title":"Java built in Annotation"},{"content":"entity manager entity 인스턴스의 생명주기를 관리 hibernate에서는 entity manager를 상속한 session인터페이스가 있음 transaction이 생성될 때 entityManagerFactory에서 생성됨 transaction이 끝날 때 삭제됨 persist, find, merge 등의 동작이 있음 jpa 1차 캐시 영속성컨텍스트에 존재하는 엔티티를 가져오는 것 hiberante에서는 session에서 find를 호출하거나, 연관관계가 있는 엔티티에서 호출할때만 사용, JPQL이나 Criteria Query를 사용할떄는 사용 불가 2차 캐시 어플리케이션의 생명주기동안 유지됨 궁금할때 찾아볼것\u0026hellip; https://thorben-janssen.com/wp-content/uploads/member-access/1stLevelCache_Handout.pdf\nhttps://dzone.com/articles/how-does-spring-transactional\nhttps://www.ibm.com/docs/en/wasdtfe?topic=architecture-entity-manager\nhttps://www.baeldung.com/jpa-hibernate-persistence-context\nhttps://openjpa.apache.org/builds/1.2.3/apache-openjpa/docs/jpa_overview_emfactory_perscontext.html|\n","date":"2023-09-30T14:49:42Z","permalink":"https://sungho94.me/p/jpa-entity-manager/","title":"JPA entity manager"},{"content":" jooq jpa가 아닌 native sql builder #Database\n#Library\n","date":"2023-09-30T14:48:53Z","permalink":"https://sungho94.me/p/jooq/","title":"jooq"},{"content":" 동기 서비스처리가 완료된 이후에 처리 결과를 확인하는 방식을 동기식 호출(결과가 올때까지 대기해야함) 비동기 서비스처리가 완료되기전에 우선 응답을 전달하는 방식(대기하는것을 방지) 블로킹 요청한 작업이 성공하거나 에러가 발생하기 전까지는 응답을 돌려주지않는 것을 의미 (ServerSocket, Socket 클래스) \u0026ldquo;Blocking\u0026rdquo; means that the caller waits until the callee finishes its processing.\n논블로킹 요청한 작업의 성공여부와 상관없이 바로 결과를 돌려줌 (ServerSocketChannel, SocketChannel 클래스) 왜 Block IO보다 NonBlock IO가 느릴까? Block I/O 데이터가 커널로 들어오면 데이터가 바로 커널스페이스에서 유저스페이스로 이동함 Non Block I/O 방법이 2가지 있음 데이터가 들어왔는지 반복해서 확인 우선 반복적으로 확인하기 때문에 cpu 자원낭비가 됨 데이터가 들어온시점과 반복적으로 확인한 시점 사이에 시간차가 발생할 수 밖에 없기 때문에 Block I/O보다 느림 데이터가 들어오면 알려 줌 데이터가 들어오면 커널에서 알려줌 알려주면 쓰레드에서 read syscall을 날려서 데이터를 읽음 커널에서 데이터가 들어온걸 알려주고, 쓰레드가 확인해서 해당 데이터를 가져오기 까지 시간 텀이 발생함 https://www.youtube.com/watch?v=mb-QHxVfmcs\u0026amp;t=757s\nhttps://nesoy.github.io/articles/2017-01/Synchronized\nhttps://d2.naver.com/helloworld/47667\n#Non-Blocking-IO\n","date":"2023-09-30T14:47:58Z","permalink":"https://sungho94.me/p/%EB%8F%99%EA%B8%B0-%EB%B9%84%EB%8F%99%EA%B8%B0-%EB%B8%94%EB%A1%9C%ED%82%B9-%EB%85%BC%EB%B8%94%EB%A1%9C%ED%82%B9/","title":"동기 \u0026 비동기, 블로킹 \u0026 논블로킹"},{"content":"정적타입 자료형을 컴파일시에 확인 타입에러를 컴파일 시에 확인가능 java, c 동적타입 자료형을 런타임시에 확인 타입에 대한 고민을 뒤로 넘길 수 있음 메서드가 다양한 기능을 할 수 있음\u0026hellip; 런타임에 타입에러 발생 가능 python, javascript 강타입 연관이 없는 타입끼리 형변환이 불가, 형변환시 명시적으로 선언해야함 약타입 연관이 없는 타입끼리 암시적으로 형변환이 가능 https://www.educative.io/answers/statically-v-dynamically-v-strongly-v-weakly-typed-languages\nhttps://stackoverflow.com/questions/11889602/difference-between-strong-vs-static-typing-and-weak-vs-dynamic-typing\n","date":"2023-09-30T14:44:40Z","permalink":"https://sungho94.me/p/static-vs-dynamicstrong-vs-weak/","title":"Static vs Dynamic,Strong vs Weak"},{"content":"파일 목록 보기(파일디스크립터 확인 위해) 1 2 3 4 5 6 7 8 9 10 - yum install lsof - 설치 - lsof -p \u0026lt;PID\u0026gt; | wc -l - 파일 디스크립터 개수 확인 열린포트 확인 sudo lsof -PiTCP -sTCP:LISTEN 특정 포트 확인 `sudo lsof -i :3000` #shell-command\n","date":"2023-09-30T14:42:10Z","permalink":"https://sungho94.me/p/%ED%8C%8C%EC%9D%BC%EB%AA%A9%EB%A1%9D-%EB%B3%B4%EA%B8%B0-%ED%8C%8C%EC%9D%BC%EB%94%94%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%84%B0/","title":"파일목록 보기, 파일디스크립터"},{"content":"프로세스 정보보기 1 2 - yum install procps - 설치 프로세스 상태 1 - cat /proc/\u0026lt;PID\u0026gt;/status 쓰레드 개수 1 2 3 4 - ps huH p \u0026lt;PID\u0026gt; | wc -l - ps -o thcount \u0026lt;PID\u0026gt; - ps -eT - ps H -o \u0026#39;tid comm\u0026#39; \u0026lt;PID\u0026gt; #shell-command\n#thread\n","date":"2023-09-30T14:41:52Z","permalink":"https://sungho94.me/p/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4-%EA%B4%80%EB%A0%A8-%EB%AA%85%EB%A0%B9%EC%96%B4/","title":"프로세스 관련 명령어"},{"content":"마스터노드가 1개라면, 마스터 노드에 장애가 발생하였을때 클러스터 전체가 동작하지 않는다는 문제가 있다.\n그 이유는 위와 같이 어떠한 장애로 인해 클러스터의 노드가 3개, 2개씩 분리가 되었을 때 각각의 집합에서 서비스를 제공하고, 이후에 장애가 해결된 이후 다시 하나의 클러스터로 만들때 데이터 정합성에 문제가 생기고 데이터 무결성이 유지될 수 없다.\n위 상황을 split brain이라고 한다.\nsplit brain을 해결하는 방법에는 최소 투표 개수를 지정하여, 최소 투표 개수 이상을 받은 후보가 마스터가 되게하는 방법, 특정 id이상의 마스터 후보만 마스터로 선출하는 방법 등이 있다\n","date":"2023-09-28T18:01:16Z","permalink":"https://sungho94.me/p/split-brain/","title":"Split brain"},{"content":"spring\nhttps://spring.io/projects/spring-boot\nkotlin + coroutine\nhttps://spring.io/projects/spring-boot\njava + gc\nhttps://docs.oracle.com/en/java/\nmysql\nhttps://dev.mysql.com/doc/\nelasticsearch\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\nredis\nhttps://redis.io/docs/\ntest\njunit\ntrouble shooting\n대용량 트래픽\n시스템 디자인\nhttps://www.enjoyalgorithms.com/system-design/\nhttps://learn.microsoft.com/en-us/azure/architecture/changelog\nhttps://microservices.io/patterns/index.html\nhttps://microservices.io\n#Study-Material\n","date":"2023-09-28T17:55:29Z","permalink":"https://sungho94.me/p/%EA%B3%B5%EB%B6%80%ED%95%A0%EC%9E%90%EB%A3%8C/","title":"공부할자료"},{"content":"Rectangle\n마그네틱\n","date":"2023-09-26T22:15:55Z","permalink":"https://sungho94.me/p/%ED%99%94%EB%A9%B4%EB%B6%84%ED%95%A0-in-mac/","title":"화면분할 in mac"},{"content":" 1 2 3 4 5 6 7 find ./ -type f -mtime +30 -print sudo find ./ -type f -mtime +30 -delete find . -type d -empty -find sudo find . -type d -empty -delete 10 0 * * * find /home/ec2-user/efs/es-log -type f -mtime +30 -delete 10 0 * * * find /home/ec2-user/efs/es-log -type d -empty -delete ","date":"2023-09-25T11:02:36Z","permalink":"https://sungho94.me/p/%EC%9D%BC%EC%A0%95-%EA%B8%B0%EA%B0%84-%ED%8C%8C%EC%9D%BC-%EC%82%AD%EC%A0%9C-%EB%B0%8F-%EB%B9%88-%EB%94%94%EB%A0%89%ED%86%A0%EB%A6%AC-%EC%82%AD%EC%A0%9C/","title":"일정 기간 파일 삭제 및 빈 디렉토리 삭제"},{"content":" 소프트웨어의 복잡성을 해결하는 방법중 하나 객체의 메서드를 Query와 Command로 분리하는것 CQRS는 side effect 어떻게 다룰까에 관한 문제임 Query 객체의 상태를 변경시키지 않고 특정한 값을 리턴하는 메서드 상태를 변경시키지 않기때문에 side effect가 발생하지 않음 command에서 사용할 수 있음 Command 객체의 상태를 변화시키는 메서드 리턴값이 존재하지 않음 commnd는 객체의 상태를 변경하는 메서드이므로 side effect가 존재 query에서 호출할 수 없음 장점 디버깅시 조회에 관한 부분은 Query에서, side effect에 관한 부분은 command만 검사하면 됨 복잡성이 줄어든다 단점 하지만 command임에도 리턴값이 필요한 상황이 존재한다 ex) 최종 변경사항을 리턴해줘야하는 경우, Stack의 pop메서드 command라는 네이밍을 가지고 메서드명도 충분히 command라는걸 표현함에도 이걸 쿼리처럼 사용하는 사람이 문제라는 결론 Query\n하나의 값을 받아서 어떠한 처리를 하는 함수 side effect가 존재해서는 안됨 Procedure에서 호출될 수 있음 Procedure\n하나의 값을 받아서 결과를 리턴해주는 함수 side effect가 존재함 Query에서 호출할 수 없음 query에서는 side effect가 생기면 안되기 때문 https://martinfowler.com/bliki/CommandQuerySeparation.html\nhttps://blog.ploeh.dk/2014/08/11/cqs-versus-server-generated-ids/\n#Software-design\n","date":"2023-09-24T23:14:02Z","permalink":"https://sungho94.me/p/cqrscommand-and-query-responsibility-segregation/","title":"CQRS(Command and Query Responsibility Segregation)"},{"content":"https://developerhandbook.stakater.com/content/java-backend/wf-engine.html\n#Study-Material\n","date":"2023-09-17T22:47:35Z","permalink":"https://sungho94.me/p/dev-handbook/","title":"dev handbook"},{"content":"https://velocity.builder.io/\n","date":"2023-09-17T22:40:08Z","permalink":"https://sungho94.me/p/velocity/","title":"Velocity"},{"content":"유스콘'23이 끝난 지 벌써 3주가 지났다는 것이 믿어지시나요? 드디어 온라인 다시 보기 영상을 공개합니다. 온라인 영상 공개에 맞춰 후기 작성 이벤트를 조금 더 연장할 예정입니다.\n유스콘'23에 대한 후기를 작성해 주세요. 작성한 후기는 발표자에게 전달되며 보다 나은 행사가 될 수 있도록 최선을 다하겠습니다. :) 후기를 남겨 주신 분들 중 추첨을 통해 상품도 드립니다. (9월 20일 수요일 마감)\nhttps://forms.gle/ecsPknq5X8UEjLsy5\n[유스콘’23 자세히 보기]\nhttps://frost-witch-afb.notion.site/YOUTHCON-23-a026c94d997e46db9396283ed869a922\n[트랙 1]\nhttps://woowahan.zoom.us/rec/share/MwZWEwiJXclNHRgU72M7c7VGXKgbIKMPJOdzO6gEu0olAfHJT5RbqhI0ZYRygJJD.TrHrSPz4F4NQYK_b\n암호: R*yL6P2+\n만료일: 2023-10-31\n[트랙 2 Hands-On Lab]\nhttps://woowahan.zoom.us/rec/share/-7KQzHpZckcCYhpFUVlS9JZHBm8QTVw82cIcCiUOtYp-mzc_jM3Fvj2ufyOnPPuF.pL2ThWDnFyTPTSnN\n암호: 95p?n^MG\n만료일: 2023-10-31\n[트랙 2 발표]\nhttps://woowahan.zoom.us/rec/share/RSESAlWFjfpe0NQEV99k_DU-iBSNkvS4F2wR6x8xUnieW3dbXZ75Q64r18DyOluV.O2f76ErzIrT0KtTk\n암호: 0.^Nq..A\n만료일: 2023-10-31\n#Spring\n","date":"2023-09-17T22:39:40Z","permalink":"https://sungho94.me/p/%EC%9C%A0%EC%BE%8C%ED%95%9C-%EC%8A%A4%ED%94%84%EB%A7%81%EB%B0%A9-%EC%BD%98%EC%84%9C%ED%8A%B8/","title":"유쾌한 스프링방 콘서트"},{"content":"#Tool\n","date":"2023-09-17T22:37:55Z","permalink":"https://sungho94.me/p/ctop/","title":"ctop"},{"content":"MySQL .ibd 파일을 이용하여 데이터 복구하기\nhttps://puleugo.tistory.com/167\nMySQL binlog를 이용하여 데이터 복구하기\nhttps://puleugo.tistory.com/168\n#Database\n","date":"2023-09-17T22:31:08Z","permalink":"https://sungho94.me/p/db-%EB%82%A0%EB%A0%A4%EB%A8%B9%EC%97%88%EC%9D%84%EB%95%8C-%EB%B3%B5%EA%B5%AC%EB%B0%A9%EB%B2%95/","title":"DB 날려먹었을때 복구방법"},{"content":"https://github.com/woowacourse-precourse\n#Study-Material\n","date":"2023-09-17T22:29:23Z","permalink":"https://sungho94.me/p/%EC%9A%B0%ED%98%95-%ED%94%84%EB%A6%AC%EC%BD%94%EC%8A%A4-github/","title":"우형 프리코스 github"},{"content":"쿼리튜닝에서 젤 먼저 우선시 되어야하는건 서비스 특성과 요구사항을 이해하는게 중요합니다. 만약에 꼭 하신다고 하면 본인 서비스가 어떤 특성을 갖고 데이터가 어떤 형태를 띄는지 부터 정리 해놓으셔야 합니다.\n#Database\n","date":"2023-09-17T22:26:20Z","permalink":"https://sungho94.me/p/%EC%BF%BC%EB%A6%AC-%ED%8A%9C%EB%8B%9D%EC%8B%9C/","title":"쿼리 튜닝시"},{"content":"픽스처를 자동으로 생성해주는 도구\nhttps://github.com/naver/fixture-monkey\nhttps://github.com/j-easy/easy-random\n#Tool\n","date":"2023-09-17T22:21:59Z","permalink":"https://sungho94.me/p/%ED%85%8C%EC%8A%A4%ED%8A%B8-%ED%94%BD%EC%8A%A4%EC%B2%98-%EB%8F%84%EA%B5%AC/","title":"테스트 픽스처 도구"},{"content":"AI 번역 툴\n다른 번역기보다 번역을 잘해서 유심히 보는중 : )\n","date":"2023-09-11T10:20:02Z","permalink":"https://sungho94.me/p/deepl/","title":"DeepL"},{"content":"java 코드와 설정사항 변경시 서버 재시작없이 현재 실행하고 있는 어플리케이션에 즉시 반영해주는 도구\n년 550달러이다..\n","date":"2023-09-11T10:17:02Z","permalink":"https://sungho94.me/p/jrebel/","title":"JRebel"},{"content":" https://excalidraw.com/ https://www.lucidchart.com/pages/ drawio http://mermaid.js.org/intro/ www.cloudcraft.co https://www.cloudcraft.co/\n#Tool ","date":"2023-09-11T10:12:53Z","permalink":"https://sungho94.me/p/%EB%93%9C%EB%A1%9C%EC%9C%99-%ED%88%B4/","title":"드로윙 툴"}]